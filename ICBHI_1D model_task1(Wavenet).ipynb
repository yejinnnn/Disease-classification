{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db226c55",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-11T04:30:45.714745Z",
     "start_time": "2023-05-11T04:30:39.946099Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.EL2C6PLE4ZYW3ECEVIV3OXXGRN2NRFM2.gfortran-win_amd64.dll\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.NOIJJG62EMASZI6NYURL6JBKM4EVBGM7.gfortran-win_amd64.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "import librosa.display\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import glob\n",
    "import shutil\n",
    "import subprocess\n",
    "import wave\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import keras\n",
    "import re\n",
    "from keras.applications.densenet import layers\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, Conv1D, MaxPooling1D, LSTM, GRU, SimpleRNN, Conv1DTranspose, Concatenate, Conv2DTranspose\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b94bfa78",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# non-segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f70dacf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-11T04:37:17.701720Z",
     "start_time": "2023-05-11T04:30:47.551393Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# 읽어올 폴더 경로 설정\n",
    "data_folder = 'D:/Data/호흡데이터/Task1/Wav_nonsegment/Healthy'\n",
    "# 읽어올 폴더 경로 설정(데이터 길이 구하기 위함)\n",
    "data_folder_unhealthy = 'D:/Data/호흡데이터/Task1/Wav_nonsegment/Unhealthy'\n",
    "\n",
    "# 읽어올 파일 리스트 생성\n",
    "file_list = []\n",
    "for root, dirs, files in os.walk(data_folder):\n",
    "    for file in files:\n",
    "        if file.endswith('.wav'):\n",
    "            file_list.append(os.path.join(root, file))\n",
    "            \n",
    "            \n",
    "# 데이터 길이 맞추기위해 읽어올 파일 리스트 생성\n",
    "file_list_unhealthy = []\n",
    "for root, dirs, files_unhealthy in os.walk(data_folder_unhealthy):\n",
    "    for file_unhealthy in files_unhealthy:\n",
    "        if file.endswith('.wav'):\n",
    "            file_list_unhealthy.append(os.path.join(root, file_unhealthy))\n",
    "            \n",
    "\n",
    "# 가장 짧은 파일의 길이 구하기\n",
    "min_len = min([len(librosa.load(file_unhealthy)[0]) for file_unhealthy in file_list_unhealthy])\n",
    "\n",
    "# 데이터프레임 생성\n",
    "dfs = []\n",
    "for file in file_list:\n",
    "    # 오디오 파일 읽어오기\n",
    "    audio_data, sample_rate = librosa.load(file)\n",
    "    # 가장 짧은 길이에 맞게 데이터 자르기\n",
    "    audio_data = audio_data[:min_len]\n",
    "    # 시간 축 설정\n",
    "    time_axis = librosa.times_like(audio_data, sr=sample_rate)\n",
    "    # 채널 축 설정\n",
    "    channel_axis = ['Channel 1']\n",
    "    # 데이터프레임 생성\n",
    "    df = pd.DataFrame(audio_data.reshape(-1, len(channel_axis)), columns=channel_axis)\n",
    "    \n",
    "    dfs.append(df)\n",
    "\n",
    "# 모든 데이터프레임을 하나로 합치기\n",
    "df_healthy = pd.concat(dfs, axis=1, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4452d771",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-11T04:37:17.746893Z",
     "start_time": "2023-05-11T04:37:17.702719Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>173215</th>\n",
       "      <th>173216</th>\n",
       "      <th>173217</th>\n",
       "      <th>173218</th>\n",
       "      <th>173219</th>\n",
       "      <th>173220</th>\n",
       "      <th>173221</th>\n",
       "      <th>173222</th>\n",
       "      <th>173223</th>\n",
       "      <th>173224</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.002834</td>\n",
       "      <td>0.004234</td>\n",
       "      <td>0.003641</td>\n",
       "      <td>0.003971</td>\n",
       "      <td>0.003700</td>\n",
       "      <td>0.003809</td>\n",
       "      <td>0.003576</td>\n",
       "      <td>0.003688</td>\n",
       "      <td>0.003570</td>\n",
       "      <td>0.003566</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008067</td>\n",
       "      <td>0.008140</td>\n",
       "      <td>0.008190</td>\n",
       "      <td>0.008175</td>\n",
       "      <td>0.008217</td>\n",
       "      <td>0.008314</td>\n",
       "      <td>0.008320</td>\n",
       "      <td>0.008422</td>\n",
       "      <td>0.008517</td>\n",
       "      <td>0.008680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.074944</td>\n",
       "      <td>-0.108564</td>\n",
       "      <td>-0.093635</td>\n",
       "      <td>-0.100122</td>\n",
       "      <td>-0.091679</td>\n",
       "      <td>-0.093961</td>\n",
       "      <td>-0.087420</td>\n",
       "      <td>-0.088095</td>\n",
       "      <td>-0.083677</td>\n",
       "      <td>-0.084414</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001657</td>\n",
       "      <td>0.001447</td>\n",
       "      <td>0.000820</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>-0.000793</td>\n",
       "      <td>-0.001621</td>\n",
       "      <td>-0.002303</td>\n",
       "      <td>-0.002842</td>\n",
       "      <td>-0.003067</td>\n",
       "      <td>-0.003418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.031243</td>\n",
       "      <td>0.045788</td>\n",
       "      <td>0.040219</td>\n",
       "      <td>0.043209</td>\n",
       "      <td>0.039028</td>\n",
       "      <td>0.038991</td>\n",
       "      <td>0.034904</td>\n",
       "      <td>0.033426</td>\n",
       "      <td>0.029972</td>\n",
       "      <td>0.028974</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.014146</td>\n",
       "      <td>-0.012259</td>\n",
       "      <td>-0.009135</td>\n",
       "      <td>-0.005213</td>\n",
       "      <td>-0.000988</td>\n",
       "      <td>0.002983</td>\n",
       "      <td>0.006162</td>\n",
       "      <td>0.008906</td>\n",
       "      <td>0.010976</td>\n",
       "      <td>0.012153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.030055</td>\n",
       "      <td>0.043004</td>\n",
       "      <td>0.036623</td>\n",
       "      <td>0.038840</td>\n",
       "      <td>0.035038</td>\n",
       "      <td>0.035900</td>\n",
       "      <td>0.033086</td>\n",
       "      <td>0.033206</td>\n",
       "      <td>0.031031</td>\n",
       "      <td>0.030529</td>\n",
       "      <td>...</td>\n",
       "      <td>0.089253</td>\n",
       "      <td>0.088449</td>\n",
       "      <td>0.087667</td>\n",
       "      <td>0.086844</td>\n",
       "      <td>0.086066</td>\n",
       "      <td>0.085214</td>\n",
       "      <td>0.084552</td>\n",
       "      <td>0.083685</td>\n",
       "      <td>0.082866</td>\n",
       "      <td>0.082092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.058900</td>\n",
       "      <td>-0.084398</td>\n",
       "      <td>-0.071648</td>\n",
       "      <td>-0.076402</td>\n",
       "      <td>-0.070458</td>\n",
       "      <td>-0.074119</td>\n",
       "      <td>-0.071738</td>\n",
       "      <td>-0.075175</td>\n",
       "      <td>-0.074700</td>\n",
       "      <td>-0.077834</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.206857</td>\n",
       "      <td>-0.213262</td>\n",
       "      <td>-0.218788</td>\n",
       "      <td>-0.223172</td>\n",
       "      <td>-0.226421</td>\n",
       "      <td>-0.228739</td>\n",
       "      <td>-0.230270</td>\n",
       "      <td>-0.231345</td>\n",
       "      <td>-0.232212</td>\n",
       "      <td>-0.233467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.007034</td>\n",
       "      <td>-0.010403</td>\n",
       "      <td>-0.009126</td>\n",
       "      <td>-0.009703</td>\n",
       "      <td>-0.009150</td>\n",
       "      <td>-0.009540</td>\n",
       "      <td>-0.009445</td>\n",
       "      <td>-0.009780</td>\n",
       "      <td>-0.009571</td>\n",
       "      <td>-0.009791</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000319</td>\n",
       "      <td>-0.000152</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.000203</td>\n",
       "      <td>0.000336</td>\n",
       "      <td>0.000413</td>\n",
       "      <td>0.000378</td>\n",
       "      <td>0.000451</td>\n",
       "      <td>0.000369</td>\n",
       "      <td>0.000313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.008411</td>\n",
       "      <td>0.012138</td>\n",
       "      <td>0.010478</td>\n",
       "      <td>0.011247</td>\n",
       "      <td>0.010533</td>\n",
       "      <td>0.011056</td>\n",
       "      <td>0.010151</td>\n",
       "      <td>0.009742</td>\n",
       "      <td>0.009111</td>\n",
       "      <td>0.009042</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.035101</td>\n",
       "      <td>-0.035011</td>\n",
       "      <td>-0.035020</td>\n",
       "      <td>-0.035029</td>\n",
       "      <td>-0.035122</td>\n",
       "      <td>-0.034985</td>\n",
       "      <td>-0.034749</td>\n",
       "      <td>-0.033376</td>\n",
       "      <td>-0.033500</td>\n",
       "      <td>-0.033659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.035490</td>\n",
       "      <td>-0.052700</td>\n",
       "      <td>-0.047214</td>\n",
       "      <td>-0.051584</td>\n",
       "      <td>-0.049264</td>\n",
       "      <td>-0.052077</td>\n",
       "      <td>-0.050764</td>\n",
       "      <td>-0.052858</td>\n",
       "      <td>-0.052138</td>\n",
       "      <td>-0.053505</td>\n",
       "      <td>...</td>\n",
       "      <td>0.251070</td>\n",
       "      <td>0.251797</td>\n",
       "      <td>0.252594</td>\n",
       "      <td>0.253096</td>\n",
       "      <td>0.253664</td>\n",
       "      <td>0.254207</td>\n",
       "      <td>0.254856</td>\n",
       "      <td>0.255327</td>\n",
       "      <td>0.256061</td>\n",
       "      <td>0.256631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.007025</td>\n",
       "      <td>-0.010711</td>\n",
       "      <td>-0.009760</td>\n",
       "      <td>-0.011117</td>\n",
       "      <td>-0.010905</td>\n",
       "      <td>-0.011542</td>\n",
       "      <td>-0.011487</td>\n",
       "      <td>-0.012052</td>\n",
       "      <td>-0.011880</td>\n",
       "      <td>-0.012059</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.043829</td>\n",
       "      <td>-0.043033</td>\n",
       "      <td>-0.042452</td>\n",
       "      <td>-0.042494</td>\n",
       "      <td>-0.042305</td>\n",
       "      <td>-0.042105</td>\n",
       "      <td>-0.041877</td>\n",
       "      <td>-0.041487</td>\n",
       "      <td>-0.040987</td>\n",
       "      <td>-0.040699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.069494</td>\n",
       "      <td>0.102969</td>\n",
       "      <td>0.091331</td>\n",
       "      <td>0.099595</td>\n",
       "      <td>0.093863</td>\n",
       "      <td>0.098485</td>\n",
       "      <td>0.095500</td>\n",
       "      <td>0.098237</td>\n",
       "      <td>0.096112</td>\n",
       "      <td>0.098258</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.010475</td>\n",
       "      <td>-0.009911</td>\n",
       "      <td>-0.009007</td>\n",
       "      <td>-0.008181</td>\n",
       "      <td>-0.007259</td>\n",
       "      <td>-0.006685</td>\n",
       "      <td>-0.005691</td>\n",
       "      <td>-0.004556</td>\n",
       "      <td>-0.003732</td>\n",
       "      <td>-0.003431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-0.002475</td>\n",
       "      <td>-0.003384</td>\n",
       "      <td>-0.002563</td>\n",
       "      <td>-0.002860</td>\n",
       "      <td>-0.003616</td>\n",
       "      <td>-0.004586</td>\n",
       "      <td>-0.005980</td>\n",
       "      <td>-0.007814</td>\n",
       "      <td>-0.009794</td>\n",
       "      <td>-0.011780</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.034290</td>\n",
       "      <td>-0.034048</td>\n",
       "      <td>-0.033800</td>\n",
       "      <td>-0.033792</td>\n",
       "      <td>-0.033129</td>\n",
       "      <td>-0.031824</td>\n",
       "      <td>-0.031523</td>\n",
       "      <td>-0.031697</td>\n",
       "      <td>-0.030978</td>\n",
       "      <td>-0.029946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-0.081173</td>\n",
       "      <td>-0.119004</td>\n",
       "      <td>-0.104803</td>\n",
       "      <td>-0.113619</td>\n",
       "      <td>-0.107089</td>\n",
       "      <td>-0.112096</td>\n",
       "      <td>-0.107956</td>\n",
       "      <td>-0.111243</td>\n",
       "      <td>-0.108613</td>\n",
       "      <td>-0.110848</td>\n",
       "      <td>...</td>\n",
       "      <td>0.034755</td>\n",
       "      <td>0.034469</td>\n",
       "      <td>0.034643</td>\n",
       "      <td>0.034344</td>\n",
       "      <td>0.034699</td>\n",
       "      <td>0.034943</td>\n",
       "      <td>0.034934</td>\n",
       "      <td>0.035696</td>\n",
       "      <td>0.035977</td>\n",
       "      <td>0.036404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-0.025988</td>\n",
       "      <td>-0.038236</td>\n",
       "      <td>-0.033611</td>\n",
       "      <td>-0.036232</td>\n",
       "      <td>-0.034116</td>\n",
       "      <td>-0.035283</td>\n",
       "      <td>-0.033953</td>\n",
       "      <td>-0.034721</td>\n",
       "      <td>-0.033415</td>\n",
       "      <td>-0.034382</td>\n",
       "      <td>...</td>\n",
       "      <td>0.053806</td>\n",
       "      <td>0.054351</td>\n",
       "      <td>0.053982</td>\n",
       "      <td>0.053644</td>\n",
       "      <td>0.053071</td>\n",
       "      <td>0.052972</td>\n",
       "      <td>0.052609</td>\n",
       "      <td>0.052387</td>\n",
       "      <td>0.052251</td>\n",
       "      <td>0.051728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-0.025989</td>\n",
       "      <td>-0.038212</td>\n",
       "      <td>-0.034844</td>\n",
       "      <td>-0.038497</td>\n",
       "      <td>-0.036611</td>\n",
       "      <td>-0.038637</td>\n",
       "      <td>-0.037569</td>\n",
       "      <td>-0.039016</td>\n",
       "      <td>-0.037861</td>\n",
       "      <td>-0.038337</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007106</td>\n",
       "      <td>0.006741</td>\n",
       "      <td>0.006647</td>\n",
       "      <td>0.006201</td>\n",
       "      <td>0.006376</td>\n",
       "      <td>0.006043</td>\n",
       "      <td>0.006107</td>\n",
       "      <td>0.005854</td>\n",
       "      <td>0.005605</td>\n",
       "      <td>0.005888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-0.011496</td>\n",
       "      <td>-0.017115</td>\n",
       "      <td>-0.015914</td>\n",
       "      <td>-0.017310</td>\n",
       "      <td>-0.016868</td>\n",
       "      <td>-0.017491</td>\n",
       "      <td>-0.017304</td>\n",
       "      <td>-0.018115</td>\n",
       "      <td>-0.017640</td>\n",
       "      <td>-0.018821</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.006674</td>\n",
       "      <td>-0.006731</td>\n",
       "      <td>-0.007832</td>\n",
       "      <td>-0.006780</td>\n",
       "      <td>-0.007392</td>\n",
       "      <td>-0.007099</td>\n",
       "      <td>-0.007130</td>\n",
       "      <td>-0.007365</td>\n",
       "      <td>-0.006983</td>\n",
       "      <td>-0.007527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.056063</td>\n",
       "      <td>0.081653</td>\n",
       "      <td>0.071722</td>\n",
       "      <td>0.077195</td>\n",
       "      <td>0.072150</td>\n",
       "      <td>0.075371</td>\n",
       "      <td>0.071995</td>\n",
       "      <td>0.073981</td>\n",
       "      <td>0.071661</td>\n",
       "      <td>0.073230</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.069173</td>\n",
       "      <td>-0.068591</td>\n",
       "      <td>-0.066967</td>\n",
       "      <td>-0.066161</td>\n",
       "      <td>-0.065221</td>\n",
       "      <td>-0.063590</td>\n",
       "      <td>-0.062556</td>\n",
       "      <td>-0.061832</td>\n",
       "      <td>-0.060643</td>\n",
       "      <td>-0.059259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-0.023203</td>\n",
       "      <td>-0.034764</td>\n",
       "      <td>-0.030409</td>\n",
       "      <td>-0.032864</td>\n",
       "      <td>-0.031366</td>\n",
       "      <td>-0.032827</td>\n",
       "      <td>-0.031958</td>\n",
       "      <td>-0.032474</td>\n",
       "      <td>-0.032428</td>\n",
       "      <td>-0.033509</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.035067</td>\n",
       "      <td>-0.033222</td>\n",
       "      <td>-0.033415</td>\n",
       "      <td>-0.032224</td>\n",
       "      <td>-0.031335</td>\n",
       "      <td>-0.030069</td>\n",
       "      <td>-0.029755</td>\n",
       "      <td>-0.028809</td>\n",
       "      <td>-0.028174</td>\n",
       "      <td>-0.027388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-0.089683</td>\n",
       "      <td>-0.132175</td>\n",
       "      <td>-0.117259</td>\n",
       "      <td>-0.127997</td>\n",
       "      <td>-0.121205</td>\n",
       "      <td>-0.127644</td>\n",
       "      <td>-0.123680</td>\n",
       "      <td>-0.127932</td>\n",
       "      <td>-0.125590</td>\n",
       "      <td>-0.128426</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.008061</td>\n",
       "      <td>-0.007805</td>\n",
       "      <td>-0.007588</td>\n",
       "      <td>-0.007294</td>\n",
       "      <td>-0.007081</td>\n",
       "      <td>-0.006809</td>\n",
       "      <td>-0.006525</td>\n",
       "      <td>-0.006133</td>\n",
       "      <td>-0.005807</td>\n",
       "      <td>-0.005591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-0.009636</td>\n",
       "      <td>-0.015557</td>\n",
       "      <td>-0.012887</td>\n",
       "      <td>-0.015032</td>\n",
       "      <td>-0.013658</td>\n",
       "      <td>-0.014902</td>\n",
       "      <td>-0.014332</td>\n",
       "      <td>-0.014974</td>\n",
       "      <td>-0.015067</td>\n",
       "      <td>-0.015134</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.084627</td>\n",
       "      <td>-0.085089</td>\n",
       "      <td>-0.084441</td>\n",
       "      <td>-0.085012</td>\n",
       "      <td>-0.083811</td>\n",
       "      <td>-0.084303</td>\n",
       "      <td>-0.083450</td>\n",
       "      <td>-0.084466</td>\n",
       "      <td>-0.083659</td>\n",
       "      <td>-0.083863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-0.016017</td>\n",
       "      <td>-0.026333</td>\n",
       "      <td>-0.021129</td>\n",
       "      <td>-0.024281</td>\n",
       "      <td>-0.021700</td>\n",
       "      <td>-0.022307</td>\n",
       "      <td>-0.020552</td>\n",
       "      <td>-0.021006</td>\n",
       "      <td>-0.020754</td>\n",
       "      <td>-0.020120</td>\n",
       "      <td>...</td>\n",
       "      <td>0.066663</td>\n",
       "      <td>0.065543</td>\n",
       "      <td>0.066852</td>\n",
       "      <td>0.066053</td>\n",
       "      <td>0.066524</td>\n",
       "      <td>0.066080</td>\n",
       "      <td>0.067139</td>\n",
       "      <td>0.065853</td>\n",
       "      <td>0.066451</td>\n",
       "      <td>0.066058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>-0.099989</td>\n",
       "      <td>-0.147183</td>\n",
       "      <td>-0.130584</td>\n",
       "      <td>-0.142348</td>\n",
       "      <td>-0.134741</td>\n",
       "      <td>-0.141679</td>\n",
       "      <td>-0.137096</td>\n",
       "      <td>-0.141694</td>\n",
       "      <td>-0.139006</td>\n",
       "      <td>-0.141943</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.007824</td>\n",
       "      <td>-0.007670</td>\n",
       "      <td>-0.007509</td>\n",
       "      <td>-0.007395</td>\n",
       "      <td>-0.007275</td>\n",
       "      <td>-0.007128</td>\n",
       "      <td>-0.007054</td>\n",
       "      <td>-0.006927</td>\n",
       "      <td>-0.006838</td>\n",
       "      <td>-0.006678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>-0.001973</td>\n",
       "      <td>-0.002743</td>\n",
       "      <td>-0.002420</td>\n",
       "      <td>-0.002587</td>\n",
       "      <td>-0.002480</td>\n",
       "      <td>-0.002982</td>\n",
       "      <td>-0.002981</td>\n",
       "      <td>-0.003135</td>\n",
       "      <td>-0.003078</td>\n",
       "      <td>-0.003289</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.049284</td>\n",
       "      <td>-0.049365</td>\n",
       "      <td>-0.049061</td>\n",
       "      <td>-0.048705</td>\n",
       "      <td>-0.048329</td>\n",
       "      <td>-0.048012</td>\n",
       "      <td>-0.047708</td>\n",
       "      <td>-0.047334</td>\n",
       "      <td>-0.047159</td>\n",
       "      <td>-0.046785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.016221</td>\n",
       "      <td>0.023973</td>\n",
       "      <td>0.021389</td>\n",
       "      <td>0.023493</td>\n",
       "      <td>0.022366</td>\n",
       "      <td>0.023787</td>\n",
       "      <td>0.023385</td>\n",
       "      <td>0.024342</td>\n",
       "      <td>0.023832</td>\n",
       "      <td>0.024507</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.024713</td>\n",
       "      <td>-0.024432</td>\n",
       "      <td>-0.024176</td>\n",
       "      <td>-0.024270</td>\n",
       "      <td>-0.024529</td>\n",
       "      <td>-0.024445</td>\n",
       "      <td>-0.024401</td>\n",
       "      <td>-0.024460</td>\n",
       "      <td>-0.024466</td>\n",
       "      <td>-0.024438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>-0.004840</td>\n",
       "      <td>-0.007136</td>\n",
       "      <td>-0.006261</td>\n",
       "      <td>-0.006881</td>\n",
       "      <td>-0.006451</td>\n",
       "      <td>-0.006893</td>\n",
       "      <td>-0.006494</td>\n",
       "      <td>-0.007021</td>\n",
       "      <td>-0.006695</td>\n",
       "      <td>-0.006755</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.063142</td>\n",
       "      <td>-0.062815</td>\n",
       "      <td>-0.062318</td>\n",
       "      <td>-0.061903</td>\n",
       "      <td>-0.061536</td>\n",
       "      <td>-0.061003</td>\n",
       "      <td>-0.060796</td>\n",
       "      <td>-0.060316</td>\n",
       "      <td>-0.059742</td>\n",
       "      <td>-0.059665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.040397</td>\n",
       "      <td>0.059391</td>\n",
       "      <td>0.052387</td>\n",
       "      <td>0.057065</td>\n",
       "      <td>0.053615</td>\n",
       "      <td>0.055963</td>\n",
       "      <td>0.053940</td>\n",
       "      <td>0.055702</td>\n",
       "      <td>0.054103</td>\n",
       "      <td>0.054922</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.278702</td>\n",
       "      <td>-0.277759</td>\n",
       "      <td>-0.277259</td>\n",
       "      <td>-0.276961</td>\n",
       "      <td>-0.276572</td>\n",
       "      <td>-0.275764</td>\n",
       "      <td>-0.275274</td>\n",
       "      <td>-0.274715</td>\n",
       "      <td>-0.273974</td>\n",
       "      <td>-0.273171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.024171</td>\n",
       "      <td>0.035643</td>\n",
       "      <td>0.031573</td>\n",
       "      <td>0.033944</td>\n",
       "      <td>0.031949</td>\n",
       "      <td>0.033281</td>\n",
       "      <td>0.032176</td>\n",
       "      <td>0.033277</td>\n",
       "      <td>0.032532</td>\n",
       "      <td>0.033085</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.017557</td>\n",
       "      <td>-0.017931</td>\n",
       "      <td>-0.018136</td>\n",
       "      <td>-0.018170</td>\n",
       "      <td>-0.018461</td>\n",
       "      <td>-0.018672</td>\n",
       "      <td>-0.018813</td>\n",
       "      <td>-0.018912</td>\n",
       "      <td>-0.019185</td>\n",
       "      <td>-0.019440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>-0.005271</td>\n",
       "      <td>-0.007909</td>\n",
       "      <td>-0.007128</td>\n",
       "      <td>-0.007691</td>\n",
       "      <td>-0.007283</td>\n",
       "      <td>-0.007654</td>\n",
       "      <td>-0.007364</td>\n",
       "      <td>-0.007667</td>\n",
       "      <td>-0.007545</td>\n",
       "      <td>-0.007722</td>\n",
       "      <td>...</td>\n",
       "      <td>0.036332</td>\n",
       "      <td>0.036274</td>\n",
       "      <td>0.036082</td>\n",
       "      <td>0.035959</td>\n",
       "      <td>0.035752</td>\n",
       "      <td>0.035615</td>\n",
       "      <td>0.035525</td>\n",
       "      <td>0.035464</td>\n",
       "      <td>0.035322</td>\n",
       "      <td>0.035180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.017108</td>\n",
       "      <td>0.025445</td>\n",
       "      <td>0.022881</td>\n",
       "      <td>0.024279</td>\n",
       "      <td>0.022516</td>\n",
       "      <td>0.024372</td>\n",
       "      <td>0.023340</td>\n",
       "      <td>0.023435</td>\n",
       "      <td>0.022920</td>\n",
       "      <td>0.023310</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.039374</td>\n",
       "      <td>-0.039252</td>\n",
       "      <td>-0.039585</td>\n",
       "      <td>-0.039900</td>\n",
       "      <td>-0.039564</td>\n",
       "      <td>-0.039428</td>\n",
       "      <td>-0.039708</td>\n",
       "      <td>-0.039632</td>\n",
       "      <td>-0.040056</td>\n",
       "      <td>-0.040228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>-0.106738</td>\n",
       "      <td>-0.155901</td>\n",
       "      <td>-0.137861</td>\n",
       "      <td>-0.150190</td>\n",
       "      <td>-0.140882</td>\n",
       "      <td>-0.148040</td>\n",
       "      <td>-0.142820</td>\n",
       "      <td>-0.147035</td>\n",
       "      <td>-0.143811</td>\n",
       "      <td>-0.145491</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010547</td>\n",
       "      <td>0.009537</td>\n",
       "      <td>0.008781</td>\n",
       "      <td>0.007943</td>\n",
       "      <td>0.007597</td>\n",
       "      <td>0.007435</td>\n",
       "      <td>0.006635</td>\n",
       "      <td>0.005664</td>\n",
       "      <td>0.005212</td>\n",
       "      <td>0.004562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>-0.010155</td>\n",
       "      <td>-0.012703</td>\n",
       "      <td>-0.008928</td>\n",
       "      <td>-0.008935</td>\n",
       "      <td>-0.007570</td>\n",
       "      <td>-0.008752</td>\n",
       "      <td>-0.009075</td>\n",
       "      <td>-0.010950</td>\n",
       "      <td>-0.012194</td>\n",
       "      <td>-0.013945</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.062928</td>\n",
       "      <td>-0.063807</td>\n",
       "      <td>-0.065390</td>\n",
       "      <td>-0.067298</td>\n",
       "      <td>-0.069424</td>\n",
       "      <td>-0.071679</td>\n",
       "      <td>-0.073628</td>\n",
       "      <td>-0.075368</td>\n",
       "      <td>-0.076868</td>\n",
       "      <td>-0.078313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.000872</td>\n",
       "      <td>0.001421</td>\n",
       "      <td>0.001248</td>\n",
       "      <td>0.001065</td>\n",
       "      <td>0.000723</td>\n",
       "      <td>0.000248</td>\n",
       "      <td>-0.000375</td>\n",
       "      <td>-0.000822</td>\n",
       "      <td>-0.001186</td>\n",
       "      <td>-0.001162</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007126</td>\n",
       "      <td>0.007027</td>\n",
       "      <td>0.007078</td>\n",
       "      <td>0.007034</td>\n",
       "      <td>0.007144</td>\n",
       "      <td>0.007079</td>\n",
       "      <td>0.006922</td>\n",
       "      <td>0.007162</td>\n",
       "      <td>0.007012</td>\n",
       "      <td>0.007001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>-0.029594</td>\n",
       "      <td>-0.043439</td>\n",
       "      <td>-0.038569</td>\n",
       "      <td>-0.041448</td>\n",
       "      <td>-0.039215</td>\n",
       "      <td>-0.041227</td>\n",
       "      <td>-0.040012</td>\n",
       "      <td>-0.041602</td>\n",
       "      <td>-0.040409</td>\n",
       "      <td>-0.041563</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.036923</td>\n",
       "      <td>-0.037202</td>\n",
       "      <td>-0.036895</td>\n",
       "      <td>-0.036869</td>\n",
       "      <td>-0.036627</td>\n",
       "      <td>-0.036918</td>\n",
       "      <td>-0.037273</td>\n",
       "      <td>-0.037111</td>\n",
       "      <td>-0.037501</td>\n",
       "      <td>-0.037352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>-0.085973</td>\n",
       "      <td>-0.126219</td>\n",
       "      <td>-0.111377</td>\n",
       "      <td>-0.120833</td>\n",
       "      <td>-0.114302</td>\n",
       "      <td>-0.120231</td>\n",
       "      <td>-0.115975</td>\n",
       "      <td>-0.119994</td>\n",
       "      <td>-0.117544</td>\n",
       "      <td>-0.119683</td>\n",
       "      <td>...</td>\n",
       "      <td>0.054593</td>\n",
       "      <td>0.054381</td>\n",
       "      <td>0.054319</td>\n",
       "      <td>0.054310</td>\n",
       "      <td>0.054423</td>\n",
       "      <td>0.054689</td>\n",
       "      <td>0.054451</td>\n",
       "      <td>0.054488</td>\n",
       "      <td>0.054470</td>\n",
       "      <td>0.054433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>-0.013644</td>\n",
       "      <td>-0.020002</td>\n",
       "      <td>-0.017502</td>\n",
       "      <td>-0.019051</td>\n",
       "      <td>-0.018019</td>\n",
       "      <td>-0.018869</td>\n",
       "      <td>-0.018058</td>\n",
       "      <td>-0.018735</td>\n",
       "      <td>-0.018426</td>\n",
       "      <td>-0.018764</td>\n",
       "      <td>...</td>\n",
       "      <td>0.111148</td>\n",
       "      <td>0.111371</td>\n",
       "      <td>0.112055</td>\n",
       "      <td>0.112463</td>\n",
       "      <td>0.112968</td>\n",
       "      <td>0.113642</td>\n",
       "      <td>0.114253</td>\n",
       "      <td>0.114758</td>\n",
       "      <td>0.115284</td>\n",
       "      <td>0.116257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>-0.085790</td>\n",
       "      <td>-0.125597</td>\n",
       "      <td>-0.110485</td>\n",
       "      <td>-0.119981</td>\n",
       "      <td>-0.112805</td>\n",
       "      <td>-0.118235</td>\n",
       "      <td>-0.113732</td>\n",
       "      <td>-0.117087</td>\n",
       "      <td>-0.114216</td>\n",
       "      <td>-0.116310</td>\n",
       "      <td>...</td>\n",
       "      <td>0.037431</td>\n",
       "      <td>0.037696</td>\n",
       "      <td>0.037924</td>\n",
       "      <td>0.038186</td>\n",
       "      <td>0.038358</td>\n",
       "      <td>0.038556</td>\n",
       "      <td>0.038800</td>\n",
       "      <td>0.039135</td>\n",
       "      <td>0.039352</td>\n",
       "      <td>0.039520</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35 rows × 173225 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0         1         2         3         4         5         6       \\\n",
       "0   0.002834  0.004234  0.003641  0.003971  0.003700  0.003809  0.003576   \n",
       "1  -0.074944 -0.108564 -0.093635 -0.100122 -0.091679 -0.093961 -0.087420   \n",
       "2   0.031243  0.045788  0.040219  0.043209  0.039028  0.038991  0.034904   \n",
       "3   0.030055  0.043004  0.036623  0.038840  0.035038  0.035900  0.033086   \n",
       "4  -0.058900 -0.084398 -0.071648 -0.076402 -0.070458 -0.074119 -0.071738   \n",
       "5  -0.007034 -0.010403 -0.009126 -0.009703 -0.009150 -0.009540 -0.009445   \n",
       "6   0.008411  0.012138  0.010478  0.011247  0.010533  0.011056  0.010151   \n",
       "7  -0.035490 -0.052700 -0.047214 -0.051584 -0.049264 -0.052077 -0.050764   \n",
       "8  -0.007025 -0.010711 -0.009760 -0.011117 -0.010905 -0.011542 -0.011487   \n",
       "9   0.069494  0.102969  0.091331  0.099595  0.093863  0.098485  0.095500   \n",
       "10 -0.002475 -0.003384 -0.002563 -0.002860 -0.003616 -0.004586 -0.005980   \n",
       "11 -0.081173 -0.119004 -0.104803 -0.113619 -0.107089 -0.112096 -0.107956   \n",
       "12 -0.025988 -0.038236 -0.033611 -0.036232 -0.034116 -0.035283 -0.033953   \n",
       "13 -0.025989 -0.038212 -0.034844 -0.038497 -0.036611 -0.038637 -0.037569   \n",
       "14 -0.011496 -0.017115 -0.015914 -0.017310 -0.016868 -0.017491 -0.017304   \n",
       "15  0.056063  0.081653  0.071722  0.077195  0.072150  0.075371  0.071995   \n",
       "16 -0.023203 -0.034764 -0.030409 -0.032864 -0.031366 -0.032827 -0.031958   \n",
       "17 -0.089683 -0.132175 -0.117259 -0.127997 -0.121205 -0.127644 -0.123680   \n",
       "18 -0.009636 -0.015557 -0.012887 -0.015032 -0.013658 -0.014902 -0.014332   \n",
       "19 -0.016017 -0.026333 -0.021129 -0.024281 -0.021700 -0.022307 -0.020552   \n",
       "20 -0.099989 -0.147183 -0.130584 -0.142348 -0.134741 -0.141679 -0.137096   \n",
       "21 -0.001973 -0.002743 -0.002420 -0.002587 -0.002480 -0.002982 -0.002981   \n",
       "22  0.016221  0.023973  0.021389  0.023493  0.022366  0.023787  0.023385   \n",
       "23 -0.004840 -0.007136 -0.006261 -0.006881 -0.006451 -0.006893 -0.006494   \n",
       "24  0.040397  0.059391  0.052387  0.057065  0.053615  0.055963  0.053940   \n",
       "25  0.024171  0.035643  0.031573  0.033944  0.031949  0.033281  0.032176   \n",
       "26 -0.005271 -0.007909 -0.007128 -0.007691 -0.007283 -0.007654 -0.007364   \n",
       "27  0.017108  0.025445  0.022881  0.024279  0.022516  0.024372  0.023340   \n",
       "28 -0.106738 -0.155901 -0.137861 -0.150190 -0.140882 -0.148040 -0.142820   \n",
       "29 -0.010155 -0.012703 -0.008928 -0.008935 -0.007570 -0.008752 -0.009075   \n",
       "30  0.000872  0.001421  0.001248  0.001065  0.000723  0.000248 -0.000375   \n",
       "31 -0.029594 -0.043439 -0.038569 -0.041448 -0.039215 -0.041227 -0.040012   \n",
       "32 -0.085973 -0.126219 -0.111377 -0.120833 -0.114302 -0.120231 -0.115975   \n",
       "33 -0.013644 -0.020002 -0.017502 -0.019051 -0.018019 -0.018869 -0.018058   \n",
       "34 -0.085790 -0.125597 -0.110485 -0.119981 -0.112805 -0.118235 -0.113732   \n",
       "\n",
       "      7         8         9       ...    173215    173216    173217    173218  \\\n",
       "0   0.003688  0.003570  0.003566  ...  0.008067  0.008140  0.008190  0.008175   \n",
       "1  -0.088095 -0.083677 -0.084414  ...  0.001657  0.001447  0.000820  0.000003   \n",
       "2   0.033426  0.029972  0.028974  ... -0.014146 -0.012259 -0.009135 -0.005213   \n",
       "3   0.033206  0.031031  0.030529  ...  0.089253  0.088449  0.087667  0.086844   \n",
       "4  -0.075175 -0.074700 -0.077834  ... -0.206857 -0.213262 -0.218788 -0.223172   \n",
       "5  -0.009780 -0.009571 -0.009791  ... -0.000319 -0.000152  0.000040  0.000203   \n",
       "6   0.009742  0.009111  0.009042  ... -0.035101 -0.035011 -0.035020 -0.035029   \n",
       "7  -0.052858 -0.052138 -0.053505  ...  0.251070  0.251797  0.252594  0.253096   \n",
       "8  -0.012052 -0.011880 -0.012059  ... -0.043829 -0.043033 -0.042452 -0.042494   \n",
       "9   0.098237  0.096112  0.098258  ... -0.010475 -0.009911 -0.009007 -0.008181   \n",
       "10 -0.007814 -0.009794 -0.011780  ... -0.034290 -0.034048 -0.033800 -0.033792   \n",
       "11 -0.111243 -0.108613 -0.110848  ...  0.034755  0.034469  0.034643  0.034344   \n",
       "12 -0.034721 -0.033415 -0.034382  ...  0.053806  0.054351  0.053982  0.053644   \n",
       "13 -0.039016 -0.037861 -0.038337  ...  0.007106  0.006741  0.006647  0.006201   \n",
       "14 -0.018115 -0.017640 -0.018821  ... -0.006674 -0.006731 -0.007832 -0.006780   \n",
       "15  0.073981  0.071661  0.073230  ... -0.069173 -0.068591 -0.066967 -0.066161   \n",
       "16 -0.032474 -0.032428 -0.033509  ... -0.035067 -0.033222 -0.033415 -0.032224   \n",
       "17 -0.127932 -0.125590 -0.128426  ... -0.008061 -0.007805 -0.007588 -0.007294   \n",
       "18 -0.014974 -0.015067 -0.015134  ... -0.084627 -0.085089 -0.084441 -0.085012   \n",
       "19 -0.021006 -0.020754 -0.020120  ...  0.066663  0.065543  0.066852  0.066053   \n",
       "20 -0.141694 -0.139006 -0.141943  ... -0.007824 -0.007670 -0.007509 -0.007395   \n",
       "21 -0.003135 -0.003078 -0.003289  ... -0.049284 -0.049365 -0.049061 -0.048705   \n",
       "22  0.024342  0.023832  0.024507  ... -0.024713 -0.024432 -0.024176 -0.024270   \n",
       "23 -0.007021 -0.006695 -0.006755  ... -0.063142 -0.062815 -0.062318 -0.061903   \n",
       "24  0.055702  0.054103  0.054922  ... -0.278702 -0.277759 -0.277259 -0.276961   \n",
       "25  0.033277  0.032532  0.033085  ... -0.017557 -0.017931 -0.018136 -0.018170   \n",
       "26 -0.007667 -0.007545 -0.007722  ...  0.036332  0.036274  0.036082  0.035959   \n",
       "27  0.023435  0.022920  0.023310  ... -0.039374 -0.039252 -0.039585 -0.039900   \n",
       "28 -0.147035 -0.143811 -0.145491  ...  0.010547  0.009537  0.008781  0.007943   \n",
       "29 -0.010950 -0.012194 -0.013945  ... -0.062928 -0.063807 -0.065390 -0.067298   \n",
       "30 -0.000822 -0.001186 -0.001162  ...  0.007126  0.007027  0.007078  0.007034   \n",
       "31 -0.041602 -0.040409 -0.041563  ... -0.036923 -0.037202 -0.036895 -0.036869   \n",
       "32 -0.119994 -0.117544 -0.119683  ...  0.054593  0.054381  0.054319  0.054310   \n",
       "33 -0.018735 -0.018426 -0.018764  ...  0.111148  0.111371  0.112055  0.112463   \n",
       "34 -0.117087 -0.114216 -0.116310  ...  0.037431  0.037696  0.037924  0.038186   \n",
       "\n",
       "      173219    173220    173221    173222    173223    173224  \n",
       "0   0.008217  0.008314  0.008320  0.008422  0.008517  0.008680  \n",
       "1  -0.000793 -0.001621 -0.002303 -0.002842 -0.003067 -0.003418  \n",
       "2  -0.000988  0.002983  0.006162  0.008906  0.010976  0.012153  \n",
       "3   0.086066  0.085214  0.084552  0.083685  0.082866  0.082092  \n",
       "4  -0.226421 -0.228739 -0.230270 -0.231345 -0.232212 -0.233467  \n",
       "5   0.000336  0.000413  0.000378  0.000451  0.000369  0.000313  \n",
       "6  -0.035122 -0.034985 -0.034749 -0.033376 -0.033500 -0.033659  \n",
       "7   0.253664  0.254207  0.254856  0.255327  0.256061  0.256631  \n",
       "8  -0.042305 -0.042105 -0.041877 -0.041487 -0.040987 -0.040699  \n",
       "9  -0.007259 -0.006685 -0.005691 -0.004556 -0.003732 -0.003431  \n",
       "10 -0.033129 -0.031824 -0.031523 -0.031697 -0.030978 -0.029946  \n",
       "11  0.034699  0.034943  0.034934  0.035696  0.035977  0.036404  \n",
       "12  0.053071  0.052972  0.052609  0.052387  0.052251  0.051728  \n",
       "13  0.006376  0.006043  0.006107  0.005854  0.005605  0.005888  \n",
       "14 -0.007392 -0.007099 -0.007130 -0.007365 -0.006983 -0.007527  \n",
       "15 -0.065221 -0.063590 -0.062556 -0.061832 -0.060643 -0.059259  \n",
       "16 -0.031335 -0.030069 -0.029755 -0.028809 -0.028174 -0.027388  \n",
       "17 -0.007081 -0.006809 -0.006525 -0.006133 -0.005807 -0.005591  \n",
       "18 -0.083811 -0.084303 -0.083450 -0.084466 -0.083659 -0.083863  \n",
       "19  0.066524  0.066080  0.067139  0.065853  0.066451  0.066058  \n",
       "20 -0.007275 -0.007128 -0.007054 -0.006927 -0.006838 -0.006678  \n",
       "21 -0.048329 -0.048012 -0.047708 -0.047334 -0.047159 -0.046785  \n",
       "22 -0.024529 -0.024445 -0.024401 -0.024460 -0.024466 -0.024438  \n",
       "23 -0.061536 -0.061003 -0.060796 -0.060316 -0.059742 -0.059665  \n",
       "24 -0.276572 -0.275764 -0.275274 -0.274715 -0.273974 -0.273171  \n",
       "25 -0.018461 -0.018672 -0.018813 -0.018912 -0.019185 -0.019440  \n",
       "26  0.035752  0.035615  0.035525  0.035464  0.035322  0.035180  \n",
       "27 -0.039564 -0.039428 -0.039708 -0.039632 -0.040056 -0.040228  \n",
       "28  0.007597  0.007435  0.006635  0.005664  0.005212  0.004562  \n",
       "29 -0.069424 -0.071679 -0.073628 -0.075368 -0.076868 -0.078313  \n",
       "30  0.007144  0.007079  0.006922  0.007162  0.007012  0.007001  \n",
       "31 -0.036627 -0.036918 -0.037273 -0.037111 -0.037501 -0.037352  \n",
       "32  0.054423  0.054689  0.054451  0.054488  0.054470  0.054433  \n",
       "33  0.112968  0.113642  0.114253  0.114758  0.115284  0.116257  \n",
       "34  0.038358  0.038556  0.038800  0.039135  0.039352  0.039520  \n",
       "\n",
       "[35 rows x 173225 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_healthy = df_healthy.transpose()\n",
    "df_healthy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "62187233",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-11T04:37:17.806705Z",
     "start_time": "2023-05-11T04:37:17.747870Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>173215</th>\n",
       "      <th>173216</th>\n",
       "      <th>173217</th>\n",
       "      <th>173218</th>\n",
       "      <th>173219</th>\n",
       "      <th>173220</th>\n",
       "      <th>173221</th>\n",
       "      <th>173222</th>\n",
       "      <th>173223</th>\n",
       "      <th>173224</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.004234</td>\n",
       "      <td>0.003641</td>\n",
       "      <td>0.003971</td>\n",
       "      <td>0.003700</td>\n",
       "      <td>0.003809</td>\n",
       "      <td>0.003576</td>\n",
       "      <td>0.003688</td>\n",
       "      <td>0.003570</td>\n",
       "      <td>0.003566</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008067</td>\n",
       "      <td>0.008140</td>\n",
       "      <td>0.008190</td>\n",
       "      <td>0.008175</td>\n",
       "      <td>0.008217</td>\n",
       "      <td>0.008314</td>\n",
       "      <td>0.008320</td>\n",
       "      <td>0.008422</td>\n",
       "      <td>0.008517</td>\n",
       "      <td>0.008680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.108564</td>\n",
       "      <td>-0.093635</td>\n",
       "      <td>-0.100122</td>\n",
       "      <td>-0.091679</td>\n",
       "      <td>-0.093961</td>\n",
       "      <td>-0.087420</td>\n",
       "      <td>-0.088095</td>\n",
       "      <td>-0.083677</td>\n",
       "      <td>-0.084414</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001657</td>\n",
       "      <td>0.001447</td>\n",
       "      <td>0.000820</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>-0.000793</td>\n",
       "      <td>-0.001621</td>\n",
       "      <td>-0.002303</td>\n",
       "      <td>-0.002842</td>\n",
       "      <td>-0.003067</td>\n",
       "      <td>-0.003418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.045788</td>\n",
       "      <td>0.040219</td>\n",
       "      <td>0.043209</td>\n",
       "      <td>0.039028</td>\n",
       "      <td>0.038991</td>\n",
       "      <td>0.034904</td>\n",
       "      <td>0.033426</td>\n",
       "      <td>0.029972</td>\n",
       "      <td>0.028974</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.014146</td>\n",
       "      <td>-0.012259</td>\n",
       "      <td>-0.009135</td>\n",
       "      <td>-0.005213</td>\n",
       "      <td>-0.000988</td>\n",
       "      <td>0.002983</td>\n",
       "      <td>0.006162</td>\n",
       "      <td>0.008906</td>\n",
       "      <td>0.010976</td>\n",
       "      <td>0.012153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.043004</td>\n",
       "      <td>0.036623</td>\n",
       "      <td>0.038840</td>\n",
       "      <td>0.035038</td>\n",
       "      <td>0.035900</td>\n",
       "      <td>0.033086</td>\n",
       "      <td>0.033206</td>\n",
       "      <td>0.031031</td>\n",
       "      <td>0.030529</td>\n",
       "      <td>...</td>\n",
       "      <td>0.089253</td>\n",
       "      <td>0.088449</td>\n",
       "      <td>0.087667</td>\n",
       "      <td>0.086844</td>\n",
       "      <td>0.086066</td>\n",
       "      <td>0.085214</td>\n",
       "      <td>0.084552</td>\n",
       "      <td>0.083685</td>\n",
       "      <td>0.082866</td>\n",
       "      <td>0.082092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.084398</td>\n",
       "      <td>-0.071648</td>\n",
       "      <td>-0.076402</td>\n",
       "      <td>-0.070458</td>\n",
       "      <td>-0.074119</td>\n",
       "      <td>-0.071738</td>\n",
       "      <td>-0.075175</td>\n",
       "      <td>-0.074700</td>\n",
       "      <td>-0.077834</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.206857</td>\n",
       "      <td>-0.213262</td>\n",
       "      <td>-0.218788</td>\n",
       "      <td>-0.223172</td>\n",
       "      <td>-0.226421</td>\n",
       "      <td>-0.228739</td>\n",
       "      <td>-0.230270</td>\n",
       "      <td>-0.231345</td>\n",
       "      <td>-0.232212</td>\n",
       "      <td>-0.233467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.010403</td>\n",
       "      <td>-0.009126</td>\n",
       "      <td>-0.009703</td>\n",
       "      <td>-0.009150</td>\n",
       "      <td>-0.009540</td>\n",
       "      <td>-0.009445</td>\n",
       "      <td>-0.009780</td>\n",
       "      <td>-0.009571</td>\n",
       "      <td>-0.009791</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000319</td>\n",
       "      <td>-0.000152</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.000203</td>\n",
       "      <td>0.000336</td>\n",
       "      <td>0.000413</td>\n",
       "      <td>0.000378</td>\n",
       "      <td>0.000451</td>\n",
       "      <td>0.000369</td>\n",
       "      <td>0.000313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0.012138</td>\n",
       "      <td>0.010478</td>\n",
       "      <td>0.011247</td>\n",
       "      <td>0.010533</td>\n",
       "      <td>0.011056</td>\n",
       "      <td>0.010151</td>\n",
       "      <td>0.009742</td>\n",
       "      <td>0.009111</td>\n",
       "      <td>0.009042</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.035101</td>\n",
       "      <td>-0.035011</td>\n",
       "      <td>-0.035020</td>\n",
       "      <td>-0.035029</td>\n",
       "      <td>-0.035122</td>\n",
       "      <td>-0.034985</td>\n",
       "      <td>-0.034749</td>\n",
       "      <td>-0.033376</td>\n",
       "      <td>-0.033500</td>\n",
       "      <td>-0.033659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.052700</td>\n",
       "      <td>-0.047214</td>\n",
       "      <td>-0.051584</td>\n",
       "      <td>-0.049264</td>\n",
       "      <td>-0.052077</td>\n",
       "      <td>-0.050764</td>\n",
       "      <td>-0.052858</td>\n",
       "      <td>-0.052138</td>\n",
       "      <td>-0.053505</td>\n",
       "      <td>...</td>\n",
       "      <td>0.251070</td>\n",
       "      <td>0.251797</td>\n",
       "      <td>0.252594</td>\n",
       "      <td>0.253096</td>\n",
       "      <td>0.253664</td>\n",
       "      <td>0.254207</td>\n",
       "      <td>0.254856</td>\n",
       "      <td>0.255327</td>\n",
       "      <td>0.256061</td>\n",
       "      <td>0.256631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.010711</td>\n",
       "      <td>-0.009760</td>\n",
       "      <td>-0.011117</td>\n",
       "      <td>-0.010905</td>\n",
       "      <td>-0.011542</td>\n",
       "      <td>-0.011487</td>\n",
       "      <td>-0.012052</td>\n",
       "      <td>-0.011880</td>\n",
       "      <td>-0.012059</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.043829</td>\n",
       "      <td>-0.043033</td>\n",
       "      <td>-0.042452</td>\n",
       "      <td>-0.042494</td>\n",
       "      <td>-0.042305</td>\n",
       "      <td>-0.042105</td>\n",
       "      <td>-0.041877</td>\n",
       "      <td>-0.041487</td>\n",
       "      <td>-0.040987</td>\n",
       "      <td>-0.040699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0.102969</td>\n",
       "      <td>0.091331</td>\n",
       "      <td>0.099595</td>\n",
       "      <td>0.093863</td>\n",
       "      <td>0.098485</td>\n",
       "      <td>0.095500</td>\n",
       "      <td>0.098237</td>\n",
       "      <td>0.096112</td>\n",
       "      <td>0.098258</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.010475</td>\n",
       "      <td>-0.009911</td>\n",
       "      <td>-0.009007</td>\n",
       "      <td>-0.008181</td>\n",
       "      <td>-0.007259</td>\n",
       "      <td>-0.006685</td>\n",
       "      <td>-0.005691</td>\n",
       "      <td>-0.004556</td>\n",
       "      <td>-0.003732</td>\n",
       "      <td>-0.003431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.003384</td>\n",
       "      <td>-0.002563</td>\n",
       "      <td>-0.002860</td>\n",
       "      <td>-0.003616</td>\n",
       "      <td>-0.004586</td>\n",
       "      <td>-0.005980</td>\n",
       "      <td>-0.007814</td>\n",
       "      <td>-0.009794</td>\n",
       "      <td>-0.011780</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.034290</td>\n",
       "      <td>-0.034048</td>\n",
       "      <td>-0.033800</td>\n",
       "      <td>-0.033792</td>\n",
       "      <td>-0.033129</td>\n",
       "      <td>-0.031824</td>\n",
       "      <td>-0.031523</td>\n",
       "      <td>-0.031697</td>\n",
       "      <td>-0.030978</td>\n",
       "      <td>-0.029946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.119004</td>\n",
       "      <td>-0.104803</td>\n",
       "      <td>-0.113619</td>\n",
       "      <td>-0.107089</td>\n",
       "      <td>-0.112096</td>\n",
       "      <td>-0.107956</td>\n",
       "      <td>-0.111243</td>\n",
       "      <td>-0.108613</td>\n",
       "      <td>-0.110848</td>\n",
       "      <td>...</td>\n",
       "      <td>0.034755</td>\n",
       "      <td>0.034469</td>\n",
       "      <td>0.034643</td>\n",
       "      <td>0.034344</td>\n",
       "      <td>0.034699</td>\n",
       "      <td>0.034943</td>\n",
       "      <td>0.034934</td>\n",
       "      <td>0.035696</td>\n",
       "      <td>0.035977</td>\n",
       "      <td>0.036404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.038236</td>\n",
       "      <td>-0.033611</td>\n",
       "      <td>-0.036232</td>\n",
       "      <td>-0.034116</td>\n",
       "      <td>-0.035283</td>\n",
       "      <td>-0.033953</td>\n",
       "      <td>-0.034721</td>\n",
       "      <td>-0.033415</td>\n",
       "      <td>-0.034382</td>\n",
       "      <td>...</td>\n",
       "      <td>0.053806</td>\n",
       "      <td>0.054351</td>\n",
       "      <td>0.053982</td>\n",
       "      <td>0.053644</td>\n",
       "      <td>0.053071</td>\n",
       "      <td>0.052972</td>\n",
       "      <td>0.052609</td>\n",
       "      <td>0.052387</td>\n",
       "      <td>0.052251</td>\n",
       "      <td>0.051728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.038212</td>\n",
       "      <td>-0.034844</td>\n",
       "      <td>-0.038497</td>\n",
       "      <td>-0.036611</td>\n",
       "      <td>-0.038637</td>\n",
       "      <td>-0.037569</td>\n",
       "      <td>-0.039016</td>\n",
       "      <td>-0.037861</td>\n",
       "      <td>-0.038337</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007106</td>\n",
       "      <td>0.006741</td>\n",
       "      <td>0.006647</td>\n",
       "      <td>0.006201</td>\n",
       "      <td>0.006376</td>\n",
       "      <td>0.006043</td>\n",
       "      <td>0.006107</td>\n",
       "      <td>0.005854</td>\n",
       "      <td>0.005605</td>\n",
       "      <td>0.005888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.017115</td>\n",
       "      <td>-0.015914</td>\n",
       "      <td>-0.017310</td>\n",
       "      <td>-0.016868</td>\n",
       "      <td>-0.017491</td>\n",
       "      <td>-0.017304</td>\n",
       "      <td>-0.018115</td>\n",
       "      <td>-0.017640</td>\n",
       "      <td>-0.018821</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.006674</td>\n",
       "      <td>-0.006731</td>\n",
       "      <td>-0.007832</td>\n",
       "      <td>-0.006780</td>\n",
       "      <td>-0.007392</td>\n",
       "      <td>-0.007099</td>\n",
       "      <td>-0.007130</td>\n",
       "      <td>-0.007365</td>\n",
       "      <td>-0.006983</td>\n",
       "      <td>-0.007527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>0.081653</td>\n",
       "      <td>0.071722</td>\n",
       "      <td>0.077195</td>\n",
       "      <td>0.072150</td>\n",
       "      <td>0.075371</td>\n",
       "      <td>0.071995</td>\n",
       "      <td>0.073981</td>\n",
       "      <td>0.071661</td>\n",
       "      <td>0.073230</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.069173</td>\n",
       "      <td>-0.068591</td>\n",
       "      <td>-0.066967</td>\n",
       "      <td>-0.066161</td>\n",
       "      <td>-0.065221</td>\n",
       "      <td>-0.063590</td>\n",
       "      <td>-0.062556</td>\n",
       "      <td>-0.061832</td>\n",
       "      <td>-0.060643</td>\n",
       "      <td>-0.059259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.034764</td>\n",
       "      <td>-0.030409</td>\n",
       "      <td>-0.032864</td>\n",
       "      <td>-0.031366</td>\n",
       "      <td>-0.032827</td>\n",
       "      <td>-0.031958</td>\n",
       "      <td>-0.032474</td>\n",
       "      <td>-0.032428</td>\n",
       "      <td>-0.033509</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.035067</td>\n",
       "      <td>-0.033222</td>\n",
       "      <td>-0.033415</td>\n",
       "      <td>-0.032224</td>\n",
       "      <td>-0.031335</td>\n",
       "      <td>-0.030069</td>\n",
       "      <td>-0.029755</td>\n",
       "      <td>-0.028809</td>\n",
       "      <td>-0.028174</td>\n",
       "      <td>-0.027388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.132175</td>\n",
       "      <td>-0.117259</td>\n",
       "      <td>-0.127997</td>\n",
       "      <td>-0.121205</td>\n",
       "      <td>-0.127644</td>\n",
       "      <td>-0.123680</td>\n",
       "      <td>-0.127932</td>\n",
       "      <td>-0.125590</td>\n",
       "      <td>-0.128426</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.008061</td>\n",
       "      <td>-0.007805</td>\n",
       "      <td>-0.007588</td>\n",
       "      <td>-0.007294</td>\n",
       "      <td>-0.007081</td>\n",
       "      <td>-0.006809</td>\n",
       "      <td>-0.006525</td>\n",
       "      <td>-0.006133</td>\n",
       "      <td>-0.005807</td>\n",
       "      <td>-0.005591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.015557</td>\n",
       "      <td>-0.012887</td>\n",
       "      <td>-0.015032</td>\n",
       "      <td>-0.013658</td>\n",
       "      <td>-0.014902</td>\n",
       "      <td>-0.014332</td>\n",
       "      <td>-0.014974</td>\n",
       "      <td>-0.015067</td>\n",
       "      <td>-0.015134</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.084627</td>\n",
       "      <td>-0.085089</td>\n",
       "      <td>-0.084441</td>\n",
       "      <td>-0.085012</td>\n",
       "      <td>-0.083811</td>\n",
       "      <td>-0.084303</td>\n",
       "      <td>-0.083450</td>\n",
       "      <td>-0.084466</td>\n",
       "      <td>-0.083659</td>\n",
       "      <td>-0.083863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.026333</td>\n",
       "      <td>-0.021129</td>\n",
       "      <td>-0.024281</td>\n",
       "      <td>-0.021700</td>\n",
       "      <td>-0.022307</td>\n",
       "      <td>-0.020552</td>\n",
       "      <td>-0.021006</td>\n",
       "      <td>-0.020754</td>\n",
       "      <td>-0.020120</td>\n",
       "      <td>...</td>\n",
       "      <td>0.066663</td>\n",
       "      <td>0.065543</td>\n",
       "      <td>0.066852</td>\n",
       "      <td>0.066053</td>\n",
       "      <td>0.066524</td>\n",
       "      <td>0.066080</td>\n",
       "      <td>0.067139</td>\n",
       "      <td>0.065853</td>\n",
       "      <td>0.066451</td>\n",
       "      <td>0.066058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.147183</td>\n",
       "      <td>-0.130584</td>\n",
       "      <td>-0.142348</td>\n",
       "      <td>-0.134741</td>\n",
       "      <td>-0.141679</td>\n",
       "      <td>-0.137096</td>\n",
       "      <td>-0.141694</td>\n",
       "      <td>-0.139006</td>\n",
       "      <td>-0.141943</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.007824</td>\n",
       "      <td>-0.007670</td>\n",
       "      <td>-0.007509</td>\n",
       "      <td>-0.007395</td>\n",
       "      <td>-0.007275</td>\n",
       "      <td>-0.007128</td>\n",
       "      <td>-0.007054</td>\n",
       "      <td>-0.006927</td>\n",
       "      <td>-0.006838</td>\n",
       "      <td>-0.006678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.002743</td>\n",
       "      <td>-0.002420</td>\n",
       "      <td>-0.002587</td>\n",
       "      <td>-0.002480</td>\n",
       "      <td>-0.002982</td>\n",
       "      <td>-0.002981</td>\n",
       "      <td>-0.003135</td>\n",
       "      <td>-0.003078</td>\n",
       "      <td>-0.003289</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.049284</td>\n",
       "      <td>-0.049365</td>\n",
       "      <td>-0.049061</td>\n",
       "      <td>-0.048705</td>\n",
       "      <td>-0.048329</td>\n",
       "      <td>-0.048012</td>\n",
       "      <td>-0.047708</td>\n",
       "      <td>-0.047334</td>\n",
       "      <td>-0.047159</td>\n",
       "      <td>-0.046785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0</td>\n",
       "      <td>0.023973</td>\n",
       "      <td>0.021389</td>\n",
       "      <td>0.023493</td>\n",
       "      <td>0.022366</td>\n",
       "      <td>0.023787</td>\n",
       "      <td>0.023385</td>\n",
       "      <td>0.024342</td>\n",
       "      <td>0.023832</td>\n",
       "      <td>0.024507</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.024713</td>\n",
       "      <td>-0.024432</td>\n",
       "      <td>-0.024176</td>\n",
       "      <td>-0.024270</td>\n",
       "      <td>-0.024529</td>\n",
       "      <td>-0.024445</td>\n",
       "      <td>-0.024401</td>\n",
       "      <td>-0.024460</td>\n",
       "      <td>-0.024466</td>\n",
       "      <td>-0.024438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.007136</td>\n",
       "      <td>-0.006261</td>\n",
       "      <td>-0.006881</td>\n",
       "      <td>-0.006451</td>\n",
       "      <td>-0.006893</td>\n",
       "      <td>-0.006494</td>\n",
       "      <td>-0.007021</td>\n",
       "      <td>-0.006695</td>\n",
       "      <td>-0.006755</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.063142</td>\n",
       "      <td>-0.062815</td>\n",
       "      <td>-0.062318</td>\n",
       "      <td>-0.061903</td>\n",
       "      <td>-0.061536</td>\n",
       "      <td>-0.061003</td>\n",
       "      <td>-0.060796</td>\n",
       "      <td>-0.060316</td>\n",
       "      <td>-0.059742</td>\n",
       "      <td>-0.059665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "      <td>0.059391</td>\n",
       "      <td>0.052387</td>\n",
       "      <td>0.057065</td>\n",
       "      <td>0.053615</td>\n",
       "      <td>0.055963</td>\n",
       "      <td>0.053940</td>\n",
       "      <td>0.055702</td>\n",
       "      <td>0.054103</td>\n",
       "      <td>0.054922</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.278702</td>\n",
       "      <td>-0.277759</td>\n",
       "      <td>-0.277259</td>\n",
       "      <td>-0.276961</td>\n",
       "      <td>-0.276572</td>\n",
       "      <td>-0.275764</td>\n",
       "      <td>-0.275274</td>\n",
       "      <td>-0.274715</td>\n",
       "      <td>-0.273974</td>\n",
       "      <td>-0.273171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0</td>\n",
       "      <td>0.035643</td>\n",
       "      <td>0.031573</td>\n",
       "      <td>0.033944</td>\n",
       "      <td>0.031949</td>\n",
       "      <td>0.033281</td>\n",
       "      <td>0.032176</td>\n",
       "      <td>0.033277</td>\n",
       "      <td>0.032532</td>\n",
       "      <td>0.033085</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.017557</td>\n",
       "      <td>-0.017931</td>\n",
       "      <td>-0.018136</td>\n",
       "      <td>-0.018170</td>\n",
       "      <td>-0.018461</td>\n",
       "      <td>-0.018672</td>\n",
       "      <td>-0.018813</td>\n",
       "      <td>-0.018912</td>\n",
       "      <td>-0.019185</td>\n",
       "      <td>-0.019440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.007909</td>\n",
       "      <td>-0.007128</td>\n",
       "      <td>-0.007691</td>\n",
       "      <td>-0.007283</td>\n",
       "      <td>-0.007654</td>\n",
       "      <td>-0.007364</td>\n",
       "      <td>-0.007667</td>\n",
       "      <td>-0.007545</td>\n",
       "      <td>-0.007722</td>\n",
       "      <td>...</td>\n",
       "      <td>0.036332</td>\n",
       "      <td>0.036274</td>\n",
       "      <td>0.036082</td>\n",
       "      <td>0.035959</td>\n",
       "      <td>0.035752</td>\n",
       "      <td>0.035615</td>\n",
       "      <td>0.035525</td>\n",
       "      <td>0.035464</td>\n",
       "      <td>0.035322</td>\n",
       "      <td>0.035180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0</td>\n",
       "      <td>0.025445</td>\n",
       "      <td>0.022881</td>\n",
       "      <td>0.024279</td>\n",
       "      <td>0.022516</td>\n",
       "      <td>0.024372</td>\n",
       "      <td>0.023340</td>\n",
       "      <td>0.023435</td>\n",
       "      <td>0.022920</td>\n",
       "      <td>0.023310</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.039374</td>\n",
       "      <td>-0.039252</td>\n",
       "      <td>-0.039585</td>\n",
       "      <td>-0.039900</td>\n",
       "      <td>-0.039564</td>\n",
       "      <td>-0.039428</td>\n",
       "      <td>-0.039708</td>\n",
       "      <td>-0.039632</td>\n",
       "      <td>-0.040056</td>\n",
       "      <td>-0.040228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.155901</td>\n",
       "      <td>-0.137861</td>\n",
       "      <td>-0.150190</td>\n",
       "      <td>-0.140882</td>\n",
       "      <td>-0.148040</td>\n",
       "      <td>-0.142820</td>\n",
       "      <td>-0.147035</td>\n",
       "      <td>-0.143811</td>\n",
       "      <td>-0.145491</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010547</td>\n",
       "      <td>0.009537</td>\n",
       "      <td>0.008781</td>\n",
       "      <td>0.007943</td>\n",
       "      <td>0.007597</td>\n",
       "      <td>0.007435</td>\n",
       "      <td>0.006635</td>\n",
       "      <td>0.005664</td>\n",
       "      <td>0.005212</td>\n",
       "      <td>0.004562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.012703</td>\n",
       "      <td>-0.008928</td>\n",
       "      <td>-0.008935</td>\n",
       "      <td>-0.007570</td>\n",
       "      <td>-0.008752</td>\n",
       "      <td>-0.009075</td>\n",
       "      <td>-0.010950</td>\n",
       "      <td>-0.012194</td>\n",
       "      <td>-0.013945</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.062928</td>\n",
       "      <td>-0.063807</td>\n",
       "      <td>-0.065390</td>\n",
       "      <td>-0.067298</td>\n",
       "      <td>-0.069424</td>\n",
       "      <td>-0.071679</td>\n",
       "      <td>-0.073628</td>\n",
       "      <td>-0.075368</td>\n",
       "      <td>-0.076868</td>\n",
       "      <td>-0.078313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0</td>\n",
       "      <td>0.001421</td>\n",
       "      <td>0.001248</td>\n",
       "      <td>0.001065</td>\n",
       "      <td>0.000723</td>\n",
       "      <td>0.000248</td>\n",
       "      <td>-0.000375</td>\n",
       "      <td>-0.000822</td>\n",
       "      <td>-0.001186</td>\n",
       "      <td>-0.001162</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007126</td>\n",
       "      <td>0.007027</td>\n",
       "      <td>0.007078</td>\n",
       "      <td>0.007034</td>\n",
       "      <td>0.007144</td>\n",
       "      <td>0.007079</td>\n",
       "      <td>0.006922</td>\n",
       "      <td>0.007162</td>\n",
       "      <td>0.007012</td>\n",
       "      <td>0.007001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.043439</td>\n",
       "      <td>-0.038569</td>\n",
       "      <td>-0.041448</td>\n",
       "      <td>-0.039215</td>\n",
       "      <td>-0.041227</td>\n",
       "      <td>-0.040012</td>\n",
       "      <td>-0.041602</td>\n",
       "      <td>-0.040409</td>\n",
       "      <td>-0.041563</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.036923</td>\n",
       "      <td>-0.037202</td>\n",
       "      <td>-0.036895</td>\n",
       "      <td>-0.036869</td>\n",
       "      <td>-0.036627</td>\n",
       "      <td>-0.036918</td>\n",
       "      <td>-0.037273</td>\n",
       "      <td>-0.037111</td>\n",
       "      <td>-0.037501</td>\n",
       "      <td>-0.037352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.126219</td>\n",
       "      <td>-0.111377</td>\n",
       "      <td>-0.120833</td>\n",
       "      <td>-0.114302</td>\n",
       "      <td>-0.120231</td>\n",
       "      <td>-0.115975</td>\n",
       "      <td>-0.119994</td>\n",
       "      <td>-0.117544</td>\n",
       "      <td>-0.119683</td>\n",
       "      <td>...</td>\n",
       "      <td>0.054593</td>\n",
       "      <td>0.054381</td>\n",
       "      <td>0.054319</td>\n",
       "      <td>0.054310</td>\n",
       "      <td>0.054423</td>\n",
       "      <td>0.054689</td>\n",
       "      <td>0.054451</td>\n",
       "      <td>0.054488</td>\n",
       "      <td>0.054470</td>\n",
       "      <td>0.054433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.020002</td>\n",
       "      <td>-0.017502</td>\n",
       "      <td>-0.019051</td>\n",
       "      <td>-0.018019</td>\n",
       "      <td>-0.018869</td>\n",
       "      <td>-0.018058</td>\n",
       "      <td>-0.018735</td>\n",
       "      <td>-0.018426</td>\n",
       "      <td>-0.018764</td>\n",
       "      <td>...</td>\n",
       "      <td>0.111148</td>\n",
       "      <td>0.111371</td>\n",
       "      <td>0.112055</td>\n",
       "      <td>0.112463</td>\n",
       "      <td>0.112968</td>\n",
       "      <td>0.113642</td>\n",
       "      <td>0.114253</td>\n",
       "      <td>0.114758</td>\n",
       "      <td>0.115284</td>\n",
       "      <td>0.116257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.125597</td>\n",
       "      <td>-0.110485</td>\n",
       "      <td>-0.119981</td>\n",
       "      <td>-0.112805</td>\n",
       "      <td>-0.118235</td>\n",
       "      <td>-0.113732</td>\n",
       "      <td>-0.117087</td>\n",
       "      <td>-0.114216</td>\n",
       "      <td>-0.116310</td>\n",
       "      <td>...</td>\n",
       "      <td>0.037431</td>\n",
       "      <td>0.037696</td>\n",
       "      <td>0.037924</td>\n",
       "      <td>0.038186</td>\n",
       "      <td>0.038358</td>\n",
       "      <td>0.038556</td>\n",
       "      <td>0.038800</td>\n",
       "      <td>0.039135</td>\n",
       "      <td>0.039352</td>\n",
       "      <td>0.039520</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35 rows × 173225 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    label         1         2         3         4         5         6  \\\n",
       "0       0  0.004234  0.003641  0.003971  0.003700  0.003809  0.003576   \n",
       "1       0 -0.108564 -0.093635 -0.100122 -0.091679 -0.093961 -0.087420   \n",
       "2       0  0.045788  0.040219  0.043209  0.039028  0.038991  0.034904   \n",
       "3       0  0.043004  0.036623  0.038840  0.035038  0.035900  0.033086   \n",
       "4       0 -0.084398 -0.071648 -0.076402 -0.070458 -0.074119 -0.071738   \n",
       "5       0 -0.010403 -0.009126 -0.009703 -0.009150 -0.009540 -0.009445   \n",
       "6       0  0.012138  0.010478  0.011247  0.010533  0.011056  0.010151   \n",
       "7       0 -0.052700 -0.047214 -0.051584 -0.049264 -0.052077 -0.050764   \n",
       "8       0 -0.010711 -0.009760 -0.011117 -0.010905 -0.011542 -0.011487   \n",
       "9       0  0.102969  0.091331  0.099595  0.093863  0.098485  0.095500   \n",
       "10      0 -0.003384 -0.002563 -0.002860 -0.003616 -0.004586 -0.005980   \n",
       "11      0 -0.119004 -0.104803 -0.113619 -0.107089 -0.112096 -0.107956   \n",
       "12      0 -0.038236 -0.033611 -0.036232 -0.034116 -0.035283 -0.033953   \n",
       "13      0 -0.038212 -0.034844 -0.038497 -0.036611 -0.038637 -0.037569   \n",
       "14      0 -0.017115 -0.015914 -0.017310 -0.016868 -0.017491 -0.017304   \n",
       "15      0  0.081653  0.071722  0.077195  0.072150  0.075371  0.071995   \n",
       "16      0 -0.034764 -0.030409 -0.032864 -0.031366 -0.032827 -0.031958   \n",
       "17      0 -0.132175 -0.117259 -0.127997 -0.121205 -0.127644 -0.123680   \n",
       "18      0 -0.015557 -0.012887 -0.015032 -0.013658 -0.014902 -0.014332   \n",
       "19      0 -0.026333 -0.021129 -0.024281 -0.021700 -0.022307 -0.020552   \n",
       "20      0 -0.147183 -0.130584 -0.142348 -0.134741 -0.141679 -0.137096   \n",
       "21      0 -0.002743 -0.002420 -0.002587 -0.002480 -0.002982 -0.002981   \n",
       "22      0  0.023973  0.021389  0.023493  0.022366  0.023787  0.023385   \n",
       "23      0 -0.007136 -0.006261 -0.006881 -0.006451 -0.006893 -0.006494   \n",
       "24      0  0.059391  0.052387  0.057065  0.053615  0.055963  0.053940   \n",
       "25      0  0.035643  0.031573  0.033944  0.031949  0.033281  0.032176   \n",
       "26      0 -0.007909 -0.007128 -0.007691 -0.007283 -0.007654 -0.007364   \n",
       "27      0  0.025445  0.022881  0.024279  0.022516  0.024372  0.023340   \n",
       "28      0 -0.155901 -0.137861 -0.150190 -0.140882 -0.148040 -0.142820   \n",
       "29      0 -0.012703 -0.008928 -0.008935 -0.007570 -0.008752 -0.009075   \n",
       "30      0  0.001421  0.001248  0.001065  0.000723  0.000248 -0.000375   \n",
       "31      0 -0.043439 -0.038569 -0.041448 -0.039215 -0.041227 -0.040012   \n",
       "32      0 -0.126219 -0.111377 -0.120833 -0.114302 -0.120231 -0.115975   \n",
       "33      0 -0.020002 -0.017502 -0.019051 -0.018019 -0.018869 -0.018058   \n",
       "34      0 -0.125597 -0.110485 -0.119981 -0.112805 -0.118235 -0.113732   \n",
       "\n",
       "           7         8         9  ...    173215    173216    173217    173218  \\\n",
       "0   0.003688  0.003570  0.003566  ...  0.008067  0.008140  0.008190  0.008175   \n",
       "1  -0.088095 -0.083677 -0.084414  ...  0.001657  0.001447  0.000820  0.000003   \n",
       "2   0.033426  0.029972  0.028974  ... -0.014146 -0.012259 -0.009135 -0.005213   \n",
       "3   0.033206  0.031031  0.030529  ...  0.089253  0.088449  0.087667  0.086844   \n",
       "4  -0.075175 -0.074700 -0.077834  ... -0.206857 -0.213262 -0.218788 -0.223172   \n",
       "5  -0.009780 -0.009571 -0.009791  ... -0.000319 -0.000152  0.000040  0.000203   \n",
       "6   0.009742  0.009111  0.009042  ... -0.035101 -0.035011 -0.035020 -0.035029   \n",
       "7  -0.052858 -0.052138 -0.053505  ...  0.251070  0.251797  0.252594  0.253096   \n",
       "8  -0.012052 -0.011880 -0.012059  ... -0.043829 -0.043033 -0.042452 -0.042494   \n",
       "9   0.098237  0.096112  0.098258  ... -0.010475 -0.009911 -0.009007 -0.008181   \n",
       "10 -0.007814 -0.009794 -0.011780  ... -0.034290 -0.034048 -0.033800 -0.033792   \n",
       "11 -0.111243 -0.108613 -0.110848  ...  0.034755  0.034469  0.034643  0.034344   \n",
       "12 -0.034721 -0.033415 -0.034382  ...  0.053806  0.054351  0.053982  0.053644   \n",
       "13 -0.039016 -0.037861 -0.038337  ...  0.007106  0.006741  0.006647  0.006201   \n",
       "14 -0.018115 -0.017640 -0.018821  ... -0.006674 -0.006731 -0.007832 -0.006780   \n",
       "15  0.073981  0.071661  0.073230  ... -0.069173 -0.068591 -0.066967 -0.066161   \n",
       "16 -0.032474 -0.032428 -0.033509  ... -0.035067 -0.033222 -0.033415 -0.032224   \n",
       "17 -0.127932 -0.125590 -0.128426  ... -0.008061 -0.007805 -0.007588 -0.007294   \n",
       "18 -0.014974 -0.015067 -0.015134  ... -0.084627 -0.085089 -0.084441 -0.085012   \n",
       "19 -0.021006 -0.020754 -0.020120  ...  0.066663  0.065543  0.066852  0.066053   \n",
       "20 -0.141694 -0.139006 -0.141943  ... -0.007824 -0.007670 -0.007509 -0.007395   \n",
       "21 -0.003135 -0.003078 -0.003289  ... -0.049284 -0.049365 -0.049061 -0.048705   \n",
       "22  0.024342  0.023832  0.024507  ... -0.024713 -0.024432 -0.024176 -0.024270   \n",
       "23 -0.007021 -0.006695 -0.006755  ... -0.063142 -0.062815 -0.062318 -0.061903   \n",
       "24  0.055702  0.054103  0.054922  ... -0.278702 -0.277759 -0.277259 -0.276961   \n",
       "25  0.033277  0.032532  0.033085  ... -0.017557 -0.017931 -0.018136 -0.018170   \n",
       "26 -0.007667 -0.007545 -0.007722  ...  0.036332  0.036274  0.036082  0.035959   \n",
       "27  0.023435  0.022920  0.023310  ... -0.039374 -0.039252 -0.039585 -0.039900   \n",
       "28 -0.147035 -0.143811 -0.145491  ...  0.010547  0.009537  0.008781  0.007943   \n",
       "29 -0.010950 -0.012194 -0.013945  ... -0.062928 -0.063807 -0.065390 -0.067298   \n",
       "30 -0.000822 -0.001186 -0.001162  ...  0.007126  0.007027  0.007078  0.007034   \n",
       "31 -0.041602 -0.040409 -0.041563  ... -0.036923 -0.037202 -0.036895 -0.036869   \n",
       "32 -0.119994 -0.117544 -0.119683  ...  0.054593  0.054381  0.054319  0.054310   \n",
       "33 -0.018735 -0.018426 -0.018764  ...  0.111148  0.111371  0.112055  0.112463   \n",
       "34 -0.117087 -0.114216 -0.116310  ...  0.037431  0.037696  0.037924  0.038186   \n",
       "\n",
       "      173219    173220    173221    173222    173223    173224  \n",
       "0   0.008217  0.008314  0.008320  0.008422  0.008517  0.008680  \n",
       "1  -0.000793 -0.001621 -0.002303 -0.002842 -0.003067 -0.003418  \n",
       "2  -0.000988  0.002983  0.006162  0.008906  0.010976  0.012153  \n",
       "3   0.086066  0.085214  0.084552  0.083685  0.082866  0.082092  \n",
       "4  -0.226421 -0.228739 -0.230270 -0.231345 -0.232212 -0.233467  \n",
       "5   0.000336  0.000413  0.000378  0.000451  0.000369  0.000313  \n",
       "6  -0.035122 -0.034985 -0.034749 -0.033376 -0.033500 -0.033659  \n",
       "7   0.253664  0.254207  0.254856  0.255327  0.256061  0.256631  \n",
       "8  -0.042305 -0.042105 -0.041877 -0.041487 -0.040987 -0.040699  \n",
       "9  -0.007259 -0.006685 -0.005691 -0.004556 -0.003732 -0.003431  \n",
       "10 -0.033129 -0.031824 -0.031523 -0.031697 -0.030978 -0.029946  \n",
       "11  0.034699  0.034943  0.034934  0.035696  0.035977  0.036404  \n",
       "12  0.053071  0.052972  0.052609  0.052387  0.052251  0.051728  \n",
       "13  0.006376  0.006043  0.006107  0.005854  0.005605  0.005888  \n",
       "14 -0.007392 -0.007099 -0.007130 -0.007365 -0.006983 -0.007527  \n",
       "15 -0.065221 -0.063590 -0.062556 -0.061832 -0.060643 -0.059259  \n",
       "16 -0.031335 -0.030069 -0.029755 -0.028809 -0.028174 -0.027388  \n",
       "17 -0.007081 -0.006809 -0.006525 -0.006133 -0.005807 -0.005591  \n",
       "18 -0.083811 -0.084303 -0.083450 -0.084466 -0.083659 -0.083863  \n",
       "19  0.066524  0.066080  0.067139  0.065853  0.066451  0.066058  \n",
       "20 -0.007275 -0.007128 -0.007054 -0.006927 -0.006838 -0.006678  \n",
       "21 -0.048329 -0.048012 -0.047708 -0.047334 -0.047159 -0.046785  \n",
       "22 -0.024529 -0.024445 -0.024401 -0.024460 -0.024466 -0.024438  \n",
       "23 -0.061536 -0.061003 -0.060796 -0.060316 -0.059742 -0.059665  \n",
       "24 -0.276572 -0.275764 -0.275274 -0.274715 -0.273974 -0.273171  \n",
       "25 -0.018461 -0.018672 -0.018813 -0.018912 -0.019185 -0.019440  \n",
       "26  0.035752  0.035615  0.035525  0.035464  0.035322  0.035180  \n",
       "27 -0.039564 -0.039428 -0.039708 -0.039632 -0.040056 -0.040228  \n",
       "28  0.007597  0.007435  0.006635  0.005664  0.005212  0.004562  \n",
       "29 -0.069424 -0.071679 -0.073628 -0.075368 -0.076868 -0.078313  \n",
       "30  0.007144  0.007079  0.006922  0.007162  0.007012  0.007001  \n",
       "31 -0.036627 -0.036918 -0.037273 -0.037111 -0.037501 -0.037352  \n",
       "32  0.054423  0.054689  0.054451  0.054488  0.054470  0.054433  \n",
       "33  0.112968  0.113642  0.114253  0.114758  0.115284  0.116257  \n",
       "34  0.038358  0.038556  0.038800  0.039135  0.039352  0.039520  \n",
       "\n",
       "[35 rows x 173225 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_healthy.rename(columns={0 : 'label'}, inplace=True)\n",
    "df_healthy['label'] = 0\n",
    "df_healthy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c3248436",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-11T04:49:59.704641Z",
     "start_time": "2023-05-11T04:37:17.807703Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# 읽어올 폴더 경로 설정\n",
    "data_folder = 'D:/Data/호흡데이터/Task1/Wav_nonsegment/Unhealthy'\n",
    "\n",
    "# 읽어올 파일 리스트 생성\n",
    "file_list = []\n",
    "for root, dirs, files in os.walk(data_folder):\n",
    "    for file in files:\n",
    "        if file.endswith('.wav'):\n",
    "            file_list.append(os.path.join(root, file))\n",
    "\n",
    "# 가장 짧은 파일의 길이 구하기\n",
    "min_len = min([len(librosa.load(file)[0]) for file in file_list])\n",
    "\n",
    "# 데이터프레임 생성\n",
    "dfs = []\n",
    "for file in file_list:\n",
    "    # 오디오 파일 읽어오기\n",
    "    audio_data, sample_rate = librosa.load(file)\n",
    "    # 가장 짧은 길이에 맞게 데이터 자르기\n",
    "    audio_data = audio_data[:min_len]\n",
    "    # 시간 축 설정\n",
    "    time_axis = librosa.times_like(audio_data, sr=sample_rate)\n",
    "    # 채널 축 설정\n",
    "    channel_axis = ['Channel 1']\n",
    "    # 데이터프레임 생성\n",
    "    df = pd.DataFrame(audio_data.reshape(-1, len(channel_axis)), columns=channel_axis)\n",
    "    \n",
    "    dfs.append(df)\n",
    "\n",
    "# 모든 데이터프레임을 하나로 합치기\n",
    "df_unhealthy = pd.concat(dfs, axis=1, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cca13a8a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-11T04:49:59.944071Z",
     "start_time": "2023-05-11T04:49:59.705489Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>173215</th>\n",
       "      <th>173216</th>\n",
       "      <th>173217</th>\n",
       "      <th>173218</th>\n",
       "      <th>173219</th>\n",
       "      <th>173220</th>\n",
       "      <th>173221</th>\n",
       "      <th>173222</th>\n",
       "      <th>173223</th>\n",
       "      <th>173224</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.069739</td>\n",
       "      <td>0.102660</td>\n",
       "      <td>0.091162</td>\n",
       "      <td>0.099346</td>\n",
       "      <td>0.093962</td>\n",
       "      <td>0.098952</td>\n",
       "      <td>0.095814</td>\n",
       "      <td>0.099173</td>\n",
       "      <td>0.097429</td>\n",
       "      <td>0.099446</td>\n",
       "      <td>...</td>\n",
       "      <td>0.032574</td>\n",
       "      <td>0.031380</td>\n",
       "      <td>0.030319</td>\n",
       "      <td>0.029251</td>\n",
       "      <td>0.028082</td>\n",
       "      <td>0.027002</td>\n",
       "      <td>0.025912</td>\n",
       "      <td>0.024975</td>\n",
       "      <td>0.023997</td>\n",
       "      <td>0.022895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.027108</td>\n",
       "      <td>-0.039935</td>\n",
       "      <td>-0.035308</td>\n",
       "      <td>-0.038430</td>\n",
       "      <td>-0.036246</td>\n",
       "      <td>-0.038055</td>\n",
       "      <td>-0.036828</td>\n",
       "      <td>-0.038055</td>\n",
       "      <td>-0.037291</td>\n",
       "      <td>-0.037937</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014216</td>\n",
       "      <td>0.013896</td>\n",
       "      <td>0.013550</td>\n",
       "      <td>0.013139</td>\n",
       "      <td>0.012629</td>\n",
       "      <td>0.012183</td>\n",
       "      <td>0.011777</td>\n",
       "      <td>0.011292</td>\n",
       "      <td>0.010910</td>\n",
       "      <td>0.010378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.254565</td>\n",
       "      <td>-0.370539</td>\n",
       "      <td>-0.323283</td>\n",
       "      <td>-0.349609</td>\n",
       "      <td>-0.325975</td>\n",
       "      <td>-0.340078</td>\n",
       "      <td>-0.324729</td>\n",
       "      <td>-0.333104</td>\n",
       "      <td>-0.322754</td>\n",
       "      <td>-0.327030</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.315960</td>\n",
       "      <td>-0.317101</td>\n",
       "      <td>-0.318015</td>\n",
       "      <td>-0.319889</td>\n",
       "      <td>-0.322268</td>\n",
       "      <td>-0.324422</td>\n",
       "      <td>-0.325804</td>\n",
       "      <td>-0.326805</td>\n",
       "      <td>-0.328887</td>\n",
       "      <td>-0.330444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000032</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>-0.000037</td>\n",
       "      <td>-0.000097</td>\n",
       "      <td>-0.000167</td>\n",
       "      <td>-0.000241</td>\n",
       "      <td>-0.000306</td>\n",
       "      <td>-0.000349</td>\n",
       "      <td>-0.000356</td>\n",
       "      <td>-0.000316</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.057230</td>\n",
       "      <td>-0.058265</td>\n",
       "      <td>-0.059157</td>\n",
       "      <td>-0.059866</td>\n",
       "      <td>-0.060358</td>\n",
       "      <td>-0.060599</td>\n",
       "      <td>-0.060566</td>\n",
       "      <td>-0.060245</td>\n",
       "      <td>-0.059636</td>\n",
       "      <td>-0.058751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000793</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>0.000911</td>\n",
       "      <td>0.000785</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>-0.000004</td>\n",
       "      <td>-0.000697</td>\n",
       "      <td>-0.001581</td>\n",
       "      <td>-0.002624</td>\n",
       "      <td>-0.003781</td>\n",
       "      <td>...</td>\n",
       "      <td>0.404312</td>\n",
       "      <td>0.405778</td>\n",
       "      <td>0.406606</td>\n",
       "      <td>0.406793</td>\n",
       "      <td>0.406343</td>\n",
       "      <td>0.405275</td>\n",
       "      <td>0.403615</td>\n",
       "      <td>0.401401</td>\n",
       "      <td>0.398680</td>\n",
       "      <td>0.395503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>880</th>\n",
       "      <td>-0.021494</td>\n",
       "      <td>-0.024439</td>\n",
       "      <td>-0.021877</td>\n",
       "      <td>-0.018722</td>\n",
       "      <td>-0.018384</td>\n",
       "      <td>-0.019853</td>\n",
       "      <td>-0.020292</td>\n",
       "      <td>-0.018930</td>\n",
       "      <td>-0.017418</td>\n",
       "      <td>-0.017117</td>\n",
       "      <td>...</td>\n",
       "      <td>0.041869</td>\n",
       "      <td>0.043017</td>\n",
       "      <td>0.043672</td>\n",
       "      <td>0.044041</td>\n",
       "      <td>0.044656</td>\n",
       "      <td>0.045717</td>\n",
       "      <td>0.046863</td>\n",
       "      <td>0.047646</td>\n",
       "      <td>0.048089</td>\n",
       "      <td>0.048581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>881</th>\n",
       "      <td>0.141533</td>\n",
       "      <td>0.164683</td>\n",
       "      <td>0.152672</td>\n",
       "      <td>0.136099</td>\n",
       "      <td>0.136327</td>\n",
       "      <td>0.146936</td>\n",
       "      <td>0.150647</td>\n",
       "      <td>0.144023</td>\n",
       "      <td>0.138333</td>\n",
       "      <td>0.141112</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.457594</td>\n",
       "      <td>-0.457217</td>\n",
       "      <td>-0.456832</td>\n",
       "      <td>-0.456634</td>\n",
       "      <td>-0.456691</td>\n",
       "      <td>-0.456818</td>\n",
       "      <td>-0.456735</td>\n",
       "      <td>-0.456354</td>\n",
       "      <td>-0.455854</td>\n",
       "      <td>-0.455478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>882</th>\n",
       "      <td>0.012251</td>\n",
       "      <td>0.018154</td>\n",
       "      <td>0.016136</td>\n",
       "      <td>0.017717</td>\n",
       "      <td>0.017060</td>\n",
       "      <td>0.017955</td>\n",
       "      <td>0.017464</td>\n",
       "      <td>0.018010</td>\n",
       "      <td>0.017709</td>\n",
       "      <td>0.018115</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005854</td>\n",
       "      <td>0.006129</td>\n",
       "      <td>0.006400</td>\n",
       "      <td>0.006754</td>\n",
       "      <td>0.007096</td>\n",
       "      <td>0.007513</td>\n",
       "      <td>0.007718</td>\n",
       "      <td>0.008190</td>\n",
       "      <td>0.008366</td>\n",
       "      <td>0.008717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>883</th>\n",
       "      <td>-0.066388</td>\n",
       "      <td>-0.097620</td>\n",
       "      <td>-0.086484</td>\n",
       "      <td>-0.094232</td>\n",
       "      <td>-0.089016</td>\n",
       "      <td>-0.093547</td>\n",
       "      <td>-0.090408</td>\n",
       "      <td>-0.093376</td>\n",
       "      <td>-0.091542</td>\n",
       "      <td>-0.093365</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016241</td>\n",
       "      <td>0.015903</td>\n",
       "      <td>0.015626</td>\n",
       "      <td>0.015331</td>\n",
       "      <td>0.015115</td>\n",
       "      <td>0.014861</td>\n",
       "      <td>0.014656</td>\n",
       "      <td>0.014480</td>\n",
       "      <td>0.014234</td>\n",
       "      <td>0.013954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>884</th>\n",
       "      <td>-0.067660</td>\n",
       "      <td>-0.098341</td>\n",
       "      <td>-0.085792</td>\n",
       "      <td>-0.092318</td>\n",
       "      <td>-0.085904</td>\n",
       "      <td>-0.089530</td>\n",
       "      <td>-0.085056</td>\n",
       "      <td>-0.086928</td>\n",
       "      <td>-0.083802</td>\n",
       "      <td>-0.084632</td>\n",
       "      <td>...</td>\n",
       "      <td>0.061345</td>\n",
       "      <td>0.061333</td>\n",
       "      <td>0.061267</td>\n",
       "      <td>0.061133</td>\n",
       "      <td>0.061157</td>\n",
       "      <td>0.061130</td>\n",
       "      <td>0.061152</td>\n",
       "      <td>0.061061</td>\n",
       "      <td>0.061055</td>\n",
       "      <td>0.060951</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>885 rows × 173225 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0         1         2         3         4         5         6       \\\n",
       "0    0.069739  0.102660  0.091162  0.099346  0.093962  0.098952  0.095814   \n",
       "1   -0.027108 -0.039935 -0.035308 -0.038430 -0.036246 -0.038055 -0.036828   \n",
       "2   -0.254565 -0.370539 -0.323283 -0.349609 -0.325975 -0.340078 -0.324729   \n",
       "3    0.000032  0.000006 -0.000037 -0.000097 -0.000167 -0.000241 -0.000306   \n",
       "4    0.000793  0.000900  0.000911  0.000785  0.000488 -0.000004 -0.000697   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "880 -0.021494 -0.024439 -0.021877 -0.018722 -0.018384 -0.019853 -0.020292   \n",
       "881  0.141533  0.164683  0.152672  0.136099  0.136327  0.146936  0.150647   \n",
       "882  0.012251  0.018154  0.016136  0.017717  0.017060  0.017955  0.017464   \n",
       "883 -0.066388 -0.097620 -0.086484 -0.094232 -0.089016 -0.093547 -0.090408   \n",
       "884 -0.067660 -0.098341 -0.085792 -0.092318 -0.085904 -0.089530 -0.085056   \n",
       "\n",
       "       7         8         9       ...    173215    173216    173217  \\\n",
       "0    0.099173  0.097429  0.099446  ...  0.032574  0.031380  0.030319   \n",
       "1   -0.038055 -0.037291 -0.037937  ...  0.014216  0.013896  0.013550   \n",
       "2   -0.333104 -0.322754 -0.327030  ... -0.315960 -0.317101 -0.318015   \n",
       "3   -0.000349 -0.000356 -0.000316  ... -0.057230 -0.058265 -0.059157   \n",
       "4   -0.001581 -0.002624 -0.003781  ...  0.404312  0.405778  0.406606   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "880 -0.018930 -0.017418 -0.017117  ...  0.041869  0.043017  0.043672   \n",
       "881  0.144023  0.138333  0.141112  ... -0.457594 -0.457217 -0.456832   \n",
       "882  0.018010  0.017709  0.018115  ...  0.005854  0.006129  0.006400   \n",
       "883 -0.093376 -0.091542 -0.093365  ...  0.016241  0.015903  0.015626   \n",
       "884 -0.086928 -0.083802 -0.084632  ...  0.061345  0.061333  0.061267   \n",
       "\n",
       "       173218    173219    173220    173221    173222    173223    173224  \n",
       "0    0.029251  0.028082  0.027002  0.025912  0.024975  0.023997  0.022895  \n",
       "1    0.013139  0.012629  0.012183  0.011777  0.011292  0.010910  0.010378  \n",
       "2   -0.319889 -0.322268 -0.324422 -0.325804 -0.326805 -0.328887 -0.330444  \n",
       "3   -0.059866 -0.060358 -0.060599 -0.060566 -0.060245 -0.059636 -0.058751  \n",
       "4    0.406793  0.406343  0.405275  0.403615  0.401401  0.398680  0.395503  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "880  0.044041  0.044656  0.045717  0.046863  0.047646  0.048089  0.048581  \n",
       "881 -0.456634 -0.456691 -0.456818 -0.456735 -0.456354 -0.455854 -0.455478  \n",
       "882  0.006754  0.007096  0.007513  0.007718  0.008190  0.008366  0.008717  \n",
       "883  0.015331  0.015115  0.014861  0.014656  0.014480  0.014234  0.013954  \n",
       "884  0.061133  0.061157  0.061130  0.061152  0.061061  0.061055  0.060951  \n",
       "\n",
       "[885 rows x 173225 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_unhealthy = df_unhealthy.transpose()\n",
    "df_unhealthy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "893f66c4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-11T04:50:00.228265Z",
     "start_time": "2023-05-11T04:49:59.944981Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>173215</th>\n",
       "      <th>173216</th>\n",
       "      <th>173217</th>\n",
       "      <th>173218</th>\n",
       "      <th>173219</th>\n",
       "      <th>173220</th>\n",
       "      <th>173221</th>\n",
       "      <th>173222</th>\n",
       "      <th>173223</th>\n",
       "      <th>173224</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.102660</td>\n",
       "      <td>0.091162</td>\n",
       "      <td>0.099346</td>\n",
       "      <td>0.093962</td>\n",
       "      <td>0.098952</td>\n",
       "      <td>0.095814</td>\n",
       "      <td>0.099173</td>\n",
       "      <td>0.097429</td>\n",
       "      <td>0.099446</td>\n",
       "      <td>...</td>\n",
       "      <td>0.032574</td>\n",
       "      <td>0.031380</td>\n",
       "      <td>0.030319</td>\n",
       "      <td>0.029251</td>\n",
       "      <td>0.028082</td>\n",
       "      <td>0.027002</td>\n",
       "      <td>0.025912</td>\n",
       "      <td>0.024975</td>\n",
       "      <td>0.023997</td>\n",
       "      <td>0.022895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.039935</td>\n",
       "      <td>-0.035308</td>\n",
       "      <td>-0.038430</td>\n",
       "      <td>-0.036246</td>\n",
       "      <td>-0.038055</td>\n",
       "      <td>-0.036828</td>\n",
       "      <td>-0.038055</td>\n",
       "      <td>-0.037291</td>\n",
       "      <td>-0.037937</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014216</td>\n",
       "      <td>0.013896</td>\n",
       "      <td>0.013550</td>\n",
       "      <td>0.013139</td>\n",
       "      <td>0.012629</td>\n",
       "      <td>0.012183</td>\n",
       "      <td>0.011777</td>\n",
       "      <td>0.011292</td>\n",
       "      <td>0.010910</td>\n",
       "      <td>0.010378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.370539</td>\n",
       "      <td>-0.323283</td>\n",
       "      <td>-0.349609</td>\n",
       "      <td>-0.325975</td>\n",
       "      <td>-0.340078</td>\n",
       "      <td>-0.324729</td>\n",
       "      <td>-0.333104</td>\n",
       "      <td>-0.322754</td>\n",
       "      <td>-0.327030</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.315960</td>\n",
       "      <td>-0.317101</td>\n",
       "      <td>-0.318015</td>\n",
       "      <td>-0.319889</td>\n",
       "      <td>-0.322268</td>\n",
       "      <td>-0.324422</td>\n",
       "      <td>-0.325804</td>\n",
       "      <td>-0.326805</td>\n",
       "      <td>-0.328887</td>\n",
       "      <td>-0.330444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>-0.000037</td>\n",
       "      <td>-0.000097</td>\n",
       "      <td>-0.000167</td>\n",
       "      <td>-0.000241</td>\n",
       "      <td>-0.000306</td>\n",
       "      <td>-0.000349</td>\n",
       "      <td>-0.000356</td>\n",
       "      <td>-0.000316</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.057230</td>\n",
       "      <td>-0.058265</td>\n",
       "      <td>-0.059157</td>\n",
       "      <td>-0.059866</td>\n",
       "      <td>-0.060358</td>\n",
       "      <td>-0.060599</td>\n",
       "      <td>-0.060566</td>\n",
       "      <td>-0.060245</td>\n",
       "      <td>-0.059636</td>\n",
       "      <td>-0.058751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>0.000911</td>\n",
       "      <td>0.000785</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>-0.000004</td>\n",
       "      <td>-0.000697</td>\n",
       "      <td>-0.001581</td>\n",
       "      <td>-0.002624</td>\n",
       "      <td>-0.003781</td>\n",
       "      <td>...</td>\n",
       "      <td>0.404312</td>\n",
       "      <td>0.405778</td>\n",
       "      <td>0.406606</td>\n",
       "      <td>0.406793</td>\n",
       "      <td>0.406343</td>\n",
       "      <td>0.405275</td>\n",
       "      <td>0.403615</td>\n",
       "      <td>0.401401</td>\n",
       "      <td>0.398680</td>\n",
       "      <td>0.395503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>880</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.024439</td>\n",
       "      <td>-0.021877</td>\n",
       "      <td>-0.018722</td>\n",
       "      <td>-0.018384</td>\n",
       "      <td>-0.019853</td>\n",
       "      <td>-0.020292</td>\n",
       "      <td>-0.018930</td>\n",
       "      <td>-0.017418</td>\n",
       "      <td>-0.017117</td>\n",
       "      <td>...</td>\n",
       "      <td>0.041869</td>\n",
       "      <td>0.043017</td>\n",
       "      <td>0.043672</td>\n",
       "      <td>0.044041</td>\n",
       "      <td>0.044656</td>\n",
       "      <td>0.045717</td>\n",
       "      <td>0.046863</td>\n",
       "      <td>0.047646</td>\n",
       "      <td>0.048089</td>\n",
       "      <td>0.048581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>881</th>\n",
       "      <td>1</td>\n",
       "      <td>0.164683</td>\n",
       "      <td>0.152672</td>\n",
       "      <td>0.136099</td>\n",
       "      <td>0.136327</td>\n",
       "      <td>0.146936</td>\n",
       "      <td>0.150647</td>\n",
       "      <td>0.144023</td>\n",
       "      <td>0.138333</td>\n",
       "      <td>0.141112</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.457594</td>\n",
       "      <td>-0.457217</td>\n",
       "      <td>-0.456832</td>\n",
       "      <td>-0.456634</td>\n",
       "      <td>-0.456691</td>\n",
       "      <td>-0.456818</td>\n",
       "      <td>-0.456735</td>\n",
       "      <td>-0.456354</td>\n",
       "      <td>-0.455854</td>\n",
       "      <td>-0.455478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>882</th>\n",
       "      <td>1</td>\n",
       "      <td>0.018154</td>\n",
       "      <td>0.016136</td>\n",
       "      <td>0.017717</td>\n",
       "      <td>0.017060</td>\n",
       "      <td>0.017955</td>\n",
       "      <td>0.017464</td>\n",
       "      <td>0.018010</td>\n",
       "      <td>0.017709</td>\n",
       "      <td>0.018115</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005854</td>\n",
       "      <td>0.006129</td>\n",
       "      <td>0.006400</td>\n",
       "      <td>0.006754</td>\n",
       "      <td>0.007096</td>\n",
       "      <td>0.007513</td>\n",
       "      <td>0.007718</td>\n",
       "      <td>0.008190</td>\n",
       "      <td>0.008366</td>\n",
       "      <td>0.008717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>883</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.097620</td>\n",
       "      <td>-0.086484</td>\n",
       "      <td>-0.094232</td>\n",
       "      <td>-0.089016</td>\n",
       "      <td>-0.093547</td>\n",
       "      <td>-0.090408</td>\n",
       "      <td>-0.093376</td>\n",
       "      <td>-0.091542</td>\n",
       "      <td>-0.093365</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016241</td>\n",
       "      <td>0.015903</td>\n",
       "      <td>0.015626</td>\n",
       "      <td>0.015331</td>\n",
       "      <td>0.015115</td>\n",
       "      <td>0.014861</td>\n",
       "      <td>0.014656</td>\n",
       "      <td>0.014480</td>\n",
       "      <td>0.014234</td>\n",
       "      <td>0.013954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>884</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.098341</td>\n",
       "      <td>-0.085792</td>\n",
       "      <td>-0.092318</td>\n",
       "      <td>-0.085904</td>\n",
       "      <td>-0.089530</td>\n",
       "      <td>-0.085056</td>\n",
       "      <td>-0.086928</td>\n",
       "      <td>-0.083802</td>\n",
       "      <td>-0.084632</td>\n",
       "      <td>...</td>\n",
       "      <td>0.061345</td>\n",
       "      <td>0.061333</td>\n",
       "      <td>0.061267</td>\n",
       "      <td>0.061133</td>\n",
       "      <td>0.061157</td>\n",
       "      <td>0.061130</td>\n",
       "      <td>0.061152</td>\n",
       "      <td>0.061061</td>\n",
       "      <td>0.061055</td>\n",
       "      <td>0.060951</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>885 rows × 173225 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     label         1         2         3         4         5         6  \\\n",
       "0        1  0.102660  0.091162  0.099346  0.093962  0.098952  0.095814   \n",
       "1        1 -0.039935 -0.035308 -0.038430 -0.036246 -0.038055 -0.036828   \n",
       "2        1 -0.370539 -0.323283 -0.349609 -0.325975 -0.340078 -0.324729   \n",
       "3        1  0.000006 -0.000037 -0.000097 -0.000167 -0.000241 -0.000306   \n",
       "4        1  0.000900  0.000911  0.000785  0.000488 -0.000004 -0.000697   \n",
       "..     ...       ...       ...       ...       ...       ...       ...   \n",
       "880      1 -0.024439 -0.021877 -0.018722 -0.018384 -0.019853 -0.020292   \n",
       "881      1  0.164683  0.152672  0.136099  0.136327  0.146936  0.150647   \n",
       "882      1  0.018154  0.016136  0.017717  0.017060  0.017955  0.017464   \n",
       "883      1 -0.097620 -0.086484 -0.094232 -0.089016 -0.093547 -0.090408   \n",
       "884      1 -0.098341 -0.085792 -0.092318 -0.085904 -0.089530 -0.085056   \n",
       "\n",
       "            7         8         9  ...    173215    173216    173217  \\\n",
       "0    0.099173  0.097429  0.099446  ...  0.032574  0.031380  0.030319   \n",
       "1   -0.038055 -0.037291 -0.037937  ...  0.014216  0.013896  0.013550   \n",
       "2   -0.333104 -0.322754 -0.327030  ... -0.315960 -0.317101 -0.318015   \n",
       "3   -0.000349 -0.000356 -0.000316  ... -0.057230 -0.058265 -0.059157   \n",
       "4   -0.001581 -0.002624 -0.003781  ...  0.404312  0.405778  0.406606   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "880 -0.018930 -0.017418 -0.017117  ...  0.041869  0.043017  0.043672   \n",
       "881  0.144023  0.138333  0.141112  ... -0.457594 -0.457217 -0.456832   \n",
       "882  0.018010  0.017709  0.018115  ...  0.005854  0.006129  0.006400   \n",
       "883 -0.093376 -0.091542 -0.093365  ...  0.016241  0.015903  0.015626   \n",
       "884 -0.086928 -0.083802 -0.084632  ...  0.061345  0.061333  0.061267   \n",
       "\n",
       "       173218    173219    173220    173221    173222    173223    173224  \n",
       "0    0.029251  0.028082  0.027002  0.025912  0.024975  0.023997  0.022895  \n",
       "1    0.013139  0.012629  0.012183  0.011777  0.011292  0.010910  0.010378  \n",
       "2   -0.319889 -0.322268 -0.324422 -0.325804 -0.326805 -0.328887 -0.330444  \n",
       "3   -0.059866 -0.060358 -0.060599 -0.060566 -0.060245 -0.059636 -0.058751  \n",
       "4    0.406793  0.406343  0.405275  0.403615  0.401401  0.398680  0.395503  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "880  0.044041  0.044656  0.045717  0.046863  0.047646  0.048089  0.048581  \n",
       "881 -0.456634 -0.456691 -0.456818 -0.456735 -0.456354 -0.455854 -0.455478  \n",
       "882  0.006754  0.007096  0.007513  0.007718  0.008190  0.008366  0.008717  \n",
       "883  0.015331  0.015115  0.014861  0.014656  0.014480  0.014234  0.013954  \n",
       "884  0.061133  0.061157  0.061130  0.061152  0.061061  0.061055  0.060951  \n",
       "\n",
       "[885 rows x 173225 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_unhealthy.rename(columns={0 : 'label'}, inplace=True)\n",
    "df_unhealthy['label'] = 1\n",
    "df_unhealthy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e0b567bf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-11T04:50:00.377900Z",
     "start_time": "2023-05-11T04:50:00.230260Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>173215</th>\n",
       "      <th>173216</th>\n",
       "      <th>173217</th>\n",
       "      <th>173218</th>\n",
       "      <th>173219</th>\n",
       "      <th>173220</th>\n",
       "      <th>173221</th>\n",
       "      <th>173222</th>\n",
       "      <th>173223</th>\n",
       "      <th>173224</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.004234</td>\n",
       "      <td>0.003641</td>\n",
       "      <td>0.003971</td>\n",
       "      <td>0.003700</td>\n",
       "      <td>0.003809</td>\n",
       "      <td>0.003576</td>\n",
       "      <td>0.003688</td>\n",
       "      <td>0.003570</td>\n",
       "      <td>0.003566</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008067</td>\n",
       "      <td>0.008140</td>\n",
       "      <td>0.008190</td>\n",
       "      <td>0.008175</td>\n",
       "      <td>0.008217</td>\n",
       "      <td>0.008314</td>\n",
       "      <td>0.008320</td>\n",
       "      <td>0.008422</td>\n",
       "      <td>0.008517</td>\n",
       "      <td>0.008680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.108564</td>\n",
       "      <td>-0.093635</td>\n",
       "      <td>-0.100122</td>\n",
       "      <td>-0.091679</td>\n",
       "      <td>-0.093961</td>\n",
       "      <td>-0.087420</td>\n",
       "      <td>-0.088095</td>\n",
       "      <td>-0.083677</td>\n",
       "      <td>-0.084414</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001657</td>\n",
       "      <td>0.001447</td>\n",
       "      <td>0.000820</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>-0.000793</td>\n",
       "      <td>-0.001621</td>\n",
       "      <td>-0.002303</td>\n",
       "      <td>-0.002842</td>\n",
       "      <td>-0.003067</td>\n",
       "      <td>-0.003418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.045788</td>\n",
       "      <td>0.040219</td>\n",
       "      <td>0.043209</td>\n",
       "      <td>0.039028</td>\n",
       "      <td>0.038991</td>\n",
       "      <td>0.034904</td>\n",
       "      <td>0.033426</td>\n",
       "      <td>0.029972</td>\n",
       "      <td>0.028974</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.014146</td>\n",
       "      <td>-0.012259</td>\n",
       "      <td>-0.009135</td>\n",
       "      <td>-0.005213</td>\n",
       "      <td>-0.000988</td>\n",
       "      <td>0.002983</td>\n",
       "      <td>0.006162</td>\n",
       "      <td>0.008906</td>\n",
       "      <td>0.010976</td>\n",
       "      <td>0.012153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.043004</td>\n",
       "      <td>0.036623</td>\n",
       "      <td>0.038840</td>\n",
       "      <td>0.035038</td>\n",
       "      <td>0.035900</td>\n",
       "      <td>0.033086</td>\n",
       "      <td>0.033206</td>\n",
       "      <td>0.031031</td>\n",
       "      <td>0.030529</td>\n",
       "      <td>...</td>\n",
       "      <td>0.089253</td>\n",
       "      <td>0.088449</td>\n",
       "      <td>0.087667</td>\n",
       "      <td>0.086844</td>\n",
       "      <td>0.086066</td>\n",
       "      <td>0.085214</td>\n",
       "      <td>0.084552</td>\n",
       "      <td>0.083685</td>\n",
       "      <td>0.082866</td>\n",
       "      <td>0.082092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.084398</td>\n",
       "      <td>-0.071648</td>\n",
       "      <td>-0.076402</td>\n",
       "      <td>-0.070458</td>\n",
       "      <td>-0.074119</td>\n",
       "      <td>-0.071738</td>\n",
       "      <td>-0.075175</td>\n",
       "      <td>-0.074700</td>\n",
       "      <td>-0.077834</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.206857</td>\n",
       "      <td>-0.213262</td>\n",
       "      <td>-0.218788</td>\n",
       "      <td>-0.223172</td>\n",
       "      <td>-0.226421</td>\n",
       "      <td>-0.228739</td>\n",
       "      <td>-0.230270</td>\n",
       "      <td>-0.231345</td>\n",
       "      <td>-0.232212</td>\n",
       "      <td>-0.233467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>880</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.024439</td>\n",
       "      <td>-0.021877</td>\n",
       "      <td>-0.018722</td>\n",
       "      <td>-0.018384</td>\n",
       "      <td>-0.019853</td>\n",
       "      <td>-0.020292</td>\n",
       "      <td>-0.018930</td>\n",
       "      <td>-0.017418</td>\n",
       "      <td>-0.017117</td>\n",
       "      <td>...</td>\n",
       "      <td>0.041869</td>\n",
       "      <td>0.043017</td>\n",
       "      <td>0.043672</td>\n",
       "      <td>0.044041</td>\n",
       "      <td>0.044656</td>\n",
       "      <td>0.045717</td>\n",
       "      <td>0.046863</td>\n",
       "      <td>0.047646</td>\n",
       "      <td>0.048089</td>\n",
       "      <td>0.048581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>881</th>\n",
       "      <td>1</td>\n",
       "      <td>0.164683</td>\n",
       "      <td>0.152672</td>\n",
       "      <td>0.136099</td>\n",
       "      <td>0.136327</td>\n",
       "      <td>0.146936</td>\n",
       "      <td>0.150647</td>\n",
       "      <td>0.144023</td>\n",
       "      <td>0.138333</td>\n",
       "      <td>0.141112</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.457594</td>\n",
       "      <td>-0.457217</td>\n",
       "      <td>-0.456832</td>\n",
       "      <td>-0.456634</td>\n",
       "      <td>-0.456691</td>\n",
       "      <td>-0.456818</td>\n",
       "      <td>-0.456735</td>\n",
       "      <td>-0.456354</td>\n",
       "      <td>-0.455854</td>\n",
       "      <td>-0.455478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>882</th>\n",
       "      <td>1</td>\n",
       "      <td>0.018154</td>\n",
       "      <td>0.016136</td>\n",
       "      <td>0.017717</td>\n",
       "      <td>0.017060</td>\n",
       "      <td>0.017955</td>\n",
       "      <td>0.017464</td>\n",
       "      <td>0.018010</td>\n",
       "      <td>0.017709</td>\n",
       "      <td>0.018115</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005854</td>\n",
       "      <td>0.006129</td>\n",
       "      <td>0.006400</td>\n",
       "      <td>0.006754</td>\n",
       "      <td>0.007096</td>\n",
       "      <td>0.007513</td>\n",
       "      <td>0.007718</td>\n",
       "      <td>0.008190</td>\n",
       "      <td>0.008366</td>\n",
       "      <td>0.008717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>883</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.097620</td>\n",
       "      <td>-0.086484</td>\n",
       "      <td>-0.094232</td>\n",
       "      <td>-0.089016</td>\n",
       "      <td>-0.093547</td>\n",
       "      <td>-0.090408</td>\n",
       "      <td>-0.093376</td>\n",
       "      <td>-0.091542</td>\n",
       "      <td>-0.093365</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016241</td>\n",
       "      <td>0.015903</td>\n",
       "      <td>0.015626</td>\n",
       "      <td>0.015331</td>\n",
       "      <td>0.015115</td>\n",
       "      <td>0.014861</td>\n",
       "      <td>0.014656</td>\n",
       "      <td>0.014480</td>\n",
       "      <td>0.014234</td>\n",
       "      <td>0.013954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>884</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.098341</td>\n",
       "      <td>-0.085792</td>\n",
       "      <td>-0.092318</td>\n",
       "      <td>-0.085904</td>\n",
       "      <td>-0.089530</td>\n",
       "      <td>-0.085056</td>\n",
       "      <td>-0.086928</td>\n",
       "      <td>-0.083802</td>\n",
       "      <td>-0.084632</td>\n",
       "      <td>...</td>\n",
       "      <td>0.061345</td>\n",
       "      <td>0.061333</td>\n",
       "      <td>0.061267</td>\n",
       "      <td>0.061133</td>\n",
       "      <td>0.061157</td>\n",
       "      <td>0.061130</td>\n",
       "      <td>0.061152</td>\n",
       "      <td>0.061061</td>\n",
       "      <td>0.061055</td>\n",
       "      <td>0.060951</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>920 rows × 173225 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     label         1         2         3         4         5         6  \\\n",
       "0        0  0.004234  0.003641  0.003971  0.003700  0.003809  0.003576   \n",
       "1        0 -0.108564 -0.093635 -0.100122 -0.091679 -0.093961 -0.087420   \n",
       "2        0  0.045788  0.040219  0.043209  0.039028  0.038991  0.034904   \n",
       "3        0  0.043004  0.036623  0.038840  0.035038  0.035900  0.033086   \n",
       "4        0 -0.084398 -0.071648 -0.076402 -0.070458 -0.074119 -0.071738   \n",
       "..     ...       ...       ...       ...       ...       ...       ...   \n",
       "880      1 -0.024439 -0.021877 -0.018722 -0.018384 -0.019853 -0.020292   \n",
       "881      1  0.164683  0.152672  0.136099  0.136327  0.146936  0.150647   \n",
       "882      1  0.018154  0.016136  0.017717  0.017060  0.017955  0.017464   \n",
       "883      1 -0.097620 -0.086484 -0.094232 -0.089016 -0.093547 -0.090408   \n",
       "884      1 -0.098341 -0.085792 -0.092318 -0.085904 -0.089530 -0.085056   \n",
       "\n",
       "            7         8         9  ...    173215    173216    173217  \\\n",
       "0    0.003688  0.003570  0.003566  ...  0.008067  0.008140  0.008190   \n",
       "1   -0.088095 -0.083677 -0.084414  ...  0.001657  0.001447  0.000820   \n",
       "2    0.033426  0.029972  0.028974  ... -0.014146 -0.012259 -0.009135   \n",
       "3    0.033206  0.031031  0.030529  ...  0.089253  0.088449  0.087667   \n",
       "4   -0.075175 -0.074700 -0.077834  ... -0.206857 -0.213262 -0.218788   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "880 -0.018930 -0.017418 -0.017117  ...  0.041869  0.043017  0.043672   \n",
       "881  0.144023  0.138333  0.141112  ... -0.457594 -0.457217 -0.456832   \n",
       "882  0.018010  0.017709  0.018115  ...  0.005854  0.006129  0.006400   \n",
       "883 -0.093376 -0.091542 -0.093365  ...  0.016241  0.015903  0.015626   \n",
       "884 -0.086928 -0.083802 -0.084632  ...  0.061345  0.061333  0.061267   \n",
       "\n",
       "       173218    173219    173220    173221    173222    173223    173224  \n",
       "0    0.008175  0.008217  0.008314  0.008320  0.008422  0.008517  0.008680  \n",
       "1    0.000003 -0.000793 -0.001621 -0.002303 -0.002842 -0.003067 -0.003418  \n",
       "2   -0.005213 -0.000988  0.002983  0.006162  0.008906  0.010976  0.012153  \n",
       "3    0.086844  0.086066  0.085214  0.084552  0.083685  0.082866  0.082092  \n",
       "4   -0.223172 -0.226421 -0.228739 -0.230270 -0.231345 -0.232212 -0.233467  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "880  0.044041  0.044656  0.045717  0.046863  0.047646  0.048089  0.048581  \n",
       "881 -0.456634 -0.456691 -0.456818 -0.456735 -0.456354 -0.455854 -0.455478  \n",
       "882  0.006754  0.007096  0.007513  0.007718  0.008190  0.008366  0.008717  \n",
       "883  0.015331  0.015115  0.014861  0.014656  0.014480  0.014234  0.013954  \n",
       "884  0.061133  0.061157  0.061130  0.061152  0.061061  0.061055  0.060951  \n",
       "\n",
       "[920 rows x 173225 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([df_healthy, df_unhealthy], axis=0)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a5a1ba52",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-11T04:50:00.392852Z",
     "start_time": "2023-05-11T04:50:00.378902Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "label_col = 'label' # 라벨이 되는 열 이름\n",
    "data_cols = df.columns[df.columns != label_col].tolist() # 나머지 열 이름"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aef7bc0c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-11T04:50:00.901690Z",
     "start_time": "2023-05-11T04:50:00.393823Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X = df[data_cols]\n",
    "y = df[label_col]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=10)\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "X_test = np.array(X_test)\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "# 라벨을 one-hot 인코딩으로 변환\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], 1, X_train.shape[1])\n",
    "X_test = X_test.reshape(X_test.shape[0], 1, X_test.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d4c8b4",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Wavenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "635f979b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-08T07:24:08.687439Z",
     "start_time": "2023-05-08T07:23:56.470867Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": " OOM when allocating tensor with shape[2048,3,173224] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node model_4/conv1d_40/Conv1D/SpaceToBatchND\n (defined at C:\\Users\\user\\anaconda3\\lib\\site-packages\\keras\\layers\\convolutional.py:231)\n]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_15547]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node model_4/conv1d_40/Conv1D/SpaceToBatchND:\nIn[0] IteratorGetNext (defined at C:\\Users\\user\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py:866)\t\nIn[1] model_4/conv1d_40/Conv1D/SpaceToBatchND/block_shape:\t\nIn[2] model_4/conv1d_40/Conv1D/SpaceToBatchND/paddings:\n\nOperation defined at: (most recent call last)\n>>>   File \"C:\\Users\\user\\anaconda3\\lib\\runpy.py\", line 194, in _run_module_as_main\n>>>     return _run_code(code, main_globals, None,\n>>> \n>>>   File \"C:\\Users\\user\\anaconda3\\lib\\runpy.py\", line 87, in _run_code\n>>>     exec(code, run_globals)\n>>> \n>>>   File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n>>>     app.launch_new_instance()\n>>> \n>>>   File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 976, in launch_instance\n>>>     app.start()\n>>> \n>>>   File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 712, in start\n>>>     self.io_loop.start()\n>>> \n>>>   File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n>>>     self.asyncio_loop.run_forever()\n>>> \n>>>   File \"C:\\Users\\user\\anaconda3\\lib\\asyncio\\base_events.py\", line 570, in run_forever\n>>>     self._run_once()\n>>> \n>>>   File \"C:\\Users\\user\\anaconda3\\lib\\asyncio\\base_events.py\", line 1859, in _run_once\n>>>     handle._run()\n>>> \n>>>   File \"C:\\Users\\user\\anaconda3\\lib\\asyncio\\events.py\", line 81, in _run\n>>>     self._context.run(self._callback, *self._args)\n>>> \n>>>   File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 510, in dispatch_queue\n>>>     await self.process_one()\n>>> \n>>>   File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 499, in process_one\n>>>     await dispatch(*args)\n>>> \n>>>   File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 406, in dispatch_shell\n>>>     await result\n>>> \n>>>   File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 730, in execute_request\n>>>     reply_content = await reply_content\n>>> \n>>>   File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 383, in do_execute\n>>>     res = shell.run_cell(\n>>> \n>>>   File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 528, in run_cell\n>>>     return super().run_cell(*args, **kwargs)\n>>> \n>>>   File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2881, in run_cell\n>>>     result = self._run_cell(\n>>> \n>>>   File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2936, in _run_cell\n>>>     return runner(coro)\n>>> \n>>>   File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n>>>     coro.send(None)\n>>> \n>>>   File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3135, in run_cell_async\n>>>     has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n>>> \n>>>   File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3338, in run_ast_nodes\n>>>     if await self.run_code(code, result, async_=asy):\n>>> \n>>>   File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3398, in run_code\n>>>     exec(code_obj, self.user_global_ns, self.user_ns)\n>>> \n>>>   File \"C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_568\\249154806.py\", line 28, in <cell line: 28>\n>>>     history = model.fit(X_train, y_train, epochs=15, batch_size=128)\n>>> \n>>>   File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1216, in fit\n>>>     tmp_logs = self.train_function(iterator)\n>>> \n>>>   File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 878, in train_function\n>>>     return step_function(self, iterator)\n>>> \n>>>   File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 867, in step_function\n>>>     outputs = model.distribute_strategy.run(run_step, args=(data,))\n>>> \n>>>   File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 860, in run_step\n>>>     outputs = model.train_step(data)\n>>> \n>>>   File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 808, in train_step\n>>>     y_pred = self(x, training=True)\n>>> \n>>>   File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1083, in __call__\n>>>     outputs = call_fn(inputs, *args, **kwargs)\n>>> \n>>>   File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\keras\\engine\\functional.py\", line 451, in call\n>>>     return self._run_internal_graph(\n>>> \n>>>   File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\keras\\engine\\functional.py\", line 589, in _run_internal_graph\n>>>     outputs = node.layer(*args, **kwargs)\n>>> \n>>>   File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1083, in __call__\n>>>     outputs = call_fn(inputs, *args, **kwargs)\n>>> \n>>>   File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\keras\\layers\\convolutional.py\", line 246, in call\n>>>     outputs = self.convolution_op(inputs, self.kernel)\n>>> \n>>>   File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\keras\\layers\\convolutional.py\", line 231, in convolution_op\n>>>     return tf.nn.convolution(\n>>> ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "Input \u001b[1;32mIn [19]\u001b[0m, in \u001b[0;36m<cell line: 28>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     25\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# 모델 학습\u001b[39;00m\n\u001b[1;32m---> 28\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m15\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:58\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     57\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 58\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     59\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     61\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m:  OOM when allocating tensor with shape[2048,3,173224] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node model_4/conv1d_40/Conv1D/SpaceToBatchND\n (defined at C:\\Users\\user\\anaconda3\\lib\\site-packages\\keras\\layers\\convolutional.py:231)\n]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_15547]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node model_4/conv1d_40/Conv1D/SpaceToBatchND:\nIn[0] IteratorGetNext (defined at C:\\Users\\user\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py:866)\t\nIn[1] model_4/conv1d_40/Conv1D/SpaceToBatchND/block_shape:\t\nIn[2] model_4/conv1d_40/Conv1D/SpaceToBatchND/paddings:\n\nOperation defined at: (most recent call last)\n>>>   File \"C:\\Users\\user\\anaconda3\\lib\\runpy.py\", line 194, in _run_module_as_main\n>>>     return _run_code(code, main_globals, None,\n>>> \n>>>   File \"C:\\Users\\user\\anaconda3\\lib\\runpy.py\", line 87, in _run_code\n>>>     exec(code, run_globals)\n>>> \n>>>   File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n>>>     app.launch_new_instance()\n>>> \n>>>   File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 976, in launch_instance\n>>>     app.start()\n>>> \n>>>   File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 712, in start\n>>>     self.io_loop.start()\n>>> \n>>>   File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n>>>     self.asyncio_loop.run_forever()\n>>> \n>>>   File \"C:\\Users\\user\\anaconda3\\lib\\asyncio\\base_events.py\", line 570, in run_forever\n>>>     self._run_once()\n>>> \n>>>   File \"C:\\Users\\user\\anaconda3\\lib\\asyncio\\base_events.py\", line 1859, in _run_once\n>>>     handle._run()\n>>> \n>>>   File \"C:\\Users\\user\\anaconda3\\lib\\asyncio\\events.py\", line 81, in _run\n>>>     self._context.run(self._callback, *self._args)\n>>> \n>>>   File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 510, in dispatch_queue\n>>>     await self.process_one()\n>>> \n>>>   File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 499, in process_one\n>>>     await dispatch(*args)\n>>> \n>>>   File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 406, in dispatch_shell\n>>>     await result\n>>> \n>>>   File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 730, in execute_request\n>>>     reply_content = await reply_content\n>>> \n>>>   File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 383, in do_execute\n>>>     res = shell.run_cell(\n>>> \n>>>   File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 528, in run_cell\n>>>     return super().run_cell(*args, **kwargs)\n>>> \n>>>   File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2881, in run_cell\n>>>     result = self._run_cell(\n>>> \n>>>   File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2936, in _run_cell\n>>>     return runner(coro)\n>>> \n>>>   File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n>>>     coro.send(None)\n>>> \n>>>   File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3135, in run_cell_async\n>>>     has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n>>> \n>>>   File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3338, in run_ast_nodes\n>>>     if await self.run_code(code, result, async_=asy):\n>>> \n>>>   File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3398, in run_code\n>>>     exec(code_obj, self.user_global_ns, self.user_ns)\n>>> \n>>>   File \"C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_568\\249154806.py\", line 28, in <cell line: 28>\n>>>     history = model.fit(X_train, y_train, epochs=15, batch_size=128)\n>>> \n>>>   File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1216, in fit\n>>>     tmp_logs = self.train_function(iterator)\n>>> \n>>>   File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 878, in train_function\n>>>     return step_function(self, iterator)\n>>> \n>>>   File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 867, in step_function\n>>>     outputs = model.distribute_strategy.run(run_step, args=(data,))\n>>> \n>>>   File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 860, in run_step\n>>>     outputs = model.train_step(data)\n>>> \n>>>   File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 808, in train_step\n>>>     y_pred = self(x, training=True)\n>>> \n>>>   File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1083, in __call__\n>>>     outputs = call_fn(inputs, *args, **kwargs)\n>>> \n>>>   File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\keras\\engine\\functional.py\", line 451, in call\n>>>     return self._run_internal_graph(\n>>> \n>>>   File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\keras\\engine\\functional.py\", line 589, in _run_internal_graph\n>>>     outputs = node.layer(*args, **kwargs)\n>>> \n>>>   File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1083, in __call__\n>>>     outputs = call_fn(inputs, *args, **kwargs)\n>>> \n>>>   File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\keras\\layers\\convolutional.py\", line 246, in call\n>>>     outputs = self.convolution_op(inputs, self.kernel)\n>>> \n>>>   File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\keras\\layers\\convolutional.py\", line 231, in convolution_op\n>>>     return tf.nn.convolution(\n>>> "
     ]
    }
   ],
   "source": [
    "inputs = Input(shape=(1, 173224))\n",
    "\n",
    "# Convolutional Layers\n",
    "residuals = []\n",
    "for dilation_rate in [1, 2, 4, 8, 16]:\n",
    "    x = Conv1D(128, 3, dilation_rate=16, padding='same')(inputs)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv1D(128, 3, dilation_rate=8, padding='same')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    residuals.append(x)\n",
    "\n",
    "# Skip Connection\n",
    "x = Add()(residuals)\n",
    "x = Activation('relu')(x)\n",
    "\n",
    "# Fully-connected Layers\n",
    "x = Flatten()(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dense(2, activation='softmax')(x)\n",
    "\n",
    "# Model\n",
    "model = Model(inputs=inputs, outputs=x)\n",
    "\n",
    "# 모델 컴파일\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# 모델 학습\n",
    "history = model.fit(X_train, y_train, epochs=15, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fa1ddb2c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-08T07:23:12.052942Z",
     "start_time": "2023-05-08T07:23:10.591567Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 1s 99ms/step - loss: 0.5086 - accuracy: 0.9457\n",
      "Test loss: 0.5086\n",
      "Test accuracy: 0.9457\n"
     ]
    }
   ],
   "source": [
    "# 모델 평가\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test loss: {loss:.4f}\")\n",
    "print(f\"Test accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f2fec0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-08T06:45:02.025152Z",
     "start_time": "2023-05-08T06:45:02.025152Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# train set에서 최고 정확도 출력\n",
    "train_acc = max(history.history['accuracy'])\n",
    "print(f\"best train accuracy: {train_acc}\")\n",
    "\n",
    "# validation set에서 최고 정확도 출력\n",
    "val_acc = max(history.history['val_accuracy'])\n",
    "print(f\"best validation accuracy: {val_acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "092875c1",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Bi-LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "95b6ae48",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-11T04:55:34.437583Z",
     "start_time": "2023-05-11T04:55:33.934193Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "inputs = Input(shape=(1, 173224))\n",
    "\n",
    "# BiLSTM Layers\n",
    "x = Bidirectional(LSTM(256, return_sequences=True))(inputs)\n",
    "x = Bidirectional(LSTM(256))(x)\n",
    "\n",
    "# Fully-connected Layers\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dense(2, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "30f50719",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-11T04:58:24.361192Z",
     "start_time": "2023-05-11T04:57:24.475159Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 1, 173224)]       0         \n",
      "                                                                 \n",
      " bidirectional_2 (Bidirectio  (None, 1, 512)           355289088 \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " bidirectional_3 (Bidirectio  (None, 512)              1574912   \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 256)               131328    \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 2)                 514       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 356,995,842\n",
      "Trainable params: 356,995,842\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/150\n",
      "3/3 [==============================] - 4s 560ms/step - loss: 3.7255e-06 - accuracy: 1.0000 - val_loss: 1.2619 - val_accuracy: 0.8098\n",
      "Epoch 2/150\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 3.0905e-06 - accuracy: 1.0000 - val_loss: 1.2878 - val_accuracy: 0.8098\n",
      "Epoch 3/150\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 2.5389e-06 - accuracy: 1.0000 - val_loss: 1.3170 - val_accuracy: 0.8098\n",
      "Epoch 4/150\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 1.9547e-06 - accuracy: 1.0000 - val_loss: 1.3456 - val_accuracy: 0.8098\n",
      "Epoch 5/150\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 1.5739e-06 - accuracy: 1.0000 - val_loss: 1.3737 - val_accuracy: 0.8098\n",
      "Epoch 6/150\n",
      "3/3 [==============================] - 0s 163ms/step - loss: 1.2764e-06 - accuracy: 1.0000 - val_loss: 1.4004 - val_accuracy: 0.8098\n",
      "Epoch 7/150\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 1.0358e-06 - accuracy: 1.0000 - val_loss: 1.4254 - val_accuracy: 0.8098\n",
      "Epoch 8/150\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 8.4360e-07 - accuracy: 1.0000 - val_loss: 1.4479 - val_accuracy: 0.8098\n",
      "Epoch 9/150\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 7.0047e-07 - accuracy: 1.0000 - val_loss: 1.4685 - val_accuracy: 0.8098\n",
      "Epoch 10/150\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 5.9572e-07 - accuracy: 1.0000 - val_loss: 1.4872 - val_accuracy: 0.8098\n",
      "Epoch 11/150\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 5.2845e-07 - accuracy: 1.0000 - val_loss: 1.5045 - val_accuracy: 0.8098\n",
      "Epoch 12/150\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 4.5263e-07 - accuracy: 1.0000 - val_loss: 1.5197 - val_accuracy: 0.8098\n",
      "Epoch 13/150\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 4.0134e-07 - accuracy: 1.0000 - val_loss: 1.5335 - val_accuracy: 0.8098\n",
      "Epoch 14/150\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 3.6063e-07 - accuracy: 1.0000 - val_loss: 1.5461 - val_accuracy: 0.8098\n",
      "Epoch 15/150\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 3.2720e-07 - accuracy: 1.0000 - val_loss: 1.5575 - val_accuracy: 0.8098\n",
      "Epoch 16/150\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 2.9375e-07 - accuracy: 1.0000 - val_loss: 1.5677 - val_accuracy: 0.8098\n",
      "Epoch 17/150\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 2.7076e-07 - accuracy: 1.0000 - val_loss: 1.5772 - val_accuracy: 0.8098\n",
      "Epoch 18/150\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 2.5269e-07 - accuracy: 1.0000 - val_loss: 1.5862 - val_accuracy: 0.8043\n",
      "Epoch 19/150\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 2.3607e-07 - accuracy: 1.0000 - val_loss: 1.5946 - val_accuracy: 0.8043\n",
      "Epoch 20/150\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 2.2207e-07 - accuracy: 1.0000 - val_loss: 1.6026 - val_accuracy: 0.8043\n",
      "Epoch 21/150\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 2.0457e-07 - accuracy: 1.0000 - val_loss: 1.6096 - val_accuracy: 0.8043\n",
      "Epoch 22/150\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 1.9509e-07 - accuracy: 1.0000 - val_loss: 1.6166 - val_accuracy: 0.8043\n",
      "Epoch 23/150\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 1.8343e-07 - accuracy: 1.0000 - val_loss: 1.6232 - val_accuracy: 0.8043\n",
      "Epoch 24/150\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 1.7581e-07 - accuracy: 1.0000 - val_loss: 1.6296 - val_accuracy: 0.8043\n",
      "Epoch 25/150\n",
      "3/3 [==============================] - 0s 135ms/step - loss: 1.6679e-07 - accuracy: 1.0000 - val_loss: 1.6357 - val_accuracy: 0.8043\n",
      "Epoch 26/150\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 1.5798e-07 - accuracy: 1.0000 - val_loss: 1.6414 - val_accuracy: 0.8043\n",
      "Epoch 27/150\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 1.5009e-07 - accuracy: 1.0000 - val_loss: 1.6468 - val_accuracy: 0.8043\n",
      "Epoch 28/150\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 1.4383e-07 - accuracy: 1.0000 - val_loss: 1.6520 - val_accuracy: 0.8043\n",
      "Epoch 29/150\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 1.3801e-07 - accuracy: 1.0000 - val_loss: 1.6571 - val_accuracy: 0.8043\n",
      "Epoch 30/150\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 1.3245e-07 - accuracy: 1.0000 - val_loss: 1.6621 - val_accuracy: 0.8043\n",
      "Epoch 31/150\n",
      "3/3 [==============================] - 0s 152ms/step - loss: 1.2706e-07 - accuracy: 1.0000 - val_loss: 1.6668 - val_accuracy: 0.8043\n",
      "Epoch 32/150\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 1.2168e-07 - accuracy: 1.0000 - val_loss: 1.6714 - val_accuracy: 0.8043\n",
      "Epoch 33/150\n",
      "3/3 [==============================] - 0s 169ms/step - loss: 1.1757e-07 - accuracy: 1.0000 - val_loss: 1.6759 - val_accuracy: 0.8043\n",
      "Epoch 34/150\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 1.1282e-07 - accuracy: 1.0000 - val_loss: 1.6803 - val_accuracy: 0.8043\n",
      "Epoch 35/150\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 1.0865e-07 - accuracy: 1.0000 - val_loss: 1.6846 - val_accuracy: 0.8043\n",
      "Epoch 36/150\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 1.0568e-07 - accuracy: 1.0000 - val_loss: 1.6890 - val_accuracy: 0.8043\n",
      "Epoch 37/150\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 1.0192e-07 - accuracy: 1.0000 - val_loss: 1.6933 - val_accuracy: 0.8043\n",
      "Epoch 38/150\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 9.8303e-08 - accuracy: 1.0000 - val_loss: 1.6973 - val_accuracy: 0.8043\n",
      "Epoch 39/150\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 9.5022e-08 - accuracy: 1.0000 - val_loss: 1.7014 - val_accuracy: 0.8043\n",
      "Epoch 40/150\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 9.1742e-08 - accuracy: 1.0000 - val_loss: 1.7052 - val_accuracy: 0.8043\n",
      "Epoch 41/150\n",
      "3/3 [==============================] - 0s 161ms/step - loss: 8.9134e-08 - accuracy: 1.0000 - val_loss: 1.7089 - val_accuracy: 0.8043\n",
      "Epoch 42/150\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 8.6064e-08 - accuracy: 1.0000 - val_loss: 1.7126 - val_accuracy: 0.8043\n",
      "Epoch 43/150\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 8.3610e-08 - accuracy: 1.0000 - val_loss: 1.7162 - val_accuracy: 0.8043\n",
      "Epoch 44/150\n",
      "3/3 [==============================] - 0s 154ms/step - loss: 8.1341e-08 - accuracy: 1.0000 - val_loss: 1.7198 - val_accuracy: 0.8043\n",
      "Epoch 45/150\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 7.8635e-08 - accuracy: 1.0000 - val_loss: 1.7233 - val_accuracy: 0.8043\n",
      "Epoch 46/150\n",
      "3/3 [==============================] - 0s 135ms/step - loss: 7.6845e-08 - accuracy: 1.0000 - val_loss: 1.7268 - val_accuracy: 0.8043\n",
      "Epoch 47/150\n",
      "3/3 [==============================] - 0s 155ms/step - loss: 7.4389e-08 - accuracy: 1.0000 - val_loss: 1.7303 - val_accuracy: 0.8043\n",
      "Epoch 48/150\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 7.2413e-08 - accuracy: 1.0000 - val_loss: 1.7337 - val_accuracy: 0.8043\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/150\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 7.0414e-08 - accuracy: 1.0000 - val_loss: 1.7369 - val_accuracy: 0.8043\n",
      "Epoch 50/150\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 6.8695e-08 - accuracy: 1.0000 - val_loss: 1.7401 - val_accuracy: 0.8043\n",
      "Epoch 51/150\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 6.6639e-08 - accuracy: 1.0000 - val_loss: 1.7432 - val_accuracy: 0.8043\n",
      "Epoch 52/150\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 6.5343e-08 - accuracy: 1.0000 - val_loss: 1.7464 - val_accuracy: 0.8043\n",
      "Epoch 53/150\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 6.3371e-08 - accuracy: 1.0000 - val_loss: 1.7494 - val_accuracy: 0.8043\n",
      "Epoch 54/150\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 6.1840e-08 - accuracy: 1.0000 - val_loss: 1.7524 - val_accuracy: 0.8043\n",
      "Epoch 55/150\n",
      "3/3 [==============================] - 0s 162ms/step - loss: 6.0293e-08 - accuracy: 1.0000 - val_loss: 1.7553 - val_accuracy: 0.8043\n",
      "Epoch 56/150\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 5.8965e-08 - accuracy: 1.0000 - val_loss: 1.7583 - val_accuracy: 0.8043\n",
      "Epoch 57/150\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 5.7453e-08 - accuracy: 1.0000 - val_loss: 1.7611 - val_accuracy: 0.8043\n",
      "Epoch 58/150\n",
      "3/3 [==============================] - 0s 151ms/step - loss: 5.6006e-08 - accuracy: 1.0000 - val_loss: 1.7637 - val_accuracy: 0.8043\n",
      "Epoch 59/150\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 5.4889e-08 - accuracy: 1.0000 - val_loss: 1.7665 - val_accuracy: 0.8043\n",
      "Epoch 60/150\n",
      "3/3 [==============================] - 0s 162ms/step - loss: 5.3703e-08 - accuracy: 1.0000 - val_loss: 1.7693 - val_accuracy: 0.8043\n",
      "Epoch 61/150\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 5.2312e-08 - accuracy: 1.0000 - val_loss: 1.7719 - val_accuracy: 0.8043\n",
      "Epoch 62/150\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 5.1373e-08 - accuracy: 1.0000 - val_loss: 1.7747 - val_accuracy: 0.8043\n",
      "Epoch 63/150\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 5.0122e-08 - accuracy: 1.0000 - val_loss: 1.7772 - val_accuracy: 0.8043\n",
      "Epoch 64/150\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 4.9119e-08 - accuracy: 1.0000 - val_loss: 1.7799 - val_accuracy: 0.8043\n",
      "Epoch 65/150\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 4.7841e-08 - accuracy: 1.0000 - val_loss: 1.7823 - val_accuracy: 0.8043\n",
      "Epoch 66/150\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 4.7181e-08 - accuracy: 1.0000 - val_loss: 1.7850 - val_accuracy: 0.8043\n",
      "Epoch 67/150\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 4.5967e-08 - accuracy: 1.0000 - val_loss: 1.7875 - val_accuracy: 0.8043\n",
      "Epoch 68/150\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 4.5197e-08 - accuracy: 1.0000 - val_loss: 1.7900 - val_accuracy: 0.8043\n",
      "Epoch 69/150\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 4.4058e-08 - accuracy: 1.0000 - val_loss: 1.7924 - val_accuracy: 0.8043\n",
      "Epoch 70/150\n",
      "3/3 [==============================] - 0s 135ms/step - loss: 4.3404e-08 - accuracy: 1.0000 - val_loss: 1.7949 - val_accuracy: 0.8043\n",
      "Epoch 71/150\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 4.2330e-08 - accuracy: 1.0000 - val_loss: 1.7972 - val_accuracy: 0.8043\n",
      "Epoch 72/150\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 4.1639e-08 - accuracy: 1.0000 - val_loss: 1.7996 - val_accuracy: 0.8043\n",
      "Epoch 73/150\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 4.0775e-08 - accuracy: 1.0000 - val_loss: 1.8018 - val_accuracy: 0.8043\n",
      "Epoch 74/150\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 3.9914e-08 - accuracy: 1.0000 - val_loss: 1.8040 - val_accuracy: 0.8043\n",
      "Epoch 75/150\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 3.9306e-08 - accuracy: 1.0000 - val_loss: 1.8063 - val_accuracy: 0.8043\n",
      "Epoch 76/150\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 3.8579e-08 - accuracy: 1.0000 - val_loss: 1.8086 - val_accuracy: 0.8043\n",
      "Epoch 77/150\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 3.7872e-08 - accuracy: 1.0000 - val_loss: 1.8108 - val_accuracy: 0.8043\n",
      "Epoch 78/150\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 3.7182e-08 - accuracy: 1.0000 - val_loss: 1.8129 - val_accuracy: 0.8043\n",
      "Epoch 79/150\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 3.6546e-08 - accuracy: 1.0000 - val_loss: 1.8152 - val_accuracy: 0.8043\n",
      "Epoch 80/150\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 3.5858e-08 - accuracy: 1.0000 - val_loss: 1.8172 - val_accuracy: 0.8043\n",
      "Epoch 81/150\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 3.5192e-08 - accuracy: 1.0000 - val_loss: 1.8192 - val_accuracy: 0.8043\n",
      "Epoch 82/150\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 3.4687e-08 - accuracy: 1.0000 - val_loss: 1.8214 - val_accuracy: 0.8043\n",
      "Epoch 83/150\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 3.4101e-08 - accuracy: 1.0000 - val_loss: 1.8234 - val_accuracy: 0.8043\n",
      "Epoch 84/150\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 3.3530e-08 - accuracy: 1.0000 - val_loss: 1.8255 - val_accuracy: 0.8043\n",
      "Epoch 85/150\n",
      "3/3 [==============================] - 0s 155ms/step - loss: 3.2933e-08 - accuracy: 1.0000 - val_loss: 1.8275 - val_accuracy: 0.8043\n",
      "Epoch 86/150\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 3.2388e-08 - accuracy: 1.0000 - val_loss: 1.8294 - val_accuracy: 0.8043\n",
      "Epoch 87/150\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 3.1842e-08 - accuracy: 1.0000 - val_loss: 1.8313 - val_accuracy: 0.8043\n",
      "Epoch 88/150\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 3.1340e-08 - accuracy: 1.0000 - val_loss: 1.8332 - val_accuracy: 0.8043\n",
      "Epoch 89/150\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 3.0812e-08 - accuracy: 1.0000 - val_loss: 1.8351 - val_accuracy: 0.8043\n",
      "Epoch 90/150\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 3.0305e-08 - accuracy: 1.0000 - val_loss: 1.8369 - val_accuracy: 0.8043\n",
      "Epoch 91/150\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 2.9842e-08 - accuracy: 1.0000 - val_loss: 1.8387 - val_accuracy: 0.8043\n",
      "Epoch 92/150\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 2.9461e-08 - accuracy: 1.0000 - val_loss: 1.8406 - val_accuracy: 0.8043\n",
      "Epoch 93/150\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 2.9042e-08 - accuracy: 1.0000 - val_loss: 1.8425 - val_accuracy: 0.8043\n",
      "Epoch 94/150\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 2.8516e-08 - accuracy: 1.0000 - val_loss: 1.8444 - val_accuracy: 0.8043\n",
      "Epoch 95/150\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 2.8099e-08 - accuracy: 1.0000 - val_loss: 1.8462 - val_accuracy: 0.8043\n",
      "Epoch 96/150\n",
      "3/3 [==============================] - 0s 152ms/step - loss: 2.7683e-08 - accuracy: 1.0000 - val_loss: 1.8480 - val_accuracy: 0.8043\n",
      "Epoch 97/150\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 2.7279e-08 - accuracy: 1.0000 - val_loss: 1.8498 - val_accuracy: 0.8043\n",
      "Epoch 98/150\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 2.6873e-08 - accuracy: 1.0000 - val_loss: 1.8516 - val_accuracy: 0.8043\n",
      "Epoch 99/150\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 2.6472e-08 - accuracy: 1.0000 - val_loss: 1.8533 - val_accuracy: 0.8043\n",
      "Epoch 100/150\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 2.6065e-08 - accuracy: 1.0000 - val_loss: 1.8550 - val_accuracy: 0.8043\n",
      "Epoch 101/150\n",
      "3/3 [==============================] - 0s 174ms/step - loss: 2.5738e-08 - accuracy: 1.0000 - val_loss: 1.8567 - val_accuracy: 0.8043\n",
      "Epoch 102/150\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 2.5367e-08 - accuracy: 1.0000 - val_loss: 1.8584 - val_accuracy: 0.8043\n",
      "Epoch 103/150\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 2.5030e-08 - accuracy: 1.0000 - val_loss: 1.8601 - val_accuracy: 0.8043\n",
      "Epoch 104/150\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 2.4653e-08 - accuracy: 1.0000 - val_loss: 1.8617 - val_accuracy: 0.8043\n",
      "Epoch 105/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 126ms/step - loss: 2.4341e-08 - accuracy: 1.0000 - val_loss: 1.8634 - val_accuracy: 0.8043\n",
      "Epoch 106/150\n",
      "3/3 [==============================] - 0s 155ms/step - loss: 2.4014e-08 - accuracy: 1.0000 - val_loss: 1.8650 - val_accuracy: 0.8043\n",
      "Epoch 107/150\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 2.3665e-08 - accuracy: 1.0000 - val_loss: 1.8667 - val_accuracy: 0.8043\n",
      "Epoch 108/150\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 2.3347e-08 - accuracy: 1.0000 - val_loss: 1.8682 - val_accuracy: 0.8043\n",
      "Epoch 109/150\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 2.3015e-08 - accuracy: 1.0000 - val_loss: 1.8699 - val_accuracy: 0.8043\n",
      "Epoch 110/150\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 2.2739e-08 - accuracy: 1.0000 - val_loss: 1.8714 - val_accuracy: 0.8043\n",
      "Epoch 111/150\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 2.2432e-08 - accuracy: 1.0000 - val_loss: 1.8731 - val_accuracy: 0.8043\n",
      "Epoch 112/150\n",
      "3/3 [==============================] - 0s 150ms/step - loss: 2.2112e-08 - accuracy: 1.0000 - val_loss: 1.8745 - val_accuracy: 0.8043\n",
      "Epoch 113/150\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 2.1873e-08 - accuracy: 1.0000 - val_loss: 1.8761 - val_accuracy: 0.8043\n",
      "Epoch 114/150\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 2.1564e-08 - accuracy: 1.0000 - val_loss: 1.8776 - val_accuracy: 0.8043\n",
      "Epoch 115/150\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 2.1341e-08 - accuracy: 1.0000 - val_loss: 1.8792 - val_accuracy: 0.8043\n",
      "Epoch 116/150\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 2.1056e-08 - accuracy: 1.0000 - val_loss: 1.8808 - val_accuracy: 0.8043\n",
      "Epoch 117/150\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 2.0756e-08 - accuracy: 1.0000 - val_loss: 1.8822 - val_accuracy: 0.8043\n",
      "Epoch 118/150\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 2.0523e-08 - accuracy: 1.0000 - val_loss: 1.8837 - val_accuracy: 0.8043\n",
      "Epoch 119/150\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 2.0251e-08 - accuracy: 1.0000 - val_loss: 1.8851 - val_accuracy: 0.8043\n",
      "Epoch 120/150\n",
      "3/3 [==============================] - 0s 156ms/step - loss: 2.0027e-08 - accuracy: 1.0000 - val_loss: 1.8866 - val_accuracy: 0.8043\n",
      "Epoch 121/150\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 1.9823e-08 - accuracy: 1.0000 - val_loss: 1.8881 - val_accuracy: 0.8043\n",
      "Epoch 122/150\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 1.9525e-08 - accuracy: 1.0000 - val_loss: 1.8895 - val_accuracy: 0.8043\n",
      "Epoch 123/150\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 1.9338e-08 - accuracy: 1.0000 - val_loss: 1.8909 - val_accuracy: 0.8043\n",
      "Epoch 124/150\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 1.9099e-08 - accuracy: 1.0000 - val_loss: 1.8922 - val_accuracy: 0.8043\n",
      "Epoch 125/150\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 1.8858e-08 - accuracy: 1.0000 - val_loss: 1.8936 - val_accuracy: 0.8043\n",
      "Epoch 126/150\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 1.8650e-08 - accuracy: 1.0000 - val_loss: 1.8950 - val_accuracy: 0.8043\n",
      "Epoch 127/150\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 1.8420e-08 - accuracy: 1.0000 - val_loss: 1.8964 - val_accuracy: 0.8043\n",
      "Epoch 128/150\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 1.8232e-08 - accuracy: 1.0000 - val_loss: 1.8977 - val_accuracy: 0.8043\n",
      "Epoch 129/150\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 1.8067e-08 - accuracy: 1.0000 - val_loss: 1.8991 - val_accuracy: 0.8043\n",
      "Epoch 130/150\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 1.7797e-08 - accuracy: 1.0000 - val_loss: 1.9005 - val_accuracy: 0.8043\n",
      "Epoch 131/150\n",
      "3/3 [==============================] - 0s 157ms/step - loss: 1.7594e-08 - accuracy: 1.0000 - val_loss: 1.9017 - val_accuracy: 0.8043\n",
      "Epoch 132/150\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 1.7474e-08 - accuracy: 1.0000 - val_loss: 1.9032 - val_accuracy: 0.8043\n",
      "Epoch 133/150\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 1.7225e-08 - accuracy: 1.0000 - val_loss: 1.9044 - val_accuracy: 0.8043\n",
      "Epoch 134/150\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 1.7048e-08 - accuracy: 1.0000 - val_loss: 1.9058 - val_accuracy: 0.8043\n",
      "Epoch 135/150\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 1.6848e-08 - accuracy: 1.0000 - val_loss: 1.9071 - val_accuracy: 0.8043\n",
      "Epoch 136/150\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 1.6684e-08 - accuracy: 1.0000 - val_loss: 1.9084 - val_accuracy: 0.8043\n",
      "Epoch 137/150\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 1.6504e-08 - accuracy: 1.0000 - val_loss: 1.9097 - val_accuracy: 0.8043\n",
      "Epoch 138/150\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 1.6308e-08 - accuracy: 1.0000 - val_loss: 1.9109 - val_accuracy: 0.8043\n",
      "Epoch 139/150\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 1.6148e-08 - accuracy: 1.0000 - val_loss: 1.9121 - val_accuracy: 0.8043\n",
      "Epoch 140/150\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 1.5999e-08 - accuracy: 1.0000 - val_loss: 1.9134 - val_accuracy: 0.8043\n",
      "Epoch 141/150\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 1.5811e-08 - accuracy: 1.0000 - val_loss: 1.9147 - val_accuracy: 0.8043\n",
      "Epoch 142/150\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 1.5637e-08 - accuracy: 1.0000 - val_loss: 1.9159 - val_accuracy: 0.8043\n",
      "Epoch 143/150\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 1.5492e-08 - accuracy: 1.0000 - val_loss: 1.9171 - val_accuracy: 0.8043\n",
      "Epoch 144/150\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 1.5317e-08 - accuracy: 1.0000 - val_loss: 1.9183 - val_accuracy: 0.8043\n",
      "Epoch 145/150\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 1.5165e-08 - accuracy: 1.0000 - val_loss: 1.9195 - val_accuracy: 0.8043\n",
      "Epoch 146/150\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 1.5024e-08 - accuracy: 1.0000 - val_loss: 1.9207 - val_accuracy: 0.8043\n",
      "Epoch 147/150\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 1.4879e-08 - accuracy: 1.0000 - val_loss: 1.9220 - val_accuracy: 0.8043\n",
      "Epoch 148/150\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 1.4718e-08 - accuracy: 1.0000 - val_loss: 1.9232 - val_accuracy: 0.8043\n",
      "Epoch 149/150\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 1.4566e-08 - accuracy: 1.0000 - val_loss: 1.9243 - val_accuracy: 0.8043\n",
      "Epoch 150/150\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 1.4426e-08 - accuracy: 1.0000 - val_loss: 1.9255 - val_accuracy: 0.8043\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy',metrics=['accuracy'])\n",
    "model.summary()\n",
    "history = model.fit(X_train, y_train, batch_size = 256, epochs = 150, verbose = 1, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3b191978",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-11T04:58:24.376524Z",
     "start_time": "2023-05-11T04:58:24.363188Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best train accuracy: 1.0\n",
      "best validation accuracy: 0.8097826242446899\n"
     ]
    }
   ],
   "source": [
    "# train set에서 최고 정확도 출력\n",
    "train_acc = max(history.history['accuracy'])\n",
    "print(f\"best train accuracy: {train_acc}\")\n",
    "\n",
    "# validation set에서 최고 정확도 출력\n",
    "val_acc = max(history.history['val_accuracy'])\n",
    "print(f\"best validation accuracy: {val_acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e216040a",
   "metadata": {},
   "source": [
    "# segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f4ef4362",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-11T05:06:47.020270Z",
     "start_time": "2023-05-11T05:00:06.806582Z"
    }
   },
   "outputs": [],
   "source": [
    "# 읽어올 폴더 경로 설정\n",
    "data_folder = 'D:/Data/호흡데이터/Task1/Wav_segment/Healthy'\n",
    "# 읽어올 폴더 경로 설정(데이터 길이 구하기 위함)\n",
    "data_folder_unhealthy = 'D:/Data/호흡데이터/Task1/Wav_segment/Unhealthy'\n",
    "\n",
    "# 읽어올 파일 리스트 생성\n",
    "file_list = []\n",
    "for root, dirs, files in os.walk(data_folder):\n",
    "    for file in files:\n",
    "        if file.endswith('.wav'):\n",
    "            file_list.append(os.path.join(root, file))\n",
    "            \n",
    "            \n",
    "# 데이터 길이 맞추기위해 읽어올 파일 리스트 생성\n",
    "file_list_unhealthy = []\n",
    "for root, dirs, files_unhealthy in os.walk(data_folder_unhealthy):\n",
    "    for file_unhealthy in files_unhealthy:\n",
    "        if file.endswith('.wav'):\n",
    "            file_list_unhealthy.append(os.path.join(root, file_unhealthy))\n",
    "            \n",
    "\n",
    "# 가장 짧은 파일의 길이 구하기\n",
    "min_len = min([len(librosa.load(file_unhealthy)[0]) for file_unhealthy in file_list_unhealthy])\n",
    "\n",
    "# 데이터프레임 생성\n",
    "dfs = []\n",
    "for file in file_list:\n",
    "    # 오디오 파일 읽어오기\n",
    "    audio_data, sample_rate = librosa.load(file)\n",
    "    # 가장 짧은 길이에 맞게 데이터 자르기\n",
    "    audio_data = audio_data[:min_len]\n",
    "    # 시간 축 설정\n",
    "    time_axis = librosa.times_like(audio_data, sr=sample_rate)\n",
    "    # 채널 축 설정\n",
    "    channel_axis = ['Channel 1']\n",
    "    # 데이터프레임 생성\n",
    "    df = pd.DataFrame(audio_data.reshape(-1, len(channel_axis)), columns=channel_axis)\n",
    "    \n",
    "    dfs.append(df)\n",
    "\n",
    "# 모든 데이터프레임을 하나로 합치기\n",
    "df_healthy_segment = pd.concat(dfs, axis=1, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c99a6118",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-11T05:06:47.050479Z",
     "start_time": "2023-05-11T05:06:47.022265Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1049</th>\n",
       "      <th>1050</th>\n",
       "      <th>1051</th>\n",
       "      <th>1052</th>\n",
       "      <th>1053</th>\n",
       "      <th>1054</th>\n",
       "      <th>1055</th>\n",
       "      <th>1056</th>\n",
       "      <th>1057</th>\n",
       "      <th>1058</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.046845</td>\n",
       "      <td>0.041362</td>\n",
       "      <td>0.045014</td>\n",
       "      <td>0.042429</td>\n",
       "      <td>0.044503</td>\n",
       "      <td>0.042943</td>\n",
       "      <td>0.044295</td>\n",
       "      <td>0.043381</td>\n",
       "      <td>0.044117</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009509</td>\n",
       "      <td>-0.009669</td>\n",
       "      <td>-0.009785</td>\n",
       "      <td>-0.009950</td>\n",
       "      <td>-0.010110</td>\n",
       "      <td>-0.010219</td>\n",
       "      <td>-0.010342</td>\n",
       "      <td>-0.010498</td>\n",
       "      <td>-0.010709</td>\n",
       "      <td>-0.010857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.015574</td>\n",
       "      <td>-0.013833</td>\n",
       "      <td>-0.014993</td>\n",
       "      <td>-0.014043</td>\n",
       "      <td>-0.014767</td>\n",
       "      <td>-0.014348</td>\n",
       "      <td>-0.014734</td>\n",
       "      <td>-0.014374</td>\n",
       "      <td>-0.014731</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.020147</td>\n",
       "      <td>-0.019904</td>\n",
       "      <td>-0.019596</td>\n",
       "      <td>-0.019437</td>\n",
       "      <td>-0.019256</td>\n",
       "      <td>-0.019100</td>\n",
       "      <td>-0.018891</td>\n",
       "      <td>-0.018626</td>\n",
       "      <td>-0.018362</td>\n",
       "      <td>-0.018042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.009853</td>\n",
       "      <td>0.008797</td>\n",
       "      <td>0.009538</td>\n",
       "      <td>0.008882</td>\n",
       "      <td>0.009197</td>\n",
       "      <td>0.008704</td>\n",
       "      <td>0.008865</td>\n",
       "      <td>0.008397</td>\n",
       "      <td>0.008483</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020226</td>\n",
       "      <td>0.020147</td>\n",
       "      <td>0.020119</td>\n",
       "      <td>0.020081</td>\n",
       "      <td>0.020009</td>\n",
       "      <td>0.019864</td>\n",
       "      <td>0.019586</td>\n",
       "      <td>0.019478</td>\n",
       "      <td>0.019241</td>\n",
       "      <td>0.019131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.021034</td>\n",
       "      <td>-0.018488</td>\n",
       "      <td>-0.019934</td>\n",
       "      <td>-0.018670</td>\n",
       "      <td>-0.019521</td>\n",
       "      <td>-0.018758</td>\n",
       "      <td>-0.019308</td>\n",
       "      <td>-0.018987</td>\n",
       "      <td>-0.019389</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003142</td>\n",
       "      <td>-0.003174</td>\n",
       "      <td>-0.003282</td>\n",
       "      <td>-0.003376</td>\n",
       "      <td>-0.003326</td>\n",
       "      <td>-0.003357</td>\n",
       "      <td>-0.003325</td>\n",
       "      <td>-0.003361</td>\n",
       "      <td>-0.003306</td>\n",
       "      <td>-0.003254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.052770</td>\n",
       "      <td>-0.046424</td>\n",
       "      <td>-0.050493</td>\n",
       "      <td>-0.047534</td>\n",
       "      <td>-0.049899</td>\n",
       "      <td>-0.048158</td>\n",
       "      <td>-0.049694</td>\n",
       "      <td>-0.048599</td>\n",
       "      <td>-0.049473</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002189</td>\n",
       "      <td>0.002212</td>\n",
       "      <td>0.002147</td>\n",
       "      <td>0.002064</td>\n",
       "      <td>0.002035</td>\n",
       "      <td>0.001908</td>\n",
       "      <td>0.001919</td>\n",
       "      <td>0.001810</td>\n",
       "      <td>0.001689</td>\n",
       "      <td>0.001720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>0</td>\n",
       "      <td>0.042524</td>\n",
       "      <td>0.037193</td>\n",
       "      <td>0.040299</td>\n",
       "      <td>0.037739</td>\n",
       "      <td>0.039439</td>\n",
       "      <td>0.037841</td>\n",
       "      <td>0.038833</td>\n",
       "      <td>0.037786</td>\n",
       "      <td>0.038285</td>\n",
       "      <td>...</td>\n",
       "      <td>0.032260</td>\n",
       "      <td>0.031217</td>\n",
       "      <td>0.030373</td>\n",
       "      <td>0.029997</td>\n",
       "      <td>0.029996</td>\n",
       "      <td>0.030189</td>\n",
       "      <td>0.030780</td>\n",
       "      <td>0.031928</td>\n",
       "      <td>0.033635</td>\n",
       "      <td>0.035407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>0</td>\n",
       "      <td>0.069728</td>\n",
       "      <td>0.061119</td>\n",
       "      <td>0.066179</td>\n",
       "      <td>0.062124</td>\n",
       "      <td>0.065085</td>\n",
       "      <td>0.062366</td>\n",
       "      <td>0.064121</td>\n",
       "      <td>0.062450</td>\n",
       "      <td>0.063499</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009508</td>\n",
       "      <td>-0.009460</td>\n",
       "      <td>-0.009336</td>\n",
       "      <td>-0.009261</td>\n",
       "      <td>-0.009162</td>\n",
       "      <td>-0.009032</td>\n",
       "      <td>-0.008800</td>\n",
       "      <td>-0.008761</td>\n",
       "      <td>-0.008617</td>\n",
       "      <td>-0.008543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.065428</td>\n",
       "      <td>-0.057655</td>\n",
       "      <td>-0.062668</td>\n",
       "      <td>-0.059073</td>\n",
       "      <td>-0.061892</td>\n",
       "      <td>-0.059588</td>\n",
       "      <td>-0.061378</td>\n",
       "      <td>-0.059846</td>\n",
       "      <td>-0.060954</td>\n",
       "      <td>...</td>\n",
       "      <td>0.042345</td>\n",
       "      <td>0.042201</td>\n",
       "      <td>0.042254</td>\n",
       "      <td>0.042235</td>\n",
       "      <td>0.042100</td>\n",
       "      <td>0.042007</td>\n",
       "      <td>0.042053</td>\n",
       "      <td>0.041879</td>\n",
       "      <td>0.041938</td>\n",
       "      <td>0.041923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>0</td>\n",
       "      <td>0.060298</td>\n",
       "      <td>0.053246</td>\n",
       "      <td>0.057850</td>\n",
       "      <td>0.054521</td>\n",
       "      <td>0.057193</td>\n",
       "      <td>0.055197</td>\n",
       "      <td>0.056892</td>\n",
       "      <td>0.055551</td>\n",
       "      <td>0.056429</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.104225</td>\n",
       "      <td>-0.104604</td>\n",
       "      <td>-0.104782</td>\n",
       "      <td>-0.105152</td>\n",
       "      <td>-0.105339</td>\n",
       "      <td>-0.105547</td>\n",
       "      <td>-0.105633</td>\n",
       "      <td>-0.105679</td>\n",
       "      <td>-0.105681</td>\n",
       "      <td>-0.105616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.024169</td>\n",
       "      <td>-0.020916</td>\n",
       "      <td>-0.022408</td>\n",
       "      <td>-0.020647</td>\n",
       "      <td>-0.021556</td>\n",
       "      <td>-0.020300</td>\n",
       "      <td>-0.020615</td>\n",
       "      <td>-0.019800</td>\n",
       "      <td>-0.020054</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003731</td>\n",
       "      <td>-0.003483</td>\n",
       "      <td>-0.003444</td>\n",
       "      <td>-0.003248</td>\n",
       "      <td>-0.003196</td>\n",
       "      <td>-0.003103</td>\n",
       "      <td>-0.003094</td>\n",
       "      <td>-0.003158</td>\n",
       "      <td>-0.003115</td>\n",
       "      <td>-0.003255</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>322 rows × 1059 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     label         1         2         3         4         5         6  \\\n",
       "0        0  0.046845  0.041362  0.045014  0.042429  0.044503  0.042943   \n",
       "1        0 -0.015574 -0.013833 -0.014993 -0.014043 -0.014767 -0.014348   \n",
       "2        0  0.009853  0.008797  0.009538  0.008882  0.009197  0.008704   \n",
       "3        0 -0.021034 -0.018488 -0.019934 -0.018670 -0.019521 -0.018758   \n",
       "4        0 -0.052770 -0.046424 -0.050493 -0.047534 -0.049899 -0.048158   \n",
       "..     ...       ...       ...       ...       ...       ...       ...   \n",
       "317      0  0.042524  0.037193  0.040299  0.037739  0.039439  0.037841   \n",
       "318      0  0.069728  0.061119  0.066179  0.062124  0.065085  0.062366   \n",
       "319      0 -0.065428 -0.057655 -0.062668 -0.059073 -0.061892 -0.059588   \n",
       "320      0  0.060298  0.053246  0.057850  0.054521  0.057193  0.055197   \n",
       "321      0 -0.024169 -0.020916 -0.022408 -0.020647 -0.021556 -0.020300   \n",
       "\n",
       "            7         8         9  ...      1049      1050      1051  \\\n",
       "0    0.044295  0.043381  0.044117  ... -0.009509 -0.009669 -0.009785   \n",
       "1   -0.014734 -0.014374 -0.014731  ... -0.020147 -0.019904 -0.019596   \n",
       "2    0.008865  0.008397  0.008483  ...  0.020226  0.020147  0.020119   \n",
       "3   -0.019308 -0.018987 -0.019389  ... -0.003142 -0.003174 -0.003282   \n",
       "4   -0.049694 -0.048599 -0.049473  ...  0.002189  0.002212  0.002147   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "317  0.038833  0.037786  0.038285  ...  0.032260  0.031217  0.030373   \n",
       "318  0.064121  0.062450  0.063499  ... -0.009508 -0.009460 -0.009336   \n",
       "319 -0.061378 -0.059846 -0.060954  ...  0.042345  0.042201  0.042254   \n",
       "320  0.056892  0.055551  0.056429  ... -0.104225 -0.104604 -0.104782   \n",
       "321 -0.020615 -0.019800 -0.020054  ... -0.003731 -0.003483 -0.003444   \n",
       "\n",
       "         1052      1053      1054      1055      1056      1057      1058  \n",
       "0   -0.009950 -0.010110 -0.010219 -0.010342 -0.010498 -0.010709 -0.010857  \n",
       "1   -0.019437 -0.019256 -0.019100 -0.018891 -0.018626 -0.018362 -0.018042  \n",
       "2    0.020081  0.020009  0.019864  0.019586  0.019478  0.019241  0.019131  \n",
       "3   -0.003376 -0.003326 -0.003357 -0.003325 -0.003361 -0.003306 -0.003254  \n",
       "4    0.002064  0.002035  0.001908  0.001919  0.001810  0.001689  0.001720  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "317  0.029997  0.029996  0.030189  0.030780  0.031928  0.033635  0.035407  \n",
       "318 -0.009261 -0.009162 -0.009032 -0.008800 -0.008761 -0.008617 -0.008543  \n",
       "319  0.042235  0.042100  0.042007  0.042053  0.041879  0.041938  0.041923  \n",
       "320 -0.105152 -0.105339 -0.105547 -0.105633 -0.105679 -0.105681 -0.105616  \n",
       "321 -0.003248 -0.003196 -0.003103 -0.003094 -0.003158 -0.003115 -0.003255  \n",
       "\n",
       "[322 rows x 1059 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_healthy_segment = df_healthy_segment.transpose()\n",
    "df_healthy_segment.rename(columns={0 : 'label'}, inplace=True)\n",
    "df_healthy_segment['label'] = 0\n",
    "df_healthy_segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "be1bad02",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-11T05:18:47.738428Z",
     "start_time": "2023-05-11T05:06:47.051476Z"
    }
   },
   "outputs": [],
   "source": [
    "# 읽어올 폴더 경로 설정\n",
    "data_folder = 'D:/Data/호흡데이터/Task1/Wav_segment/Unhealthy'\n",
    "\n",
    "# 읽어올 파일 리스트 생성\n",
    "file_list = []\n",
    "for root, dirs, files in os.walk(data_folder):\n",
    "    for file in files:\n",
    "        if file.endswith('.wav'):\n",
    "            file_list.append(os.path.join(root, file))\n",
    "\n",
    "# 가장 짧은 파일의 길이 구하기\n",
    "min_len = min([len(librosa.load(file)[0]) for file in file_list])\n",
    "\n",
    "# 데이터프레임 생성\n",
    "dfs = []\n",
    "for file in file_list:\n",
    "    # 오디오 파일 읽어오기\n",
    "    audio_data, sample_rate = librosa.load(file)\n",
    "    # 가장 짧은 길이에 맞게 데이터 자르기\n",
    "    audio_data = audio_data[:min_len]\n",
    "    # 시간 축 설정\n",
    "    time_axis = librosa.times_like(audio_data, sr=sample_rate)\n",
    "    # 채널 축 설정\n",
    "    channel_axis = ['Channel 1']\n",
    "    # 데이터프레임 생성\n",
    "    df = pd.DataFrame(audio_data.reshape(-1, len(channel_axis)), columns=channel_axis)\n",
    "    \n",
    "    dfs.append(df)\n",
    "\n",
    "# 모든 데이터프레임을 하나로 합치기\n",
    "df_unhealthy_segment = pd.concat(dfs, axis=1, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "393f86f8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-11T05:18:47.858083Z",
     "start_time": "2023-05-11T05:18:47.740393Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1049</th>\n",
       "      <th>1050</th>\n",
       "      <th>1051</th>\n",
       "      <th>1052</th>\n",
       "      <th>1053</th>\n",
       "      <th>1054</th>\n",
       "      <th>1055</th>\n",
       "      <th>1056</th>\n",
       "      <th>1057</th>\n",
       "      <th>1058</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.003693</td>\n",
       "      <td>-0.003417</td>\n",
       "      <td>-0.003740</td>\n",
       "      <td>-0.003609</td>\n",
       "      <td>-0.003878</td>\n",
       "      <td>-0.003735</td>\n",
       "      <td>-0.003992</td>\n",
       "      <td>-0.003988</td>\n",
       "      <td>-0.004031</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.054604</td>\n",
       "      <td>-0.054661</td>\n",
       "      <td>-0.054841</td>\n",
       "      <td>-0.054933</td>\n",
       "      <td>-0.054882</td>\n",
       "      <td>-0.054955</td>\n",
       "      <td>-0.055035</td>\n",
       "      <td>-0.055172</td>\n",
       "      <td>-0.055131</td>\n",
       "      <td>-0.055180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.099915</td>\n",
       "      <td>-0.087809</td>\n",
       "      <td>-0.095247</td>\n",
       "      <td>-0.089586</td>\n",
       "      <td>-0.093977</td>\n",
       "      <td>-0.090251</td>\n",
       "      <td>-0.092868</td>\n",
       "      <td>-0.090588</td>\n",
       "      <td>-0.092129</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.090444</td>\n",
       "      <td>-0.090096</td>\n",
       "      <td>-0.089726</td>\n",
       "      <td>-0.089194</td>\n",
       "      <td>-0.088959</td>\n",
       "      <td>-0.088632</td>\n",
       "      <td>-0.088248</td>\n",
       "      <td>-0.087994</td>\n",
       "      <td>-0.087688</td>\n",
       "      <td>-0.087345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.028217</td>\n",
       "      <td>0.024996</td>\n",
       "      <td>0.027193</td>\n",
       "      <td>0.025651</td>\n",
       "      <td>0.027094</td>\n",
       "      <td>0.026221</td>\n",
       "      <td>0.026985</td>\n",
       "      <td>0.026474</td>\n",
       "      <td>0.027070</td>\n",
       "      <td>...</td>\n",
       "      <td>0.059308</td>\n",
       "      <td>0.059223</td>\n",
       "      <td>0.058934</td>\n",
       "      <td>0.058737</td>\n",
       "      <td>0.058451</td>\n",
       "      <td>0.058186</td>\n",
       "      <td>0.058045</td>\n",
       "      <td>0.057905</td>\n",
       "      <td>0.057863</td>\n",
       "      <td>0.057752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.026931</td>\n",
       "      <td>0.023891</td>\n",
       "      <td>0.026022</td>\n",
       "      <td>0.024644</td>\n",
       "      <td>0.025983</td>\n",
       "      <td>0.025059</td>\n",
       "      <td>0.025753</td>\n",
       "      <td>0.025256</td>\n",
       "      <td>0.025655</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.025749</td>\n",
       "      <td>-0.025832</td>\n",
       "      <td>-0.025924</td>\n",
       "      <td>-0.026023</td>\n",
       "      <td>-0.026161</td>\n",
       "      <td>-0.026159</td>\n",
       "      <td>-0.026201</td>\n",
       "      <td>-0.026270</td>\n",
       "      <td>-0.026277</td>\n",
       "      <td>-0.026317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.059426</td>\n",
       "      <td>0.052245</td>\n",
       "      <td>0.056828</td>\n",
       "      <td>0.053359</td>\n",
       "      <td>0.055949</td>\n",
       "      <td>0.053820</td>\n",
       "      <td>0.055476</td>\n",
       "      <td>0.054281</td>\n",
       "      <td>0.055336</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.026483</td>\n",
       "      <td>-0.026363</td>\n",
       "      <td>-0.026168</td>\n",
       "      <td>-0.026054</td>\n",
       "      <td>-0.025773</td>\n",
       "      <td>-0.025622</td>\n",
       "      <td>-0.025524</td>\n",
       "      <td>-0.025400</td>\n",
       "      <td>-0.025244</td>\n",
       "      <td>-0.025193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6571</th>\n",
       "      <td>1</td>\n",
       "      <td>0.179154</td>\n",
       "      <td>0.157903</td>\n",
       "      <td>0.171524</td>\n",
       "      <td>0.161279</td>\n",
       "      <td>0.168878</td>\n",
       "      <td>0.162411</td>\n",
       "      <td>0.167137</td>\n",
       "      <td>0.163014</td>\n",
       "      <td>0.165699</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001285</td>\n",
       "      <td>0.001285</td>\n",
       "      <td>0.001164</td>\n",
       "      <td>0.001156</td>\n",
       "      <td>0.001157</td>\n",
       "      <td>0.001029</td>\n",
       "      <td>0.000951</td>\n",
       "      <td>0.000871</td>\n",
       "      <td>0.000781</td>\n",
       "      <td>0.000741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6572</th>\n",
       "      <td>1</td>\n",
       "      <td>0.006466</td>\n",
       "      <td>0.005275</td>\n",
       "      <td>0.005454</td>\n",
       "      <td>0.004694</td>\n",
       "      <td>0.004632</td>\n",
       "      <td>0.004100</td>\n",
       "      <td>0.003986</td>\n",
       "      <td>0.003438</td>\n",
       "      <td>0.003049</td>\n",
       "      <td>...</td>\n",
       "      <td>0.038782</td>\n",
       "      <td>0.038324</td>\n",
       "      <td>0.037962</td>\n",
       "      <td>0.037507</td>\n",
       "      <td>0.037265</td>\n",
       "      <td>0.036894</td>\n",
       "      <td>0.036672</td>\n",
       "      <td>0.036327</td>\n",
       "      <td>0.035937</td>\n",
       "      <td>0.035690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6573</th>\n",
       "      <td>1</td>\n",
       "      <td>0.035796</td>\n",
       "      <td>0.031475</td>\n",
       "      <td>0.034012</td>\n",
       "      <td>0.031747</td>\n",
       "      <td>0.033035</td>\n",
       "      <td>0.031451</td>\n",
       "      <td>0.032101</td>\n",
       "      <td>0.031015</td>\n",
       "      <td>0.031319</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001874</td>\n",
       "      <td>-0.001763</td>\n",
       "      <td>-0.001532</td>\n",
       "      <td>-0.001271</td>\n",
       "      <td>-0.001049</td>\n",
       "      <td>-0.000838</td>\n",
       "      <td>-0.000657</td>\n",
       "      <td>-0.000376</td>\n",
       "      <td>-0.000099</td>\n",
       "      <td>0.000192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6574</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.049789</td>\n",
       "      <td>-0.043592</td>\n",
       "      <td>-0.047203</td>\n",
       "      <td>-0.044249</td>\n",
       "      <td>-0.046084</td>\n",
       "      <td>-0.044158</td>\n",
       "      <td>-0.045249</td>\n",
       "      <td>-0.043926</td>\n",
       "      <td>-0.044602</td>\n",
       "      <td>...</td>\n",
       "      <td>0.102576</td>\n",
       "      <td>0.102426</td>\n",
       "      <td>0.102349</td>\n",
       "      <td>0.102191</td>\n",
       "      <td>0.102019</td>\n",
       "      <td>0.101875</td>\n",
       "      <td>0.101817</td>\n",
       "      <td>0.101674</td>\n",
       "      <td>0.101624</td>\n",
       "      <td>0.101678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6575</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.042801</td>\n",
       "      <td>-0.037612</td>\n",
       "      <td>-0.040856</td>\n",
       "      <td>-0.038495</td>\n",
       "      <td>-0.040384</td>\n",
       "      <td>-0.038768</td>\n",
       "      <td>-0.039878</td>\n",
       "      <td>-0.038926</td>\n",
       "      <td>-0.039675</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.051101</td>\n",
       "      <td>-0.050532</td>\n",
       "      <td>-0.049931</td>\n",
       "      <td>-0.049304</td>\n",
       "      <td>-0.048700</td>\n",
       "      <td>-0.048108</td>\n",
       "      <td>-0.047467</td>\n",
       "      <td>-0.046625</td>\n",
       "      <td>-0.046147</td>\n",
       "      <td>-0.045456</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6576 rows × 1059 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      label         1         2         3         4         5         6  \\\n",
       "0         1 -0.003693 -0.003417 -0.003740 -0.003609 -0.003878 -0.003735   \n",
       "1         1 -0.099915 -0.087809 -0.095247 -0.089586 -0.093977 -0.090251   \n",
       "2         1  0.028217  0.024996  0.027193  0.025651  0.027094  0.026221   \n",
       "3         1  0.026931  0.023891  0.026022  0.024644  0.025983  0.025059   \n",
       "4         1  0.059426  0.052245  0.056828  0.053359  0.055949  0.053820   \n",
       "...     ...       ...       ...       ...       ...       ...       ...   \n",
       "6571      1  0.179154  0.157903  0.171524  0.161279  0.168878  0.162411   \n",
       "6572      1  0.006466  0.005275  0.005454  0.004694  0.004632  0.004100   \n",
       "6573      1  0.035796  0.031475  0.034012  0.031747  0.033035  0.031451   \n",
       "6574      1 -0.049789 -0.043592 -0.047203 -0.044249 -0.046084 -0.044158   \n",
       "6575      1 -0.042801 -0.037612 -0.040856 -0.038495 -0.040384 -0.038768   \n",
       "\n",
       "             7         8         9  ...      1049      1050      1051  \\\n",
       "0    -0.003992 -0.003988 -0.004031  ... -0.054604 -0.054661 -0.054841   \n",
       "1    -0.092868 -0.090588 -0.092129  ... -0.090444 -0.090096 -0.089726   \n",
       "2     0.026985  0.026474  0.027070  ...  0.059308  0.059223  0.058934   \n",
       "3     0.025753  0.025256  0.025655  ... -0.025749 -0.025832 -0.025924   \n",
       "4     0.055476  0.054281  0.055336  ... -0.026483 -0.026363 -0.026168   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "6571  0.167137  0.163014  0.165699  ...  0.001285  0.001285  0.001164   \n",
       "6572  0.003986  0.003438  0.003049  ...  0.038782  0.038324  0.037962   \n",
       "6573  0.032101  0.031015  0.031319  ... -0.001874 -0.001763 -0.001532   \n",
       "6574 -0.045249 -0.043926 -0.044602  ...  0.102576  0.102426  0.102349   \n",
       "6575 -0.039878 -0.038926 -0.039675  ... -0.051101 -0.050532 -0.049931   \n",
       "\n",
       "          1052      1053      1054      1055      1056      1057      1058  \n",
       "0    -0.054933 -0.054882 -0.054955 -0.055035 -0.055172 -0.055131 -0.055180  \n",
       "1    -0.089194 -0.088959 -0.088632 -0.088248 -0.087994 -0.087688 -0.087345  \n",
       "2     0.058737  0.058451  0.058186  0.058045  0.057905  0.057863  0.057752  \n",
       "3    -0.026023 -0.026161 -0.026159 -0.026201 -0.026270 -0.026277 -0.026317  \n",
       "4    -0.026054 -0.025773 -0.025622 -0.025524 -0.025400 -0.025244 -0.025193  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "6571  0.001156  0.001157  0.001029  0.000951  0.000871  0.000781  0.000741  \n",
       "6572  0.037507  0.037265  0.036894  0.036672  0.036327  0.035937  0.035690  \n",
       "6573 -0.001271 -0.001049 -0.000838 -0.000657 -0.000376 -0.000099  0.000192  \n",
       "6574  0.102191  0.102019  0.101875  0.101817  0.101674  0.101624  0.101678  \n",
       "6575 -0.049304 -0.048700 -0.048108 -0.047467 -0.046625 -0.046147 -0.045456  \n",
       "\n",
       "[6576 rows x 1059 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_unhealthy_segment = df_unhealthy_segment.transpose()\n",
    "df_unhealthy_segment.rename(columns={0 : 'label'}, inplace=True)\n",
    "df_unhealthy_segment['label'] = 1\n",
    "df_unhealthy_segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bed7bd36",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-11T05:18:47.888067Z",
     "start_time": "2023-05-11T05:18:47.859081Z"
    }
   },
   "outputs": [],
   "source": [
    "df_segment = pd.concat([df_healthy_segment, df_unhealthy_segment], axis=0)\n",
    "df_segment\n",
    "\n",
    "label_col = 'label' # 라벨이 되는 열 이름\n",
    "data_cols = df_segment.columns[df_segment.columns != label_col].tolist() # 나머지 열 이름"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "af5e6d07",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-11T05:18:47.918017Z",
     "start_time": "2023-05-11T05:18:47.890064Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1049</th>\n",
       "      <th>1050</th>\n",
       "      <th>1051</th>\n",
       "      <th>1052</th>\n",
       "      <th>1053</th>\n",
       "      <th>1054</th>\n",
       "      <th>1055</th>\n",
       "      <th>1056</th>\n",
       "      <th>1057</th>\n",
       "      <th>1058</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.046845</td>\n",
       "      <td>0.041362</td>\n",
       "      <td>0.045014</td>\n",
       "      <td>0.042429</td>\n",
       "      <td>0.044503</td>\n",
       "      <td>0.042943</td>\n",
       "      <td>0.044295</td>\n",
       "      <td>0.043381</td>\n",
       "      <td>0.044117</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009509</td>\n",
       "      <td>-0.009669</td>\n",
       "      <td>-0.009785</td>\n",
       "      <td>-0.009950</td>\n",
       "      <td>-0.010110</td>\n",
       "      <td>-0.010219</td>\n",
       "      <td>-0.010342</td>\n",
       "      <td>-0.010498</td>\n",
       "      <td>-0.010709</td>\n",
       "      <td>-0.010857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.015574</td>\n",
       "      <td>-0.013833</td>\n",
       "      <td>-0.014993</td>\n",
       "      <td>-0.014043</td>\n",
       "      <td>-0.014767</td>\n",
       "      <td>-0.014348</td>\n",
       "      <td>-0.014734</td>\n",
       "      <td>-0.014374</td>\n",
       "      <td>-0.014731</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.020147</td>\n",
       "      <td>-0.019904</td>\n",
       "      <td>-0.019596</td>\n",
       "      <td>-0.019437</td>\n",
       "      <td>-0.019256</td>\n",
       "      <td>-0.019100</td>\n",
       "      <td>-0.018891</td>\n",
       "      <td>-0.018626</td>\n",
       "      <td>-0.018362</td>\n",
       "      <td>-0.018042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.009853</td>\n",
       "      <td>0.008797</td>\n",
       "      <td>0.009538</td>\n",
       "      <td>0.008882</td>\n",
       "      <td>0.009197</td>\n",
       "      <td>0.008704</td>\n",
       "      <td>0.008865</td>\n",
       "      <td>0.008397</td>\n",
       "      <td>0.008483</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020226</td>\n",
       "      <td>0.020147</td>\n",
       "      <td>0.020119</td>\n",
       "      <td>0.020081</td>\n",
       "      <td>0.020009</td>\n",
       "      <td>0.019864</td>\n",
       "      <td>0.019586</td>\n",
       "      <td>0.019478</td>\n",
       "      <td>0.019241</td>\n",
       "      <td>0.019131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.021034</td>\n",
       "      <td>-0.018488</td>\n",
       "      <td>-0.019934</td>\n",
       "      <td>-0.018670</td>\n",
       "      <td>-0.019521</td>\n",
       "      <td>-0.018758</td>\n",
       "      <td>-0.019308</td>\n",
       "      <td>-0.018987</td>\n",
       "      <td>-0.019389</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003142</td>\n",
       "      <td>-0.003174</td>\n",
       "      <td>-0.003282</td>\n",
       "      <td>-0.003376</td>\n",
       "      <td>-0.003326</td>\n",
       "      <td>-0.003357</td>\n",
       "      <td>-0.003325</td>\n",
       "      <td>-0.003361</td>\n",
       "      <td>-0.003306</td>\n",
       "      <td>-0.003254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.052770</td>\n",
       "      <td>-0.046424</td>\n",
       "      <td>-0.050493</td>\n",
       "      <td>-0.047534</td>\n",
       "      <td>-0.049899</td>\n",
       "      <td>-0.048158</td>\n",
       "      <td>-0.049694</td>\n",
       "      <td>-0.048599</td>\n",
       "      <td>-0.049473</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002189</td>\n",
       "      <td>0.002212</td>\n",
       "      <td>0.002147</td>\n",
       "      <td>0.002064</td>\n",
       "      <td>0.002035</td>\n",
       "      <td>0.001908</td>\n",
       "      <td>0.001919</td>\n",
       "      <td>0.001810</td>\n",
       "      <td>0.001689</td>\n",
       "      <td>0.001720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6571</th>\n",
       "      <td>1</td>\n",
       "      <td>0.179154</td>\n",
       "      <td>0.157903</td>\n",
       "      <td>0.171524</td>\n",
       "      <td>0.161279</td>\n",
       "      <td>0.168878</td>\n",
       "      <td>0.162411</td>\n",
       "      <td>0.167137</td>\n",
       "      <td>0.163014</td>\n",
       "      <td>0.165699</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001285</td>\n",
       "      <td>0.001285</td>\n",
       "      <td>0.001164</td>\n",
       "      <td>0.001156</td>\n",
       "      <td>0.001157</td>\n",
       "      <td>0.001029</td>\n",
       "      <td>0.000951</td>\n",
       "      <td>0.000871</td>\n",
       "      <td>0.000781</td>\n",
       "      <td>0.000741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6572</th>\n",
       "      <td>1</td>\n",
       "      <td>0.006466</td>\n",
       "      <td>0.005275</td>\n",
       "      <td>0.005454</td>\n",
       "      <td>0.004694</td>\n",
       "      <td>0.004632</td>\n",
       "      <td>0.004100</td>\n",
       "      <td>0.003986</td>\n",
       "      <td>0.003438</td>\n",
       "      <td>0.003049</td>\n",
       "      <td>...</td>\n",
       "      <td>0.038782</td>\n",
       "      <td>0.038324</td>\n",
       "      <td>0.037962</td>\n",
       "      <td>0.037507</td>\n",
       "      <td>0.037265</td>\n",
       "      <td>0.036894</td>\n",
       "      <td>0.036672</td>\n",
       "      <td>0.036327</td>\n",
       "      <td>0.035937</td>\n",
       "      <td>0.035690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6573</th>\n",
       "      <td>1</td>\n",
       "      <td>0.035796</td>\n",
       "      <td>0.031475</td>\n",
       "      <td>0.034012</td>\n",
       "      <td>0.031747</td>\n",
       "      <td>0.033035</td>\n",
       "      <td>0.031451</td>\n",
       "      <td>0.032101</td>\n",
       "      <td>0.031015</td>\n",
       "      <td>0.031319</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001874</td>\n",
       "      <td>-0.001763</td>\n",
       "      <td>-0.001532</td>\n",
       "      <td>-0.001271</td>\n",
       "      <td>-0.001049</td>\n",
       "      <td>-0.000838</td>\n",
       "      <td>-0.000657</td>\n",
       "      <td>-0.000376</td>\n",
       "      <td>-0.000099</td>\n",
       "      <td>0.000192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6574</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.049789</td>\n",
       "      <td>-0.043592</td>\n",
       "      <td>-0.047203</td>\n",
       "      <td>-0.044249</td>\n",
       "      <td>-0.046084</td>\n",
       "      <td>-0.044158</td>\n",
       "      <td>-0.045249</td>\n",
       "      <td>-0.043926</td>\n",
       "      <td>-0.044602</td>\n",
       "      <td>...</td>\n",
       "      <td>0.102576</td>\n",
       "      <td>0.102426</td>\n",
       "      <td>0.102349</td>\n",
       "      <td>0.102191</td>\n",
       "      <td>0.102019</td>\n",
       "      <td>0.101875</td>\n",
       "      <td>0.101817</td>\n",
       "      <td>0.101674</td>\n",
       "      <td>0.101624</td>\n",
       "      <td>0.101678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6575</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.042801</td>\n",
       "      <td>-0.037612</td>\n",
       "      <td>-0.040856</td>\n",
       "      <td>-0.038495</td>\n",
       "      <td>-0.040384</td>\n",
       "      <td>-0.038768</td>\n",
       "      <td>-0.039878</td>\n",
       "      <td>-0.038926</td>\n",
       "      <td>-0.039675</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.051101</td>\n",
       "      <td>-0.050532</td>\n",
       "      <td>-0.049931</td>\n",
       "      <td>-0.049304</td>\n",
       "      <td>-0.048700</td>\n",
       "      <td>-0.048108</td>\n",
       "      <td>-0.047467</td>\n",
       "      <td>-0.046625</td>\n",
       "      <td>-0.046147</td>\n",
       "      <td>-0.045456</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6898 rows × 1059 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      label         1         2         3         4         5         6  \\\n",
       "0         0  0.046845  0.041362  0.045014  0.042429  0.044503  0.042943   \n",
       "1         0 -0.015574 -0.013833 -0.014993 -0.014043 -0.014767 -0.014348   \n",
       "2         0  0.009853  0.008797  0.009538  0.008882  0.009197  0.008704   \n",
       "3         0 -0.021034 -0.018488 -0.019934 -0.018670 -0.019521 -0.018758   \n",
       "4         0 -0.052770 -0.046424 -0.050493 -0.047534 -0.049899 -0.048158   \n",
       "...     ...       ...       ...       ...       ...       ...       ...   \n",
       "6571      1  0.179154  0.157903  0.171524  0.161279  0.168878  0.162411   \n",
       "6572      1  0.006466  0.005275  0.005454  0.004694  0.004632  0.004100   \n",
       "6573      1  0.035796  0.031475  0.034012  0.031747  0.033035  0.031451   \n",
       "6574      1 -0.049789 -0.043592 -0.047203 -0.044249 -0.046084 -0.044158   \n",
       "6575      1 -0.042801 -0.037612 -0.040856 -0.038495 -0.040384 -0.038768   \n",
       "\n",
       "             7         8         9  ...      1049      1050      1051  \\\n",
       "0     0.044295  0.043381  0.044117  ... -0.009509 -0.009669 -0.009785   \n",
       "1    -0.014734 -0.014374 -0.014731  ... -0.020147 -0.019904 -0.019596   \n",
       "2     0.008865  0.008397  0.008483  ...  0.020226  0.020147  0.020119   \n",
       "3    -0.019308 -0.018987 -0.019389  ... -0.003142 -0.003174 -0.003282   \n",
       "4    -0.049694 -0.048599 -0.049473  ...  0.002189  0.002212  0.002147   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "6571  0.167137  0.163014  0.165699  ...  0.001285  0.001285  0.001164   \n",
       "6572  0.003986  0.003438  0.003049  ...  0.038782  0.038324  0.037962   \n",
       "6573  0.032101  0.031015  0.031319  ... -0.001874 -0.001763 -0.001532   \n",
       "6574 -0.045249 -0.043926 -0.044602  ...  0.102576  0.102426  0.102349   \n",
       "6575 -0.039878 -0.038926 -0.039675  ... -0.051101 -0.050532 -0.049931   \n",
       "\n",
       "          1052      1053      1054      1055      1056      1057      1058  \n",
       "0    -0.009950 -0.010110 -0.010219 -0.010342 -0.010498 -0.010709 -0.010857  \n",
       "1    -0.019437 -0.019256 -0.019100 -0.018891 -0.018626 -0.018362 -0.018042  \n",
       "2     0.020081  0.020009  0.019864  0.019586  0.019478  0.019241  0.019131  \n",
       "3    -0.003376 -0.003326 -0.003357 -0.003325 -0.003361 -0.003306 -0.003254  \n",
       "4     0.002064  0.002035  0.001908  0.001919  0.001810  0.001689  0.001720  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "6571  0.001156  0.001157  0.001029  0.000951  0.000871  0.000781  0.000741  \n",
       "6572  0.037507  0.037265  0.036894  0.036672  0.036327  0.035937  0.035690  \n",
       "6573 -0.001271 -0.001049 -0.000838 -0.000657 -0.000376 -0.000099  0.000192  \n",
       "6574  0.102191  0.102019  0.101875  0.101817  0.101674  0.101624  0.101678  \n",
       "6575 -0.049304 -0.048700 -0.048108 -0.047467 -0.046625 -0.046147 -0.045456  \n",
       "\n",
       "[6898 rows x 1059 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a2823315",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-11T05:18:47.962869Z",
     "start_time": "2023-05-11T05:18:47.919983Z"
    }
   },
   "outputs": [],
   "source": [
    "X = df_segment[data_cols]\n",
    "y = df_segment[label_col]\n",
    "\n",
    "X_train_segment, X_test_segment, y_train_segment, y_test_segment = train_test_split(X, y, test_size=0.2, random_state=12)\n",
    "\n",
    "X_train_segment = np.array(X_train_segment)\n",
    "X_test_segment = np.array(X_test_segment)\n",
    "y_train_segment = np.array(y_train_segment)\n",
    "y_test_segment = np.array(y_test_segment)\n",
    "\n",
    "# 라벨을 one-hot 인코딩으로 변환\n",
    "y_train_segment = to_categorical(y_train_segment)\n",
    "y_test_segment = to_categorical(y_test_segment)\n",
    "\n",
    "X_train_segment = X_train_segment.reshape(X_train_segment.shape[0], 1, X_train_segment.shape[1])\n",
    "X_test_segment = X_test_segment.reshape(X_test_segment.shape[0], 1, X_test_segment.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a2ba458",
   "metadata": {},
   "source": [
    "## Wavenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ac6e30ee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-08T07:57:23.622718Z",
     "start_time": "2023-05-08T07:53:03.517095Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "44/44 [==============================] - 2s 17ms/step - loss: 0.2783 - accuracy: 0.9353\n",
      "Epoch 2/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.1730 - accuracy: 0.9552\n",
      "Epoch 3/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.1633 - accuracy: 0.9552\n",
      "Epoch 4/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.1622 - accuracy: 0.9552\n",
      "Epoch 5/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.1588 - accuracy: 0.9552\n",
      "Epoch 6/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.1579 - accuracy: 0.9552\n",
      "Epoch 7/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.1566 - accuracy: 0.9552\n",
      "Epoch 8/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.1524 - accuracy: 0.9552\n",
      "Epoch 9/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.1524 - accuracy: 0.9552\n",
      "Epoch 10/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.1506 - accuracy: 0.9552\n",
      "Epoch 11/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.1455 - accuracy: 0.9552\n",
      "Epoch 12/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.1456 - accuracy: 0.9552\n",
      "Epoch 13/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.1510 - accuracy: 0.9552\n",
      "Epoch 14/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.1430 - accuracy: 0.9552\n",
      "Epoch 15/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.1402 - accuracy: 0.9552\n",
      "Epoch 16/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.1370 - accuracy: 0.9552\n",
      "Epoch 17/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.1351 - accuracy: 0.9552\n",
      "Epoch 18/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.1357 - accuracy: 0.9552\n",
      "Epoch 19/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.1328 - accuracy: 0.9552\n",
      "Epoch 20/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.1324 - accuracy: 0.9552\n",
      "Epoch 21/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.1287 - accuracy: 0.9552\n",
      "Epoch 22/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.1307 - accuracy: 0.9560\n",
      "Epoch 23/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.1253 - accuracy: 0.9554\n",
      "Epoch 24/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.1183 - accuracy: 0.9560\n",
      "Epoch 25/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.1277 - accuracy: 0.9563\n",
      "Epoch 26/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.1205 - accuracy: 0.9556\n",
      "Epoch 27/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.1126 - accuracy: 0.9572\n",
      "Epoch 28/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.1183 - accuracy: 0.9563\n",
      "Epoch 29/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.1141 - accuracy: 0.9569\n",
      "Epoch 30/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.1101 - accuracy: 0.9570\n",
      "Epoch 31/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.1082 - accuracy: 0.9581\n",
      "Epoch 32/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.1051 - accuracy: 0.9599\n",
      "Epoch 33/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.1101 - accuracy: 0.9583\n",
      "Epoch 34/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.1004 - accuracy: 0.9612\n",
      "Epoch 35/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.1016 - accuracy: 0.9594\n",
      "Epoch 36/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.0996 - accuracy: 0.9610\n",
      "Epoch 37/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.0996 - accuracy: 0.9621\n",
      "Epoch 38/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.1064 - accuracy: 0.9623\n",
      "Epoch 39/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.0944 - accuracy: 0.9612\n",
      "Epoch 40/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.0964 - accuracy: 0.9632\n",
      "Epoch 41/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.0884 - accuracy: 0.9650\n",
      "Epoch 42/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.0904 - accuracy: 0.9665\n",
      "Epoch 43/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.0816 - accuracy: 0.9672\n",
      "Epoch 44/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.0798 - accuracy: 0.9681\n",
      "Epoch 45/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.0882 - accuracy: 0.9672\n",
      "Epoch 46/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.0718 - accuracy: 0.9703\n",
      "Epoch 47/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.0699 - accuracy: 0.9710\n",
      "Epoch 48/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.0809 - accuracy: 0.9697\n",
      "Epoch 49/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.0870 - accuracy: 0.9654\n",
      "Epoch 50/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.0846 - accuracy: 0.9686\n",
      "Epoch 51/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.0739 - accuracy: 0.9708\n",
      "Epoch 52/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.0591 - accuracy: 0.9754\n",
      "Epoch 53/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.0605 - accuracy: 0.9741\n",
      "Epoch 54/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.0603 - accuracy: 0.9757\n",
      "Epoch 55/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.0699 - accuracy: 0.9750\n",
      "Epoch 56/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.0528 - accuracy: 0.9788\n",
      "Epoch 57/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.0560 - accuracy: 0.9799\n",
      "Epoch 58/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.0534 - accuracy: 0.9781\n",
      "Epoch 59/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.0456 - accuracy: 0.9822\n",
      "Epoch 60/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.0574 - accuracy: 0.9775\n",
      "Epoch 61/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.0525 - accuracy: 0.9795\n",
      "Epoch 62/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.0591 - accuracy: 0.9757\n",
      "Epoch 63/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.0472 - accuracy: 0.9815\n",
      "Epoch 64/500\n",
      "44/44 [==============================] - 1s 11ms/step - loss: 0.0424 - accuracy: 0.9833\n",
      "Epoch 65/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.0466 - accuracy: 0.9808\n",
      "Epoch 66/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.0349 - accuracy: 0.9860\n",
      "Epoch 67/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.0570 - accuracy: 0.9821\n",
      "Epoch 68/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.0392 - accuracy: 0.9842\n",
      "Epoch 69/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.0517 - accuracy: 0.9812\n",
      "Epoch 70/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.0547 - accuracy: 0.9799\n",
      "Epoch 71/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.0324 - accuracy: 0.9873\n",
      "Epoch 72/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.0394 - accuracy: 0.9848\n",
      "Epoch 73/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.0386 - accuracy: 0.9846\n",
      "Epoch 74/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.0313 - accuracy: 0.9875\n",
      "Epoch 75/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.0431 - accuracy: 0.9846\n",
      "Epoch 76/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.0294 - accuracy: 0.9879\n",
      "Epoch 77/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.0308 - accuracy: 0.9889\n",
      "Epoch 78/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.0275 - accuracy: 0.9886\n",
      "Epoch 79/500\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.0370 - accuracy: 0.9880\n",
      "Epoch 80/500\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.0455 - accuracy: 0.9839\n",
      "Epoch 81/500\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.0292 - accuracy: 0.9888\n",
      "Epoch 82/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.0294 - accuracy: 0.9891\n",
      "Epoch 83/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.0250 - accuracy: 0.9897\n",
      "Epoch 84/500\n",
      "44/44 [==============================] - 1s 11ms/step - loss: 0.0172 - accuracy: 0.9928\n",
      "Epoch 85/500\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.0199 - accuracy: 0.9909\n",
      "Epoch 86/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.0209 - accuracy: 0.9920\n",
      "Epoch 87/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.0381 - accuracy: 0.9904\n",
      "Epoch 88/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.0207 - accuracy: 0.9924\n",
      "Epoch 89/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.0194 - accuracy: 0.9935\n",
      "Epoch 90/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.0195 - accuracy: 0.9920\n",
      "Epoch 91/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.0443 - accuracy: 0.9853\n",
      "Epoch 92/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.0256 - accuracy: 0.9893\n",
      "Epoch 93/500\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.0135 - accuracy: 0.9946\n",
      "Epoch 94/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.0179 - accuracy: 0.9928\n",
      "Epoch 95/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.0184 - accuracy: 0.9931\n",
      "Epoch 96/500\n",
      "44/44 [==============================] - 1s 11ms/step - loss: 0.0163 - accuracy: 0.9926\n",
      "Epoch 97/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.0228 - accuracy: 0.9915\n",
      "Epoch 98/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.0194 - accuracy: 0.9931\n",
      "Epoch 99/500\n",
      "44/44 [==============================] - 1s 11ms/step - loss: 0.0194 - accuracy: 0.9931\n",
      "Epoch 100/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.0240 - accuracy: 0.9900\n",
      "Epoch 101/500\n",
      "44/44 [==============================] - 1s 11ms/step - loss: 0.0277 - accuracy: 0.9920\n",
      "Epoch 102/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.0197 - accuracy: 0.9929\n",
      "Epoch 103/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.0140 - accuracy: 0.9947\n",
      "Epoch 104/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.0158 - accuracy: 0.9949\n",
      "Epoch 105/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.0393 - accuracy: 0.9877\n",
      "Epoch 106/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.0256 - accuracy: 0.9918\n",
      "Epoch 107/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.0228 - accuracy: 0.9915\n",
      "Epoch 108/500\n",
      "44/44 [==============================] - 1s 11ms/step - loss: 0.0136 - accuracy: 0.9957\n",
      "Epoch 109/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.0141 - accuracy: 0.9960\n",
      "Epoch 110/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.0236 - accuracy: 0.9933\n",
      "Epoch 111/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.0162 - accuracy: 0.9947\n",
      "Epoch 112/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.0165 - accuracy: 0.9942\n",
      "Epoch 113/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.0133 - accuracy: 0.9951\n",
      "Epoch 114/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.0103 - accuracy: 0.9960\n",
      "Epoch 115/500\n",
      "44/44 [==============================] - 1s 11ms/step - loss: 0.0117 - accuracy: 0.9964\n",
      "Epoch 116/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.0148 - accuracy: 0.9940\n",
      "Epoch 117/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.0163 - accuracy: 0.9942\n",
      "Epoch 118/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.0201 - accuracy: 0.9933\n",
      "Epoch 119/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.0514 - accuracy: 0.9830\n",
      "Epoch 120/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.0285 - accuracy: 0.9886\n",
      "Epoch 121/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.0160 - accuracy: 0.9949\n",
      "Epoch 122/500\n",
      "44/44 [==============================] - 1s 11ms/step - loss: 0.0098 - accuracy: 0.9962\n",
      "Epoch 123/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.0090 - accuracy: 0.9966\n",
      "Epoch 124/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.0130 - accuracy: 0.9944\n",
      "Epoch 125/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.0174 - accuracy: 0.9935\n",
      "Epoch 126/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.0335 - accuracy: 0.9873\n",
      "Epoch 127/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.0170 - accuracy: 0.9931\n",
      "Epoch 128/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.0123 - accuracy: 0.9951\n",
      "Epoch 129/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.0261 - accuracy: 0.9920\n",
      "Epoch 130/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.0253 - accuracy: 0.9900\n",
      "Epoch 131/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.0113 - accuracy: 0.9960\n",
      "Epoch 132/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.0097 - accuracy: 0.9967\n",
      "Epoch 133/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.0081 - accuracy: 0.9964\n",
      "Epoch 134/500\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.0137 - accuracy: 0.9946\n",
      "Epoch 135/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.0187 - accuracy: 0.9938\n",
      "Epoch 136/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.0397 - accuracy: 0.9879\n",
      "Epoch 137/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.0224 - accuracy: 0.9926\n",
      "Epoch 138/500\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.0166 - accuracy: 0.9942\n",
      "Epoch 139/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.0120 - accuracy: 0.9957\n",
      "Epoch 140/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.0231 - accuracy: 0.9922\n",
      "Epoch 141/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.0173 - accuracy: 0.9938\n",
      "Epoch 142/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.0174 - accuracy: 0.9937\n",
      "Epoch 143/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.0173 - accuracy: 0.9946\n",
      "Epoch 144/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.0063 - accuracy: 0.9971\n",
      "Epoch 145/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.0205 - accuracy: 0.9942\n",
      "Epoch 146/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.0497 - accuracy: 0.9819\n",
      "Epoch 147/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.0188 - accuracy: 0.9935\n",
      "Epoch 148/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.0173 - accuracy: 0.9944\n",
      "Epoch 149/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.0107 - accuracy: 0.9964\n",
      "Epoch 150/500\n",
      "44/44 [==============================] - 1s 11ms/step - loss: 0.0115 - accuracy: 0.9955\n",
      "Epoch 151/500\n",
      "44/44 [==============================] - 1s 11ms/step - loss: 0.0074 - accuracy: 0.9969\n",
      "Epoch 152/500\n",
      "44/44 [==============================] - 1s 11ms/step - loss: 0.0128 - accuracy: 0.9960\n",
      "Epoch 153/500\n",
      "44/44 [==============================] - 1s 11ms/step - loss: 0.0097 - accuracy: 0.9962\n",
      "Epoch 154/500\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.0081 - accuracy: 0.9971\n",
      "Epoch 155/500\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.0114 - accuracy: 0.9962\n",
      "Epoch 156/500\n",
      "44/44 [==============================] - 1s 11ms/step - loss: 0.0200 - accuracy: 0.9935\n",
      "Epoch 157/500\n",
      "44/44 [==============================] - 1s 11ms/step - loss: 0.0267 - accuracy: 0.9929\n",
      "Epoch 158/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.0157 - accuracy: 0.9938\n",
      "Epoch 159/500\n",
      "44/44 [==============================] - 1s 11ms/step - loss: 0.0107 - accuracy: 0.9955\n",
      "Epoch 160/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.0214 - accuracy: 0.9953\n",
      "Epoch 161/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.0143 - accuracy: 0.9960\n",
      "Epoch 162/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44/44 [==============================] - 1s 12ms/step - loss: 0.0167 - accuracy: 0.9940\n",
      "Epoch 163/500\n",
      "44/44 [==============================] - 1s 11ms/step - loss: 0.0216 - accuracy: 0.9924\n",
      "Epoch 164/500\n",
      "44/44 [==============================] - 1s 11ms/step - loss: 0.0200 - accuracy: 0.9929\n",
      "Epoch 165/500\n",
      "44/44 [==============================] - 1s 11ms/step - loss: 0.0110 - accuracy: 0.9967\n",
      "Epoch 166/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.0038 - accuracy: 0.9987\n",
      "Epoch 167/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.0022 - accuracy: 0.9995\n",
      "Epoch 168/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.0082 - accuracy: 0.9980\n",
      "Epoch 169/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.0364 - accuracy: 0.9900\n",
      "Epoch 170/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.0219 - accuracy: 0.9911\n",
      "Epoch 171/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.0094 - accuracy: 0.9975\n",
      "Epoch 172/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.0075 - accuracy: 0.9975\n",
      "Epoch 173/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.0041 - accuracy: 0.9987\n",
      "Epoch 174/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.0035 - accuracy: 0.9982\n",
      "Epoch 175/500\n",
      "44/44 [==============================] - 1s 11ms/step - loss: 0.0124 - accuracy: 0.9962\n",
      "Epoch 176/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.0531 - accuracy: 0.9857\n",
      "Epoch 177/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.0252 - accuracy: 0.9908\n",
      "Epoch 178/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.0210 - accuracy: 0.9924\n",
      "Epoch 179/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.0209 - accuracy: 0.9928\n",
      "Epoch 180/500\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.0146 - accuracy: 0.9958\n",
      "Epoch 181/500\n",
      "44/44 [==============================] - 1s 11ms/step - loss: 0.0066 - accuracy: 0.9973\n",
      "Epoch 182/500\n",
      "44/44 [==============================] - 1s 11ms/step - loss: 0.0030 - accuracy: 0.9989\n",
      "Epoch 183/500\n",
      "44/44 [==============================] - 1s 11ms/step - loss: 0.0088 - accuracy: 0.9969\n",
      "Epoch 184/500\n",
      "44/44 [==============================] - 1s 11ms/step - loss: 0.0121 - accuracy: 0.9966\n",
      "Epoch 185/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.0117 - accuracy: 0.9964\n",
      "Epoch 186/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.0167 - accuracy: 0.9940\n",
      "Epoch 187/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.0157 - accuracy: 0.9955\n",
      "Epoch 188/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.0053 - accuracy: 0.9986\n",
      "Epoch 189/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.0267 - accuracy: 0.9933\n",
      "Epoch 190/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.0350 - accuracy: 0.9859\n",
      "Epoch 191/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.0185 - accuracy: 0.9929\n",
      "Epoch 192/500\n",
      "44/44 [==============================] - 1s 11ms/step - loss: 0.0112 - accuracy: 0.9964\n",
      "Epoch 193/500\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.0057 - accuracy: 0.9982\n",
      "Epoch 194/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.0118 - accuracy: 0.9967\n",
      "Epoch 195/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.0252 - accuracy: 0.9913\n",
      "Epoch 196/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.0221 - accuracy: 0.9928\n",
      "Epoch 197/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.0116 - accuracy: 0.9960\n",
      "Epoch 198/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.0060 - accuracy: 0.9976\n",
      "Epoch 199/500\n",
      "44/44 [==============================] - 1s 11ms/step - loss: 0.0039 - accuracy: 0.9986\n",
      "Epoch 200/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.0020 - accuracy: 0.9993\n",
      "Epoch 201/500\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.0013 - accuracy: 0.9996\n",
      "Epoch 202/500\n",
      "44/44 [==============================] - 1s 11ms/step - loss: 0.0027 - accuracy: 0.9995\n",
      "Epoch 203/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.0016 - accuracy: 0.9996\n",
      "Epoch 204/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.0016 - accuracy: 0.9995\n",
      "Epoch 205/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.0016 - accuracy: 0.9998\n",
      "Epoch 206/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 5.6031e-04 - accuracy: 1.0000\n",
      "Epoch 207/500\n",
      "44/44 [==============================] - 1s 11ms/step - loss: 0.0015 - accuracy: 0.9993\n",
      "Epoch 208/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.0301 - accuracy: 0.9933\n",
      "Epoch 209/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.0355 - accuracy: 0.9864\n",
      "Epoch 210/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.0311 - accuracy: 0.9904\n",
      "Epoch 211/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.0160 - accuracy: 0.9938\n",
      "Epoch 212/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.0089 - accuracy: 0.9971\n",
      "Epoch 213/500\n",
      "44/44 [==============================] - 1s 11ms/step - loss: 0.0069 - accuracy: 0.9976\n",
      "Epoch 214/500\n",
      "44/44 [==============================] - 1s 11ms/step - loss: 0.0055 - accuracy: 0.9982\n",
      "Epoch 215/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.0245 - accuracy: 0.9947\n",
      "Epoch 216/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.0139 - accuracy: 0.9946\n",
      "Epoch 217/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.0148 - accuracy: 0.9953\n",
      "Epoch 218/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.0082 - accuracy: 0.9969\n",
      "Epoch 219/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.0030 - accuracy: 0.9986\n",
      "Epoch 220/500\n",
      "44/44 [==============================] - 1s 11ms/step - loss: 6.9114e-04 - accuracy: 1.0000\n",
      "Epoch 221/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 8.2734e-04 - accuracy: 0.9998\n",
      "Epoch 222/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.0032 - accuracy: 0.9991\n",
      "Epoch 223/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.0013 - accuracy: 0.9998\n",
      "Epoch 224/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.0047 - accuracy: 0.9984\n",
      "Epoch 225/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.0039 - accuracy: 0.9987\n",
      "Epoch 226/500\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.0053 - accuracy: 0.9982\n",
      "Epoch 227/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.0047 - accuracy: 0.9984\n",
      "Epoch 228/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.0065 - accuracy: 0.9989\n",
      "Epoch 229/500\n",
      "44/44 [==============================] - 1s 11ms/step - loss: 0.0068 - accuracy: 0.9973\n",
      "Epoch 230/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.0023 - accuracy: 0.9993\n",
      "Epoch 231/500\n",
      "44/44 [==============================] - 1s 11ms/step - loss: 6.1480e-04 - accuracy: 1.0000\n",
      "Epoch 232/500\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 4.7634e-04 - accuracy: 1.0000\n",
      "Epoch 233/500\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.0033 - accuracy: 0.9989\n",
      "Epoch 234/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.0049 - accuracy: 0.9989\n",
      "Epoch 235/500\n",
      "44/44 [==============================] - 1s 11ms/step - loss: 0.0045 - accuracy: 0.9987\n",
      "Epoch 236/500\n",
      "44/44 [==============================] - 1s 11ms/step - loss: 0.0026 - accuracy: 0.9993\n",
      "Epoch 237/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.0040 - accuracy: 0.9980\n",
      "Epoch 238/500\n",
      "44/44 [==============================] - 1s 11ms/step - loss: 0.0256 - accuracy: 0.9928\n",
      "Epoch 239/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.0363 - accuracy: 0.9884\n",
      "Epoch 240/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.0254 - accuracy: 0.9915\n",
      "Epoch 241/500\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.0090 - accuracy: 0.9976\n",
      "Epoch 242/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.0075 - accuracy: 0.9984\n",
      "Epoch 243/500\n",
      "44/44 [==============================] - 1s 11ms/step - loss: 0.0057 - accuracy: 0.9978\n",
      "Epoch 244/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.0359 - accuracy: 0.9897\n",
      "Epoch 245/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.0177 - accuracy: 0.9938\n",
      "Epoch 246/500\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.0106 - accuracy: 0.9962\n",
      "Epoch 247/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.0050 - accuracy: 0.9980\n",
      "Epoch 248/500\n",
      "44/44 [==============================] - 1s 11ms/step - loss: 0.0037 - accuracy: 0.9984\n",
      "Epoch 249/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.0030 - accuracy: 0.9987\n",
      "Epoch 250/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.0139 - accuracy: 0.9967\n",
      "Epoch 251/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.0142 - accuracy: 0.9947\n",
      "Epoch 252/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.0057 - accuracy: 0.9978\n",
      "Epoch 253/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.0045 - accuracy: 0.9984\n",
      "Epoch 254/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.0074 - accuracy: 0.9975\n",
      "Epoch 255/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.0049 - accuracy: 0.9987\n",
      "Epoch 256/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.0086 - accuracy: 0.9969\n",
      "Epoch 257/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.0333 - accuracy: 0.9888\n",
      "Epoch 258/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.0294 - accuracy: 0.9904\n",
      "Epoch 259/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.0110 - accuracy: 0.9973\n",
      "Epoch 260/500\n",
      "44/44 [==============================] - 1s 11ms/step - loss: 0.0084 - accuracy: 0.9969\n",
      "Epoch 261/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.0173 - accuracy: 0.9937\n",
      "Epoch 262/500\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.0205 - accuracy: 0.9929\n",
      "Epoch 263/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.0086 - accuracy: 0.9967\n",
      "Epoch 264/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.0062 - accuracy: 0.9986\n",
      "Epoch 265/500\n",
      "44/44 [==============================] - 1s 11ms/step - loss: 0.0154 - accuracy: 0.9949\n",
      "Epoch 266/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.0099 - accuracy: 0.9978\n",
      "Epoch 267/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.0082 - accuracy: 0.9975\n",
      "Epoch 268/500\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.0059 - accuracy: 0.9984\n",
      "Epoch 269/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.0017 - accuracy: 0.9998\n",
      "Epoch 270/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 7.1015e-04 - accuracy: 0.9998\n",
      "Epoch 271/500\n",
      "44/44 [==============================] - 1s 11ms/step - loss: 3.6009e-04 - accuracy: 1.0000\n",
      "Epoch 272/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 2.2531e-04 - accuracy: 1.0000\n",
      "Epoch 273/500\n",
      "44/44 [==============================] - 1s 11ms/step - loss: 1.4847e-04 - accuracy: 1.0000\n",
      "Epoch 274/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 1.1457e-04 - accuracy: 1.0000\n",
      "Epoch 275/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 9.2953e-05 - accuracy: 1.0000\n",
      "Epoch 276/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 7.9460e-05 - accuracy: 1.0000\n",
      "Epoch 277/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 6.7291e-05 - accuracy: 1.0000\n",
      "Epoch 278/500\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 5.6262e-05 - accuracy: 1.0000\n",
      "Epoch 279/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 4.5476e-05 - accuracy: 1.0000\n",
      "Epoch 280/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 3.7935e-05 - accuracy: 1.0000\n",
      "Epoch 281/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 3.0932e-05 - accuracy: 1.0000\n",
      "Epoch 282/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 2.4559e-05 - accuracy: 1.0000\n",
      "Epoch 283/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 1.9289e-05 - accuracy: 1.0000\n",
      "Epoch 284/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 1.6246e-05 - accuracy: 1.0000\n",
      "Epoch 285/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 1.4234e-05 - accuracy: 1.0000\n",
      "Epoch 286/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 1.2526e-05 - accuracy: 1.0000\n",
      "Epoch 287/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 1.1075e-05 - accuracy: 1.0000\n",
      "Epoch 288/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 9.5091e-06 - accuracy: 1.0000\n",
      "Epoch 289/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 8.0548e-06 - accuracy: 1.0000\n",
      "Epoch 290/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 5.9355e-06 - accuracy: 1.0000\n",
      "Epoch 291/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 4.8062e-06 - accuracy: 1.0000\n",
      "Epoch 292/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 4.1282e-06 - accuracy: 1.0000\n",
      "Epoch 293/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 3.3839e-06 - accuracy: 1.0000\n",
      "Epoch 294/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 2.8386e-06 - accuracy: 1.0000\n",
      "Epoch 295/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 2.4023e-06 - accuracy: 1.0000\n",
      "Epoch 296/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 2.0971e-06 - accuracy: 1.0000\n",
      "Epoch 297/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 1.8491e-06 - accuracy: 1.0000\n",
      "Epoch 298/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 1.6325e-06 - accuracy: 1.0000\n",
      "Epoch 299/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 1.4686e-06 - accuracy: 1.0000\n",
      "Epoch 300/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 1.3182e-06 - accuracy: 1.0000\n",
      "Epoch 301/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 1.1897e-06 - accuracy: 1.0000\n",
      "Epoch 302/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 1.0773e-06 - accuracy: 1.0000\n",
      "Epoch 303/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 9.8915e-07 - accuracy: 1.0000\n",
      "Epoch 304/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 8.9370e-07 - accuracy: 1.0000\n",
      "Epoch 305/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 8.1828e-07 - accuracy: 1.0000\n",
      "Epoch 306/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 7.5267e-07 - accuracy: 1.0000\n",
      "Epoch 307/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 6.9869e-07 - accuracy: 1.0000\n",
      "Epoch 308/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 6.4301e-07 - accuracy: 1.0000\n",
      "Epoch 309/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 6.0122e-07 - accuracy: 1.0000\n",
      "Epoch 310/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 5.6333e-07 - accuracy: 1.0000\n",
      "Epoch 311/500\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 5.1802e-07 - accuracy: 1.0000\n",
      "Epoch 312/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 4.8643e-07 - accuracy: 1.0000\n",
      "Epoch 313/500\n",
      "44/44 [==============================] - 1s 11ms/step - loss: 4.5498e-07 - accuracy: 1.0000\n",
      "Epoch 314/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 4.2620e-07 - accuracy: 1.0000\n",
      "Epoch 315/500\n",
      "44/44 [==============================] - 1s 11ms/step - loss: 3.9904e-07 - accuracy: 1.0000\n",
      "Epoch 316/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 3.7685e-07 - accuracy: 1.0000\n",
      "Epoch 317/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 3.6318e-07 - accuracy: 1.0000\n",
      "Epoch 318/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 3.3416e-07 - accuracy: 1.0000\n",
      "Epoch 319/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 3.1471e-07 - accuracy: 1.0000\n",
      "Epoch 320/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44/44 [==============================] - 1s 12ms/step - loss: 2.9820e-07 - accuracy: 1.0000\n",
      "Epoch 321/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 2.8202e-07 - accuracy: 1.0000\n",
      "Epoch 322/500\n",
      "44/44 [==============================] - 1s 11ms/step - loss: 2.6938e-07 - accuracy: 1.0000\n",
      "Epoch 323/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 2.5499e-07 - accuracy: 1.0000\n",
      "Epoch 324/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 2.4303e-07 - accuracy: 1.0000\n",
      "Epoch 325/500\n",
      "44/44 [==============================] - 1s 11ms/step - loss: 2.3943e-07 - accuracy: 1.0000\n",
      "Epoch 326/500\n",
      "44/44 [==============================] - 1s 11ms/step - loss: 2.1901e-07 - accuracy: 1.0000\n",
      "Epoch 327/500\n",
      "44/44 [==============================] - 1s 11ms/step - loss: 2.1071e-07 - accuracy: 1.0000\n",
      "Epoch 328/500\n",
      "44/44 [==============================] - 1s 11ms/step - loss: 2.0272e-07 - accuracy: 1.0000\n",
      "Epoch 329/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 1.9437e-07 - accuracy: 1.0000\n",
      "Epoch 330/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 1.8546e-07 - accuracy: 1.0000\n",
      "Epoch 331/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 1.7791e-07 - accuracy: 1.0000\n",
      "Epoch 332/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 1.6898e-07 - accuracy: 1.0000\n",
      "Epoch 333/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 1.6286e-07 - accuracy: 1.0000\n",
      "Epoch 334/500\n",
      "44/44 [==============================] - 1s 11ms/step - loss: 1.5678e-07 - accuracy: 1.0000\n",
      "Epoch 335/500\n",
      "44/44 [==============================] - 1s 11ms/step - loss: 1.5036e-07 - accuracy: 1.0000\n",
      "Epoch 336/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 1.4466e-07 - accuracy: 1.0000\n",
      "Epoch 337/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 1.3903e-07 - accuracy: 1.0000\n",
      "Epoch 338/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 1.3457e-07 - accuracy: 1.0000\n",
      "Epoch 339/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 1.2924e-07 - accuracy: 1.0000\n",
      "Epoch 340/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 1.2443e-07 - accuracy: 1.0000\n",
      "Epoch 341/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 1.2046e-07 - accuracy: 1.0000\n",
      "Epoch 342/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 1.1593e-07 - accuracy: 1.0000\n",
      "Epoch 343/500\n",
      "44/44 [==============================] - 1s 11ms/step - loss: 1.1269e-07 - accuracy: 1.0000\n",
      "Epoch 344/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 1.0809e-07 - accuracy: 1.0000\n",
      "Epoch 345/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 1.0485e-07 - accuracy: 1.0000\n",
      "Epoch 346/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 1.0123e-07 - accuracy: 1.0000\n",
      "Epoch 347/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 9.8162e-08 - accuracy: 1.0000\n",
      "Epoch 348/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 9.4508e-08 - accuracy: 1.0000\n",
      "Epoch 349/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 9.0983e-08 - accuracy: 1.0000\n",
      "Epoch 350/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 8.8193e-08 - accuracy: 1.0000\n",
      "Epoch 351/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 8.5134e-08 - accuracy: 1.0000\n",
      "Epoch 352/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 8.2510e-08 - accuracy: 1.0000\n",
      "Epoch 353/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 8.0005e-08 - accuracy: 1.0000\n",
      "Epoch 354/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 7.7226e-08 - accuracy: 1.0000\n",
      "Epoch 355/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 7.5109e-08 - accuracy: 1.0000\n",
      "Epoch 356/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 7.2413e-08 - accuracy: 1.0000\n",
      "Epoch 357/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 7.0680e-08 - accuracy: 1.0000\n",
      "Epoch 358/500\n",
      "44/44 [==============================] - 1s 11ms/step - loss: 6.8518e-08 - accuracy: 1.0000\n",
      "Epoch 359/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 6.6013e-08 - accuracy: 1.0000\n",
      "Epoch 360/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 6.4145e-08 - accuracy: 1.0000\n",
      "Epoch 361/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 6.2100e-08 - accuracy: 1.0000\n",
      "Epoch 362/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 6.0566e-08 - accuracy: 1.0000\n",
      "Epoch 363/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 5.8641e-08 - accuracy: 1.0000\n",
      "Epoch 364/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 5.6791e-08 - accuracy: 1.0000\n",
      "Epoch 365/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 5.5325e-08 - accuracy: 1.0000\n",
      "Epoch 366/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 5.3642e-08 - accuracy: 1.0000\n",
      "Epoch 367/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 5.2164e-08 - accuracy: 1.0000\n",
      "Epoch 368/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 5.0760e-08 - accuracy: 1.0000\n",
      "Epoch 369/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 4.9463e-08 - accuracy: 1.0000\n",
      "Epoch 370/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 4.7784e-08 - accuracy: 1.0000\n",
      "Epoch 371/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 4.6340e-08 - accuracy: 1.0000\n",
      "Epoch 372/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 4.5213e-08 - accuracy: 1.0000\n",
      "Epoch 373/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 4.3946e-08 - accuracy: 1.0000\n",
      "Epoch 374/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 4.2664e-08 - accuracy: 1.0000\n",
      "Epoch 375/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 4.1496e-08 - accuracy: 1.0000\n",
      "Epoch 376/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 4.0409e-08 - accuracy: 1.0000\n",
      "Epoch 377/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 3.9370e-08 - accuracy: 1.0000\n",
      "Epoch 378/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 3.8337e-08 - accuracy: 1.0000\n",
      "Epoch 379/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 3.7394e-08 - accuracy: 1.0000\n",
      "Epoch 380/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 3.6545e-08 - accuracy: 1.0000\n",
      "Epoch 381/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 3.5561e-08 - accuracy: 1.0000\n",
      "Epoch 382/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 3.4633e-08 - accuracy: 1.0000\n",
      "Epoch 383/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 3.3875e-08 - accuracy: 1.0000\n",
      "Epoch 384/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 3.2889e-08 - accuracy: 1.0000\n",
      "Epoch 385/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 3.2368e-08 - accuracy: 1.0000\n",
      "Epoch 386/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 3.1224e-08 - accuracy: 1.0000\n",
      "Epoch 387/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 3.0628e-08 - accuracy: 1.0000\n",
      "Epoch 388/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 2.9785e-08 - accuracy: 1.0000\n",
      "Epoch 389/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 2.9090e-08 - accuracy: 1.0000\n",
      "Epoch 390/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 2.8309e-08 - accuracy: 1.0000\n",
      "Epoch 391/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 2.7618e-08 - accuracy: 1.0000\n",
      "Epoch 392/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 2.7529e-08 - accuracy: 1.0000\n",
      "Epoch 393/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 2.6097e-08 - accuracy: 1.0000\n",
      "Epoch 394/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 2.5789e-08 - accuracy: 1.0000\n",
      "Epoch 395/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 2.4889e-08 - accuracy: 1.0000\n",
      "Epoch 396/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 2.4545e-08 - accuracy: 1.0000\n",
      "Epoch 397/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 2.3819e-08 - accuracy: 1.0000\n",
      "Epoch 398/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 2.3430e-08 - accuracy: 1.0000\n",
      "Epoch 399/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 2.3298e-08 - accuracy: 1.0000\n",
      "Epoch 400/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 2.2280e-08 - accuracy: 1.0000\n",
      "Epoch 401/500\n",
      "44/44 [==============================] - 1s 11ms/step - loss: 2.1704e-08 - accuracy: 1.0000\n",
      "Epoch 402/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 2.1186e-08 - accuracy: 1.0000\n",
      "Epoch 403/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 2.0952e-08 - accuracy: 1.0000\n",
      "Epoch 404/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 2.0209e-08 - accuracy: 1.0000\n",
      "Epoch 405/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 1.9694e-08 - accuracy: 1.0000\n",
      "Epoch 406/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 1.9214e-08 - accuracy: 1.0000\n",
      "Epoch 407/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 1.8844e-08 - accuracy: 1.0000\n",
      "Epoch 408/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 1.8585e-08 - accuracy: 1.0000\n",
      "Epoch 409/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 1.8009e-08 - accuracy: 1.0000\n",
      "Epoch 410/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 1.7666e-08 - accuracy: 1.0000\n",
      "Epoch 411/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 1.7266e-08 - accuracy: 1.0000\n",
      "Epoch 412/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 1.6995e-08 - accuracy: 1.0000\n",
      "Epoch 413/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 1.6554e-08 - accuracy: 1.0000\n",
      "Epoch 414/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 1.6336e-08 - accuracy: 1.0000\n",
      "Epoch 415/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 1.5887e-08 - accuracy: 1.0000\n",
      "Epoch 416/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 1.5608e-08 - accuracy: 1.0000\n",
      "Epoch 417/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 1.5339e-08 - accuracy: 1.0000\n",
      "Epoch 418/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 1.5029e-08 - accuracy: 1.0000\n",
      "Epoch 419/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 1.4684e-08 - accuracy: 1.0000\n",
      "Epoch 420/500\n",
      "44/44 [==============================] - 1s 11ms/step - loss: 1.4379e-08 - accuracy: 1.0000\n",
      "Epoch 421/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 1.4191e-08 - accuracy: 1.0000\n",
      "Epoch 422/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 1.3959e-08 - accuracy: 1.0000\n",
      "Epoch 423/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 1.3539e-08 - accuracy: 1.0000\n",
      "Epoch 424/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 1.3333e-08 - accuracy: 1.0000\n",
      "Epoch 425/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 1.3144e-08 - accuracy: 1.0000\n",
      "Epoch 426/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 1.2772e-08 - accuracy: 1.0000\n",
      "Epoch 427/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 1.2540e-08 - accuracy: 1.0000\n",
      "Epoch 428/500\n",
      "44/44 [==============================] - 1s 11ms/step - loss: 1.2316e-08 - accuracy: 1.0000\n",
      "Epoch 429/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 1.2117e-08 - accuracy: 1.0000\n",
      "Epoch 430/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 1.1834e-08 - accuracy: 1.0000\n",
      "Epoch 431/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 1.1654e-08 - accuracy: 1.0000\n",
      "Epoch 432/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 1.1409e-08 - accuracy: 1.0000\n",
      "Epoch 433/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 1.1206e-08 - accuracy: 1.0000\n",
      "Epoch 434/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 1.0985e-08 - accuracy: 1.0000\n",
      "Epoch 435/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 1.0774e-08 - accuracy: 1.0000\n",
      "Epoch 436/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 1.0609e-08 - accuracy: 1.0000\n",
      "Epoch 437/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 1.0386e-08 - accuracy: 1.0000\n",
      "Epoch 438/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 1.0260e-08 - accuracy: 1.0000\n",
      "Epoch 439/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 1.0048e-08 - accuracy: 1.0000\n",
      "Epoch 440/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 9.8642e-09 - accuracy: 1.0000\n",
      "Epoch 441/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 9.6862e-09 - accuracy: 1.0000\n",
      "Epoch 442/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 9.5170e-09 - accuracy: 1.0000\n",
      "Epoch 443/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 9.4099e-09 - accuracy: 1.0000\n",
      "Epoch 444/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 9.2482e-09 - accuracy: 1.0000\n",
      "Epoch 445/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 9.0134e-09 - accuracy: 1.0000\n",
      "Epoch 446/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 8.8591e-09 - accuracy: 1.0000\n",
      "Epoch 447/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 8.6805e-09 - accuracy: 1.0000\n",
      "Epoch 448/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 8.6187e-09 - accuracy: 1.0000\n",
      "Epoch 449/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 8.5529e-09 - accuracy: 1.0000\n",
      "Epoch 450/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 8.5527e-09 - accuracy: 1.0000\n",
      "Epoch 451/500\n",
      "44/44 [==============================] - 1s 11ms/step - loss: 8.0479e-09 - accuracy: 1.0000\n",
      "Epoch 452/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 7.9594e-09 - accuracy: 1.0000\n",
      "Epoch 453/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 7.8188e-09 - accuracy: 1.0000\n",
      "Epoch 454/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 7.6952e-09 - accuracy: 1.0000\n",
      "Epoch 455/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 7.5923e-09 - accuracy: 1.0000\n",
      "Epoch 456/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 7.4429e-09 - accuracy: 1.0000\n",
      "Epoch 457/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 7.3061e-09 - accuracy: 1.0000\n",
      "Epoch 458/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 7.1757e-09 - accuracy: 1.0000\n",
      "Epoch 459/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 7.0933e-09 - accuracy: 1.0000\n",
      "Epoch 460/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 6.9222e-09 - accuracy: 1.0000\n",
      "Epoch 461/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 6.8916e-09 - accuracy: 1.0000\n",
      "Epoch 462/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 6.7322e-09 - accuracy: 1.0000\n",
      "Epoch 463/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 6.6036e-09 - accuracy: 1.0000\n",
      "Epoch 464/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 6.4780e-09 - accuracy: 1.0000\n",
      "Epoch 465/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 6.3935e-09 - accuracy: 1.0000\n",
      "Epoch 466/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 6.2888e-09 - accuracy: 1.0000\n",
      "Epoch 467/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 6.5118e-09 - accuracy: 1.0000\n",
      "Epoch 468/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 6.1223e-09 - accuracy: 1.0000\n",
      "Epoch 469/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 5.9761e-09 - accuracy: 1.0000\n",
      "Epoch 470/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 5.8844e-09 - accuracy: 1.0000\n",
      "Epoch 471/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 5.7872e-09 - accuracy: 1.0000\n",
      "Epoch 472/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 5.6863e-09 - accuracy: 1.0000\n",
      "Epoch 473/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 5.6093e-09 - accuracy: 1.0000\n",
      "Epoch 474/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44/44 [==============================] - 1s 12ms/step - loss: 5.5264e-09 - accuracy: 1.0000\n",
      "Epoch 475/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 5.5537e-09 - accuracy: 1.0000\n",
      "Epoch 476/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 5.3397e-09 - accuracy: 1.0000\n",
      "Epoch 477/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 5.2578e-09 - accuracy: 1.0000\n",
      "Epoch 478/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 5.1851e-09 - accuracy: 1.0000\n",
      "Epoch 479/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 5.0946e-09 - accuracy: 1.0000\n",
      "Epoch 480/500\n",
      "44/44 [==============================] - 1s 11ms/step - loss: 5.0049e-09 - accuracy: 1.0000\n",
      "Epoch 481/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 4.9549e-09 - accuracy: 1.0000\n",
      "Epoch 482/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 4.8508e-09 - accuracy: 1.0000\n",
      "Epoch 483/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 4.7878e-09 - accuracy: 1.0000\n",
      "Epoch 484/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 4.7228e-09 - accuracy: 1.0000\n",
      "Epoch 485/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 4.6311e-09 - accuracy: 1.0000\n",
      "Epoch 486/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 4.5755e-09 - accuracy: 1.0000\n",
      "Epoch 487/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 4.5755e-09 - accuracy: 1.0000\n",
      "Epoch 488/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 4.4198e-09 - accuracy: 1.0000\n",
      "Epoch 489/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 4.3598e-09 - accuracy: 1.0000\n",
      "Epoch 490/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 4.3053e-09 - accuracy: 1.0000\n",
      "Epoch 491/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 4.2455e-09 - accuracy: 1.0000\n",
      "Epoch 492/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 4.1771e-09 - accuracy: 1.0000\n",
      "Epoch 493/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 4.1249e-09 - accuracy: 1.0000\n",
      "Epoch 494/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 4.0506e-09 - accuracy: 1.0000\n",
      "Epoch 495/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 4.0180e-09 - accuracy: 1.0000\n",
      "Epoch 496/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 3.9419e-09 - accuracy: 1.0000\n",
      "Epoch 497/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 3.8889e-09 - accuracy: 1.0000\n",
      "Epoch 498/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 3.8308e-09 - accuracy: 1.0000\n",
      "Epoch 499/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 3.7699e-09 - accuracy: 1.0000\n",
      "Epoch 500/500\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 3.7104e-09 - accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "inputs = Input(shape=(1, 1058))\n",
    "\n",
    "# Convolutional Layers\n",
    "residuals = []\n",
    "for dilation_rate in [1, 2, 4, 8, 16]:\n",
    "    x = Conv1D(128, 3, dilation_rate=dilation_rate, padding='same')(inputs)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv1D(128, 3, dilation_rate=dilation_rate, padding='same')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv1D(128, 3, dilation_rate=dilation_rate, padding='same')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    residuals.append(x)\n",
    "\n",
    "# Skip Connection\n",
    "x = Add()(residuals)\n",
    "x = Activation('relu')(x)\n",
    "\n",
    "# Fully-connected Layers\n",
    "x = Flatten()(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "x = Dense(2, activation='softmax')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98840e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "model_segment = Model(inputs=inputs, outputs=x)\n",
    "\n",
    "# 모델 컴파일\n",
    "model_segment.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# 모델 학습\n",
    "history = model_segment.fit(X_train_segment, y_train_segment, epochs=500, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e20a127e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-08T07:58:25.680702Z",
     "start_time": "2023-05-08T07:58:25.040930Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44/44 [==============================] - 1s 12ms/step - loss: 3.2672 - accuracy: 0.9203\n",
      "Test loss: 3.2672\n",
      "Test accuracy: 0.9203\n"
     ]
    }
   ],
   "source": [
    "# 모델 평가\n",
    "loss, accuracy = model_segment.evaluate(X_test_segment, y_test_segment)\n",
    "print(f\"Test loss: {loss:.4f}\")\n",
    "print(f\"Test accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37d53dc2",
   "metadata": {},
   "source": [
    "## Bi-LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "862b87f6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-11T05:19:18.415569Z",
     "start_time": "2023-05-11T05:19:17.917124Z"
    }
   },
   "outputs": [],
   "source": [
    "inputs = Input(shape=(1, 1058))\n",
    "\n",
    "# BiLSTM Layers\n",
    "x = Bidirectional(LSTM(256, return_sequences=True))(inputs)\n",
    "x = Bidirectional(LSTM(256))(x)\n",
    "\n",
    "# Fully-connected Layers\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dense(2, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e58d2d52",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-11T05:20:09.437730Z",
     "start_time": "2023-05-11T05:19:33.450513Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 1, 1058)]         0         \n",
      "                                                                 \n",
      " bidirectional_4 (Bidirectio  (None, 1, 512)           2693120   \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " bidirectional_5 (Bidirectio  (None, 512)              1574912   \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 256)               131328    \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 2)                 514       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,399,874\n",
      "Trainable params: 4,399,874\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/150\n",
      "22/22 [==============================] - 4s 51ms/step - loss: 0.3832 - accuracy: 0.9346 - val_loss: 0.2921 - val_accuracy: 0.9457\n",
      "Epoch 2/150\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.2139 - accuracy: 0.9552 - val_loss: 0.2305 - val_accuracy: 0.9457\n",
      "Epoch 3/150\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.1864 - accuracy: 0.9552 - val_loss: 0.2097 - val_accuracy: 0.9457\n",
      "Epoch 4/150\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.1701 - accuracy: 0.9552 - val_loss: 0.2058 - val_accuracy: 0.9457\n",
      "Epoch 5/150\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.1688 - accuracy: 0.9552 - val_loss: 0.2064 - val_accuracy: 0.9457\n",
      "Epoch 6/150\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.1665 - accuracy: 0.9552 - val_loss: 0.2061 - val_accuracy: 0.9457\n",
      "Epoch 7/150\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.1625 - accuracy: 0.9552 - val_loss: 0.2038 - val_accuracy: 0.9457\n",
      "Epoch 8/150\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.1608 - accuracy: 0.9552 - val_loss: 0.1965 - val_accuracy: 0.9457\n",
      "Epoch 9/150\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.1585 - accuracy: 0.9552 - val_loss: 0.2004 - val_accuracy: 0.9457\n",
      "Epoch 10/150\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.1578 - accuracy: 0.9552 - val_loss: 0.1984 - val_accuracy: 0.9457\n",
      "Epoch 11/150\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.1574 - accuracy: 0.9552 - val_loss: 0.2058 - val_accuracy: 0.9457\n",
      "Epoch 12/150\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.1551 - accuracy: 0.9552 - val_loss: 0.1986 - val_accuracy: 0.9457\n",
      "Epoch 13/150\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.1536 - accuracy: 0.9554 - val_loss: 0.2087 - val_accuracy: 0.9457\n",
      "Epoch 14/150\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.1556 - accuracy: 0.9552 - val_loss: 0.2022 - val_accuracy: 0.9457\n",
      "Epoch 15/150\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.1494 - accuracy: 0.9554 - val_loss: 0.2043 - val_accuracy: 0.9457\n",
      "Epoch 16/150\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.1503 - accuracy: 0.9554 - val_loss: 0.2039 - val_accuracy: 0.9457\n",
      "Epoch 17/150\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.1521 - accuracy: 0.9551 - val_loss: 0.1970 - val_accuracy: 0.9457\n",
      "Epoch 18/150\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.1479 - accuracy: 0.9552 - val_loss: 0.2048 - val_accuracy: 0.9457\n",
      "Epoch 19/150\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.1474 - accuracy: 0.9554 - val_loss: 0.2120 - val_accuracy: 0.9449\n",
      "Epoch 20/150\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.1457 - accuracy: 0.9556 - val_loss: 0.2124 - val_accuracy: 0.9457\n",
      "Epoch 21/150\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.1438 - accuracy: 0.9558 - val_loss: 0.2093 - val_accuracy: 0.9457\n",
      "Epoch 22/150\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.1416 - accuracy: 0.9561 - val_loss: 0.2123 - val_accuracy: 0.9449\n",
      "Epoch 23/150\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.1383 - accuracy: 0.9563 - val_loss: 0.2189 - val_accuracy: 0.9449\n",
      "Epoch 24/150\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.1376 - accuracy: 0.9560 - val_loss: 0.2166 - val_accuracy: 0.9457\n",
      "Epoch 25/150\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.1382 - accuracy: 0.9560 - val_loss: 0.2147 - val_accuracy: 0.9449\n",
      "Epoch 26/150\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.1342 - accuracy: 0.9563 - val_loss: 0.2239 - val_accuracy: 0.9449\n",
      "Epoch 27/150\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.1347 - accuracy: 0.9563 - val_loss: 0.2163 - val_accuracy: 0.9428\n",
      "Epoch 28/150\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.1328 - accuracy: 0.9563 - val_loss: 0.2336 - val_accuracy: 0.9428\n",
      "Epoch 29/150\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.1329 - accuracy: 0.9558 - val_loss: 0.2213 - val_accuracy: 0.9457\n",
      "Epoch 30/150\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.1282 - accuracy: 0.9563 - val_loss: 0.2262 - val_accuracy: 0.9413\n",
      "Epoch 31/150\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.1299 - accuracy: 0.9570 - val_loss: 0.2248 - val_accuracy: 0.9435\n",
      "Epoch 32/150\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.1322 - accuracy: 0.9556 - val_loss: 0.2235 - val_accuracy: 0.9442\n",
      "Epoch 33/150\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.1257 - accuracy: 0.9578 - val_loss: 0.2368 - val_accuracy: 0.9449\n",
      "Epoch 34/150\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.1267 - accuracy: 0.9567 - val_loss: 0.2397 - val_accuracy: 0.9435\n",
      "Epoch 35/150\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.1268 - accuracy: 0.9574 - val_loss: 0.2516 - val_accuracy: 0.9362\n",
      "Epoch 36/150\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.1242 - accuracy: 0.9578 - val_loss: 0.2437 - val_accuracy: 0.9435\n",
      "Epoch 37/150\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.1205 - accuracy: 0.9590 - val_loss: 0.2664 - val_accuracy: 0.9312\n",
      "Epoch 38/150\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.1234 - accuracy: 0.9574 - val_loss: 0.2359 - val_accuracy: 0.9391\n",
      "Epoch 39/150\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.1236 - accuracy: 0.9587 - val_loss: 0.2359 - val_accuracy: 0.9384\n",
      "Epoch 40/150\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.1155 - accuracy: 0.9583 - val_loss: 0.2518 - val_accuracy: 0.9399\n",
      "Epoch 41/150\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.1119 - accuracy: 0.9610 - val_loss: 0.2773 - val_accuracy: 0.9377\n",
      "Epoch 42/150\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.1143 - accuracy: 0.9609 - val_loss: 0.2584 - val_accuracy: 0.9413\n",
      "Epoch 43/150\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.1139 - accuracy: 0.9585 - val_loss: 0.2673 - val_accuracy: 0.9399\n",
      "Epoch 44/150\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.1161 - accuracy: 0.9570 - val_loss: 0.2671 - val_accuracy: 0.9384\n",
      "Epoch 45/150\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.1128 - accuracy: 0.9598 - val_loss: 0.2823 - val_accuracy: 0.9413\n",
      "Epoch 46/150\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.1087 - accuracy: 0.9601 - val_loss: 0.2876 - val_accuracy: 0.9362\n",
      "Epoch 47/150\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.1121 - accuracy: 0.9598 - val_loss: 0.2767 - val_accuracy: 0.9384\n",
      "Epoch 48/150\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.1096 - accuracy: 0.9601 - val_loss: 0.2787 - val_accuracy: 0.9370\n",
      "Epoch 49/150\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.1040 - accuracy: 0.9614 - val_loss: 0.2836 - val_accuracy: 0.9370\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/150\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.1026 - accuracy: 0.9621 - val_loss: 0.3034 - val_accuracy: 0.9391\n",
      "Epoch 51/150\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.1013 - accuracy: 0.9612 - val_loss: 0.3019 - val_accuracy: 0.9304\n",
      "Epoch 52/150\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.1027 - accuracy: 0.9618 - val_loss: 0.2892 - val_accuracy: 0.9341\n",
      "Epoch 53/150\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.1011 - accuracy: 0.9610 - val_loss: 0.2835 - val_accuracy: 0.9297\n",
      "Epoch 54/150\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.1071 - accuracy: 0.9607 - val_loss: 0.2976 - val_accuracy: 0.9362\n",
      "Epoch 55/150\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.0985 - accuracy: 0.9619 - val_loss: 0.3194 - val_accuracy: 0.9283\n",
      "Epoch 56/150\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.0947 - accuracy: 0.9638 - val_loss: 0.3173 - val_accuracy: 0.9348\n",
      "Epoch 57/150\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.0954 - accuracy: 0.9632 - val_loss: 0.3189 - val_accuracy: 0.9377\n",
      "Epoch 58/150\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.0928 - accuracy: 0.9643 - val_loss: 0.3352 - val_accuracy: 0.9297\n",
      "Epoch 59/150\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.0913 - accuracy: 0.9634 - val_loss: 0.3351 - val_accuracy: 0.9326\n",
      "Epoch 60/150\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.0901 - accuracy: 0.9663 - val_loss: 0.3411 - val_accuracy: 0.9312\n",
      "Epoch 61/150\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.0932 - accuracy: 0.9648 - val_loss: 0.3451 - val_accuracy: 0.9362\n",
      "Epoch 62/150\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.0902 - accuracy: 0.9645 - val_loss: 0.3294 - val_accuracy: 0.9341\n",
      "Epoch 63/150\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.0888 - accuracy: 0.9657 - val_loss: 0.3548 - val_accuracy: 0.9362\n",
      "Epoch 64/150\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.0866 - accuracy: 0.9665 - val_loss: 0.3606 - val_accuracy: 0.9355\n",
      "Epoch 65/150\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.0971 - accuracy: 0.9657 - val_loss: 0.3367 - val_accuracy: 0.9333\n",
      "Epoch 66/150\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.0884 - accuracy: 0.9667 - val_loss: 0.3351 - val_accuracy: 0.9370\n",
      "Epoch 67/150\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.0854 - accuracy: 0.9667 - val_loss: 0.3760 - val_accuracy: 0.9312\n",
      "Epoch 68/150\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.0886 - accuracy: 0.9663 - val_loss: 0.3695 - val_accuracy: 0.9246\n",
      "Epoch 69/150\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.0865 - accuracy: 0.9663 - val_loss: 0.3648 - val_accuracy: 0.9362\n",
      "Epoch 70/150\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.0810 - accuracy: 0.9685 - val_loss: 0.3910 - val_accuracy: 0.9326\n",
      "Epoch 71/150\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.0845 - accuracy: 0.9674 - val_loss: 0.3841 - val_accuracy: 0.9232\n",
      "Epoch 72/150\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.0787 - accuracy: 0.9699 - val_loss: 0.3977 - val_accuracy: 0.9254\n",
      "Epoch 73/150\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.0785 - accuracy: 0.9696 - val_loss: 0.3756 - val_accuracy: 0.9304\n",
      "Epoch 74/150\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.0710 - accuracy: 0.9710 - val_loss: 0.3847 - val_accuracy: 0.9312\n",
      "Epoch 75/150\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.0738 - accuracy: 0.9710 - val_loss: 0.4286 - val_accuracy: 0.9362\n",
      "Epoch 76/150\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.0815 - accuracy: 0.9688 - val_loss: 0.4085 - val_accuracy: 0.9326\n",
      "Epoch 77/150\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.0764 - accuracy: 0.9719 - val_loss: 0.4329 - val_accuracy: 0.9290\n",
      "Epoch 78/150\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.0730 - accuracy: 0.9706 - val_loss: 0.3809 - val_accuracy: 0.9239\n",
      "Epoch 79/150\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.0692 - accuracy: 0.9723 - val_loss: 0.4402 - val_accuracy: 0.9275\n",
      "Epoch 80/150\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.0648 - accuracy: 0.9763 - val_loss: 0.4301 - val_accuracy: 0.9217\n",
      "Epoch 81/150\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.0682 - accuracy: 0.9735 - val_loss: 0.4477 - val_accuracy: 0.9203\n",
      "Epoch 82/150\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.0672 - accuracy: 0.9728 - val_loss: 0.4432 - val_accuracy: 0.9362\n",
      "Epoch 83/150\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.0603 - accuracy: 0.9763 - val_loss: 0.4926 - val_accuracy: 0.9268\n",
      "Epoch 84/150\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.0632 - accuracy: 0.9748 - val_loss: 0.4806 - val_accuracy: 0.9239\n",
      "Epoch 85/150\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.0580 - accuracy: 0.9772 - val_loss: 0.4951 - val_accuracy: 0.9246\n",
      "Epoch 86/150\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.0613 - accuracy: 0.9757 - val_loss: 0.5148 - val_accuracy: 0.9210\n",
      "Epoch 87/150\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.0668 - accuracy: 0.9728 - val_loss: 0.5111 - val_accuracy: 0.9159\n",
      "Epoch 88/150\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.0699 - accuracy: 0.9732 - val_loss: 0.4341 - val_accuracy: 0.9152\n",
      "Epoch 89/150\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.0773 - accuracy: 0.9696 - val_loss: 0.4531 - val_accuracy: 0.9254\n",
      "Epoch 90/150\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.0702 - accuracy: 0.9744 - val_loss: 0.4271 - val_accuracy: 0.9188\n",
      "Epoch 91/150\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.0782 - accuracy: 0.9712 - val_loss: 0.4171 - val_accuracy: 0.9312\n",
      "Epoch 92/150\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.0633 - accuracy: 0.9764 - val_loss: 0.4356 - val_accuracy: 0.9232\n",
      "Epoch 93/150\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.0618 - accuracy: 0.9750 - val_loss: 0.4451 - val_accuracy: 0.9290\n",
      "Epoch 94/150\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.0544 - accuracy: 0.9812 - val_loss: 0.4726 - val_accuracy: 0.9246\n",
      "Epoch 95/150\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.0496 - accuracy: 0.9821 - val_loss: 0.4974 - val_accuracy: 0.9261\n",
      "Epoch 96/150\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.0480 - accuracy: 0.9833 - val_loss: 0.5312 - val_accuracy: 0.9268\n",
      "Epoch 97/150\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.0475 - accuracy: 0.9808 - val_loss: 0.5550 - val_accuracy: 0.9203\n",
      "Epoch 98/150\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.0530 - accuracy: 0.9804 - val_loss: 0.5399 - val_accuracy: 0.9217\n",
      "Epoch 99/150\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.0464 - accuracy: 0.9817 - val_loss: 0.5699 - val_accuracy: 0.9254\n",
      "Epoch 100/150\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.0441 - accuracy: 0.9842 - val_loss: 0.5855 - val_accuracy: 0.9203\n",
      "Epoch 101/150\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.0428 - accuracy: 0.9851 - val_loss: 0.6023 - val_accuracy: 0.9225\n",
      "Epoch 102/150\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.0416 - accuracy: 0.9853 - val_loss: 0.6006 - val_accuracy: 0.9203\n",
      "Epoch 103/150\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.0477 - accuracy: 0.9813 - val_loss: 0.6045 - val_accuracy: 0.9181\n",
      "Epoch 104/150\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.0443 - accuracy: 0.9842 - val_loss: 0.6043 - val_accuracy: 0.9275\n",
      "Epoch 105/150\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.0473 - accuracy: 0.9826 - val_loss: 0.6151 - val_accuracy: 0.9217\n",
      "Epoch 106/150\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.0431 - accuracy: 0.9860 - val_loss: 0.6034 - val_accuracy: 0.9109\n",
      "Epoch 107/150\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.0501 - accuracy: 0.9808 - val_loss: 0.6081 - val_accuracy: 0.9130\n",
      "Epoch 108/150\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.0546 - accuracy: 0.9788 - val_loss: 0.5656 - val_accuracy: 0.9188\n",
      "Epoch 109/150\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.0520 - accuracy: 0.9819 - val_loss: 0.5725 - val_accuracy: 0.9167\n",
      "Epoch 110/150\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.0437 - accuracy: 0.9831 - val_loss: 0.5752 - val_accuracy: 0.9116\n",
      "Epoch 111/150\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.0413 - accuracy: 0.9846 - val_loss: 0.6206 - val_accuracy: 0.9217\n",
      "Epoch 112/150\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.0517 - accuracy: 0.9815 - val_loss: 0.6155 - val_accuracy: 0.9196\n",
      "Epoch 113/150\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.0477 - accuracy: 0.9828 - val_loss: 0.5725 - val_accuracy: 0.9275\n",
      "Epoch 114/150\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.0380 - accuracy: 0.9851 - val_loss: 0.5961 - val_accuracy: 0.9167\n",
      "Epoch 115/150\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.0387 - accuracy: 0.9855 - val_loss: 0.5891 - val_accuracy: 0.9145\n",
      "Epoch 116/150\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.0366 - accuracy: 0.9866 - val_loss: 0.6174 - val_accuracy: 0.9203\n",
      "Epoch 117/150\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.0485 - accuracy: 0.9844 - val_loss: 0.6057 - val_accuracy: 0.9080\n",
      "Epoch 118/150\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.0386 - accuracy: 0.9860 - val_loss: 0.6049 - val_accuracy: 0.9239\n",
      "Epoch 119/150\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.0362 - accuracy: 0.9862 - val_loss: 0.5966 - val_accuracy: 0.9225\n",
      "Epoch 120/150\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.0319 - accuracy: 0.9891 - val_loss: 0.6371 - val_accuracy: 0.9130\n",
      "Epoch 121/150\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.0308 - accuracy: 0.9893 - val_loss: 0.6665 - val_accuracy: 0.9196\n",
      "Epoch 122/150\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.0311 - accuracy: 0.9879 - val_loss: 0.6886 - val_accuracy: 0.9246\n",
      "Epoch 123/150\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.0282 - accuracy: 0.9900 - val_loss: 0.6996 - val_accuracy: 0.9239\n",
      "Epoch 124/150\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.0299 - accuracy: 0.9888 - val_loss: 0.7244 - val_accuracy: 0.9283\n",
      "Epoch 125/150\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.0294 - accuracy: 0.9911 - val_loss: 0.7111 - val_accuracy: 0.9203\n",
      "Epoch 126/150\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.0241 - accuracy: 0.9918 - val_loss: 0.7542 - val_accuracy: 0.9246\n",
      "Epoch 127/150\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.0227 - accuracy: 0.9929 - val_loss: 0.7603 - val_accuracy: 0.9167\n",
      "Epoch 128/150\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.0229 - accuracy: 0.9913 - val_loss: 0.7767 - val_accuracy: 0.9203\n",
      "Epoch 129/150\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.0253 - accuracy: 0.9911 - val_loss: 0.7891 - val_accuracy: 0.9181\n",
      "Epoch 130/150\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.0296 - accuracy: 0.9900 - val_loss: 0.7858 - val_accuracy: 0.9101\n",
      "Epoch 131/150\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.0291 - accuracy: 0.9889 - val_loss: 0.7823 - val_accuracy: 0.9196\n",
      "Epoch 132/150\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.0278 - accuracy: 0.9904 - val_loss: 0.8043 - val_accuracy: 0.9123\n",
      "Epoch 133/150\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.0558 - accuracy: 0.9826 - val_loss: 0.7975 - val_accuracy: 0.9225\n",
      "Epoch 134/150\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.0430 - accuracy: 0.9837 - val_loss: 0.6698 - val_accuracy: 0.9159\n",
      "Epoch 135/150\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.0383 - accuracy: 0.9862 - val_loss: 0.6925 - val_accuracy: 0.9188\n",
      "Epoch 136/150\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.0366 - accuracy: 0.9875 - val_loss: 0.7072 - val_accuracy: 0.9123\n",
      "Epoch 137/150\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.0359 - accuracy: 0.9862 - val_loss: 0.6748 - val_accuracy: 0.9174\n",
      "Epoch 138/150\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.0403 - accuracy: 0.9862 - val_loss: 0.6671 - val_accuracy: 0.9181\n",
      "Epoch 139/150\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.0430 - accuracy: 0.9828 - val_loss: 0.6268 - val_accuracy: 0.9174\n",
      "Epoch 140/150\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.0298 - accuracy: 0.9884 - val_loss: 0.6714 - val_accuracy: 0.9217\n",
      "Epoch 141/150\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.0238 - accuracy: 0.9920 - val_loss: 0.6925 - val_accuracy: 0.9210\n",
      "Epoch 142/150\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.0406 - accuracy: 0.9884 - val_loss: 0.6697 - val_accuracy: 0.9087\n",
      "Epoch 143/150\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.0393 - accuracy: 0.9831 - val_loss: 0.6756 - val_accuracy: 0.9210\n",
      "Epoch 144/150\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.0255 - accuracy: 0.9906 - val_loss: 0.6744 - val_accuracy: 0.9196\n",
      "Epoch 145/150\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.0216 - accuracy: 0.9928 - val_loss: 0.6840 - val_accuracy: 0.9181\n",
      "Epoch 146/150\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.0170 - accuracy: 0.9947 - val_loss: 0.7041 - val_accuracy: 0.9130\n",
      "Epoch 147/150\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.0152 - accuracy: 0.9947 - val_loss: 0.7258 - val_accuracy: 0.9181\n",
      "Epoch 148/150\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.0151 - accuracy: 0.9953 - val_loss: 0.7475 - val_accuracy: 0.9138\n",
      "Epoch 149/150\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.0131 - accuracy: 0.9966 - val_loss: 0.7854 - val_accuracy: 0.9203\n",
      "Epoch 150/150\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.0132 - accuracy: 0.9964 - val_loss: 0.7858 - val_accuracy: 0.9188\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy',metrics=['accuracy'])\n",
    "model.summary()\n",
    "history = model.fit(X_train_segment, y_train_segment, batch_size = 256, epochs = 150, verbose = 1, validation_data=(X_test_segment, y_test_segment))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b9eb1228",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-11T05:20:09.452691Z",
     "start_time": "2023-05-11T05:20:09.438728Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best train accuracy: 0.9965566992759705\n",
      "best validation accuracy: 0.945652186870575\n"
     ]
    }
   ],
   "source": [
    "# train set에서 최고 정확도 출력\n",
    "train_acc = max(history.history['accuracy'])\n",
    "print(f\"best train accuracy: {train_acc}\")\n",
    "\n",
    "# validation set에서 최고 정확도 출력\n",
    "val_acc = max(history.history['val_accuracy'])\n",
    "print(f\"best validation accuracy: {val_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cba83e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ecg",
   "language": "python",
   "name": "ecg"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
